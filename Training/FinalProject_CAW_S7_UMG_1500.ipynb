{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dg-Zaz71X5ao","outputId":"be47ae63-da0a-43c6-956f-fbf0a54d2ec9","executionInfo":{"status":"ok","timestamp":1663242078326,"user_tz":-60,"elapsed":10578,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (1.9.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (4.1.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: librosa==0.8.1 in /usr/local/lib/python3.7/dist-packages (0.8.1)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (1.0.2)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (0.56.2)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (3.0.0)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (1.7.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (1.21.6)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (0.4.0)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (1.6.0)\n","Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (0.10.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (21.3)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (1.1.0)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (4.4.2)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.8.1) (0.39.1)\n","Requirement already satisfied: setuptools<60 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.8.1) (57.4.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.8.1) (4.12.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa==0.8.1) (3.0.9)\n","Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.1) (1.4.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.1) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (3.0.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.1) (3.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa==0.8.1) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.8.1) (2.21)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.43.0->librosa==0.8.1) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.43.0->librosa==0.8.1) (4.1.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: soundfile==0.10.2 in /usr/local/lib/python3.7/dist-packages (0.10.2)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile==0.10.2) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile==0.10.2) (2.21)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: bokeh==2.3.0 in /usr/local/lib/python3.7/dist-packages (2.3.0)\n","Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (5.1.1)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (1.21.6)\n","Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (7.1.2)\n","Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (2.11.3)\n","Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (6.0)\n","Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (4.1.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (2.8.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.7->bokeh==2.3.0) (2.0.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh==2.3.0) (3.0.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh==2.3.0) (1.15.0)\n"]}],"source":["!pip install torch==1.9.0\n","!pip install librosa==0.8.1\n","!pip install soundfile==0.10.2\n","!pip install bokeh==2.3.0"]},{"cell_type":"code","source":["import torch\n","import librosa\n","import soundfile as sf\n","import torch.nn as nn\n","import numpy as np\n","from torch.nn.utils import weight_norm\n","from torch import optim\n","from math import ceil\n","import glob\n","import time\n","import random\n","import os"],"metadata":{"id":"jkAW3HWGajZj","executionInfo":{"status":"ok","timestamp":1663242078327,"user_tz":-60,"elapsed":9,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["#Connect colab to your google drive\n","from google.colab import drive\n","drive.mount('/gdrive')"],"metadata":{"id":"LqIHLYluDlVe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663242082957,"user_tz":-60,"elapsed":4639,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}},"outputId":"632ece27-686d-455d-9251-69bb295853ab"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-dJwYs_iAkN","executionInfo":{"status":"ok","timestamp":1663242087384,"user_tz":-60,"elapsed":4431,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}},"outputId":"485f2b8c-e8c9-4284-eb55-c99ec5c41cb9"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#prepare input folder\n","input_folder='inputs'\n","if not os.path.exists(input_folder):\n","    os.mkdir(input_folder)\n","#copy file from drive to colab --remember it has to be from mydrive---for whatever reason it does not go any deeper!\n","!cp /content/drive/MyDrive/S7_mono_UG.wav /content/inputs"],"metadata":{"id":"SajXpcQKDUgM","executionInfo":{"status":"ok","timestamp":1663242087385,"user_tz":-60,"elapsed":5,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["#paramaters\n","inpainting_indices= [0, 1]\n","is_cuda = torch.cuda.is_available()\n","gpu_num = 0\n","manual_random_seed = -1\n","input_file = 'S7_mono_UG.wav'\n","segments_to_train = []\n","start_time = 0\n","init_sample_rate =  16000\n","fs_list = [320, 400, 500, 640, 800, 1000, 1280, 1600, 2000, 2500, 4000, 8000, 10000, 12000, 14400, 16000]\n","max_length = 25\n","run_mode = 'normal' #['normal', 'inpainting', 'denoising']\n","num_epochs = 1500\n","learning_rate = 0.0015\n","scheduler_lr_decay = 0.1\n","beta1 = 0.5\n","speech = False\n","num_layers = 8\n","output_folder = 'outputs'\n","filter_size = 9\n","set_first_scale_by_energy = True\n","min_energy_th = 0.0025\n","hidden_channels_init = 16\n","growing_hidden_channels_factor = 6\n","plot_losses = False\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","initial_noise_amp = 1\n","noise_amp_factor = 0.01"],"metadata":{"id":"4q0K6-KXcxmO","executionInfo":{"status":"ok","timestamp":1663242104422,"user_tz":-60,"elapsed":287,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["#functions\n","def get_input_signal(input_file, max_length):\n","    file_name = input_file.split('.')\n","    if len(file_name) < 2:\n","        input_file = '.'.join([input_file, 'wav'])\n","    output_folder = file_name[0].replace(' ', '_')\n","    if len(segments_to_train) == 0:\n","        samples, Fs = librosa.load(os.path.join('inputs', input_file), sr=None,\n","                                   offset=start_time, duration=2 * max_length)\n","\n","    if samples.shape[0] / Fs > max_length:\n","        n_samples = int(max_length * Fs)\n","        samples = samples[:n_samples]\n","\n","    output_folder = output_folder\n","    output_folder = os.path.join('outputs', output_folder)\n","    Fs = Fs\n","    if init_sample_rate < Fs:\n","        hr_samples = samples.copy()\n","        samples = librosa.resample(hr_samples, Fs, init_sample_rate)\n","        Fs = init_sample_rate\n","    norm_factor = max(abs(samples.reshape(-1)))\n","    samples = samples / norm_factor\n","    return samples, Fs\n","\n","def create_input_signals(scales, set_first_scale_by_energy, min_energy_th,  filter_size, input_signal, Fs):\n","    # Performs downscaling for desired scales and outputs list of signals\n","    signals_list = []\n","    fs_list = []\n","    n_scales = len(scales)\n","    set_first_scale = False\n","    rf = calc_receptive_field(filter_size, dilation_factors)\n","    for k in range(n_scales):\n","        downsample = scales[k]\n","        fs = int(Fs / downsample)\n","        if downsample == 1:\n","            coarse_sig = input_signal\n","        else:\n","            coarse_sig = torch.Tensor(librosa.resample(input_signal.squeeze().numpy(), Fs, fs))\n","        if speech and fs < 500:\n","            continue\n","        if set_first_scale_by_energy and not speech:\n","            e = (coarse_sig ** 2).mean()\n","            if e < min_energy_th and not set_first_scale:\n","                continue\n","        set_first_scale = True\n","        signals_list.append(coarse_sig)\n","        assert np.mod(fs, 1) == 0, 'Sampling rate is not integer'\n","        fs_list.append(int(fs))\n","\n","        # Write downsampled real sound\n","        filename = 'real@%dHz.wav' % fs\n","        write_signal(os.path.join(output_folder, filename), coarse_sig.cpu(), fs)\n","\n","    return signals_list, fs_list\n","\n","def calc_receptive_field(filter_size, dilation_factors, Fs=None):\n","    if Fs is None:\n","        # in samples\n","        return (filter_size * dilation_factors[0] + sum(dilation_factors[1:]) * (filter_size - 1))\n","    else:\n","        # in [ms]\n","        return (filter_size * dilation_factors[0] + sum(dilation_factors[1:]) * (filter_size - 1)) / Fs * 1e3\n","\n","def write_signal(path, signal, fs, overwrite=False, subtype='PCM_16'):\n","    if signal is None:\n","        return\n","    if torch.is_tensor(signal):\n","        signal = signal.squeeze().detach().cpu().numpy()\n","    if not path.endswith('.wav'):\n","        path = path + '.wav'\n","    if not overwrite:\n","        if os.path.exists(path):\n","            files = glob.glob(path[:-4].replace('[Hz]', '[[]Hz[]]') + '*')\n","            path = path[:-4] + '_' + str(len(files)) + path[-4:]\n","    maxAmp = max(abs(signal.reshape(-1)))\n","    if maxAmp > 1:\n","        signal = signal / maxAmp  # normalize to avoid clipping\n","    sf.write(path, signal, fs, subtype=subtype)\n","\n","def calc_pad_size(dilation_factors, filter_size):\n","    return int(np.ceil(sum(dilation_factors) * (filter_size - 1) / 2))\n","\n","def get_noise(device, shape):\n","    return torch.randn(shape, device=device)\n","\n","def draw_signal(generators_list, signals_lengths_list, fs_list, noise_amp_list, filter_size, dilation_factors, device, reconstruction_noise_list=None,\n","                condition=None, output_all_scales=False):\n","    # Draws a signal up to current scale, using learned generators\n","    pad_size = calc_pad_size(dilation_factors, filter_size)\n","    if output_all_scales:\n","        signals_all_scales = []\n","    for scale_idx, (netG, noise_amp) in enumerate(zip(generators_list, noise_amp_list)):\n","        signal_padder = nn.ConstantPad1d(pad_size, 0)\n","        if condition is None:\n","            n_samples = signals_lengths_list[scale_idx]\n","            if reconstruction_noise_list is not None:\n","                noise_signal = reconstruction_noise_list[scale_idx]\n","            else:\n","                noise_signal = get_noise(device, (1, 1, n_samples))\n","                noise_signal = noise_signal * noise_amp\n","\n","            if scale_idx == 0:\n","                prev_sig = torch.full(noise_signal.shape, 0, device=device, dtype=noise_signal.dtype)\n","            else:\n","                prev_sig = signal_padder(prev_sig)\n","\n","            # pad noise with zeros, to match signal after filtering\n","            if reconstruction_noise_list is None:\n","                # reconstruction_noise is already padded\n","                noise_signal = signal_padder(noise_signal)\n","                if scale_idx == 0:\n","                    prev_sig = signal_padder(prev_sig)\n","        else:\n","            if scale_idx < condition[\"condition_scale_idx\"]:\n","                continue\n","            elif scale_idx == condition[\"condition_scale_idx\"]:\n","                prev_sig = resample_sig(device, condition[\"condition_signal\"], condition['condition_fs'],\n","                                        fs_list[scale_idx]).expand(1, 1, -1)\n","            noise_signal = get_noise(device, prev_sig.shape[2]).expand(1, 1, -1)\n","            noise_signal = signal_padder(noise_signal)\n","            noise_signal = noise_signal * noise_amp\n","            prev_sig = signal_padder(prev_sig)\n","\n","        # Generate this scale signal\n","        cur_sig = netG((noise_signal + prev_sig).detach(), prev_sig)\n","\n","        if output_all_scales:\n","            signals_all_scales.append(torch.squeeze(cur_sig).detach().cpu().numpy())\n","\n","        # Upsample for next scale\n","        if scale_idx < len(fs_list) - 1:\n","            up_sig = resample_sig( device, cur_sig, orig_fs=fs_list[scale_idx], target_fs=fs_list[scale_idx + 1])\n","            if up_sig.shape[2] > signals_lengths_list[scale_idx + 1]:\n","                assert abs(\n","                    up_sig.shape[2] > signals_lengths_list[scale_idx + 1]) < 20, 'Should not happen, check this!'\n","                up_sig = up_sig[:, :, :signals_lengths_list[scale_idx + 1]]\n","            elif up_sig.shape[2] < signals_lengths_list[scale_idx + 1]:\n","                assert abs(\n","                    up_sig.shape[2] < signals_lengths_list[scale_idx + 1]) < 20, 'Should not happen, check this!'\n","                up_sig = torch.cat(\n","                    (up_sig, up_sig.new_zeros(1, 1, signals_lengths_list[scale_idx + 1] - up_sig.shape[2])),\n","                    dim=2)\n","        else:\n","            up_sig = cur_sig\n","        prev_sig = up_sig\n","        prev_sig = prev_sig.detach()\n","\n","        del up_sig, cur_sig, noise_signal, netG\n","\n","    if output_all_scales:\n","        return signals_all_scales\n","    else:\n","        return prev_sig\n","\n","def resample_sig(device,input_signal, orig_fs=None, target_fs=None, resamplers=None):\n","    if resamplers == None:\n","        resamplers = {}\n","    if (orig_fs, target_fs) in resamplers.keys() and resamplers[(orig_fs, target_fs)].in_shape[2] == \\\n","            input_signal.shape[2]:\n","        resampler = resamplers[(orig_fs, target_fs)]\n","    else:\n","        in_shape = input_signal.shape\n","        scale_factors = (1, 1, target_fs / orig_fs)\n","        resampler = ResizeLayer(in_shape, scale_factors=scale_factors, device=device)\n","        resamplers[(orig_fs, target_fs)] = resampler\n","    new_sig = resampler(input_signal)\n","\n","    return new_sig\n","\n","def support_sz(sz):\n","    def wrapper(f):\n","        f.support_sz = sz\n","        return f\n","    return wrapper\n","\n","@support_sz(4)\n","def cubic(x):\n","    fw, to_dtype, eps = set_framework_dependencies(x)\n","    absx = fw.abs(x)\n","    absx2 = absx ** 2\n","    absx3 = absx ** 3\n","    return ((1.5 * absx3 - 2.5 * absx2 + 1.) * to_dtype(absx <= 1.) +\n","            (-0.5 * absx3 + 2.5 * absx2 - 4. * absx + 2.) *\n","            to_dtype((1. < absx) & (absx <= 2.)))\n","\n","class ResizeLayer(nn.Module):\n","    def __init__(self, in_shape, scale_factors=None, out_shape=None,\n","                 interp_method=cubic, support_sz=None,\n","                 antialiasing=True, device=None):\n","        super(ResizeLayer, self).__init__()\n","\n","        # fw stands for framework, that can be either numpy or torch. since\n","        # this is a torch layer, only one option in this case.\n","        fw = torch\n","        eps = fw.finfo(fw.float32).eps\n","\n","        # set missing scale factors or output shapem one according to another,\n","        # scream if both missing\n","        scale_factors, out_shape = set_scale_and_out_sz(in_shape, out_shape,\n","                                                        scale_factors, fw)\n","        \n","        # unless support size is specified by the user, it is an attribute\n","        # of the interpolation method\n","        if support_sz is None:\n","            support_sz = interp_method.support_sz\n","        \n","        self.n_dims = len(in_shape)       \n","\n","        # sort indices of dimensions according to scale of each dimension.\n","        # since we are going dim by dim this is efficient\n","        self.sorted_filtered_dims_and_scales = [(dim, scale_factors[dim])\n","                                                for dim in\n","                                                sorted(range(self.n_dims),\n","                                                key=lambda ind:\n","                                                scale_factors[ind])\n","                                                if scale_factors[dim] != 1.]\n","\n","        # iterate over dims\n","        field_of_view_list = []\n","        weights_list = []\n","        for dim, scale_factor in self.sorted_filtered_dims_and_scales:\n","\n","            # get 1d set of weights and fields of view for each output\n","            # location along this dim\n","            field_of_view, weights = prepare_weights_and_field_of_view_1d(\n","                dim, scale_factor, in_shape[dim], out_shape[dim],\n","                interp_method, support_sz, antialiasing, fw, eps, device)\n","\n","            # keep weights and fields of views for all dims\n","            weights_list.append(nn.Parameter(weights, requires_grad=False))\n","            field_of_view_list.append(nn.Parameter(field_of_view,\n","                                      requires_grad=False))\n","\n","        self.field_of_view = nn.ParameterList(field_of_view_list)\n","        self.weights = nn.ParameterList(weights_list)\n","        self.in_shape = in_shape\n","\n","    def forward(self, input):\n","        # output begins identical to input and changes with each iteration\n","        output = input\n","\n","        for (dim, scale_factor), field_of_view, weights in zip(\n","                self.sorted_filtered_dims_and_scales,\n","                self.field_of_view,\n","                self.weights):\n","            # multiply the weights by the values in the field of view and\n","            # aggreagate\n","            output = apply_weights(output, field_of_view, weights, dim,\n","                                   self.n_dims, torch)\n","        return output\n","\n","def prepare_weights_and_field_of_view_1d(dim, scale_factor, in_sz, out_sz,\n","                                         interp_method, support_sz, \n","                                         antialiasing, fw, eps, device=None):\n","    # If antialiasing is taking place, we modify the window size and the\n","    # interpolation method (see inside function)\n","    interp_method, cur_support_sz = apply_antialiasing_if_needed(\n","                                                             interp_method,\n","                                                             support_sz,\n","                                                             scale_factor,\n","                                                             antialiasing)\n","\n","    # STEP 1- PROJECTED GRID: The non-integer locations of the projection of\n","    # output pixel locations to the input tensor\n","    projected_grid = get_projected_grid(in_sz, out_sz, scale_factor, fw, device)\n","\n","    # STEP 2- FIELDS OF VIEW: for each output pixels, map the input pixels\n","    # that influence it\n","    field_of_view = get_field_of_view(projected_grid, cur_support_sz, in_sz,\n","                                      fw, eps)\n","\n","    # STEP 3- CALCULATE WEIGHTS: Match a set of weights to the pixels in the\n","    # field of view for each output pixel\n","    weights = get_weights(interp_method, projected_grid, field_of_view)\n","\n","    return field_of_view, weights\n","\n","def apply_weights(input, field_of_view, weights, dim, n_dims, fw):\n","    # STEP 4- APPLY WEIGHTS: Each output pixel is calculated by multiplying\n","    # its set of weights with the pixel values in its field of view.\n","    # We now multiply the fields of view with their matching weights.\n","    # We do this by tensor multiplication and broadcasting.\n","    # this step is separated to a different function, so that it can be\n","    # repeated with the same calculated weights and fields.\n","\n","    # for this operations we assume the resized dim is the first one.\n","    # so we transpose and will transpose back after multiplying\n","    tmp_input = fw_swapaxes(input, dim, 0, fw)\n","\n","    # field_of_view is a tensor of order 2: for each output (1d location\n","    # along cur dim)- a list of 1d neighbors locations.\n","    # note that this whole operations is applied to each dim separately,\n","    # this is why it is all in 1d.\n","    # neighbors = tmp_input[field_of_view] is a tensor of order image_dims+1:\n","    # for each output pixel (this time indicated in all dims), these are the\n","    # values of the neighbors in the 1d field of view. note that we only\n","    # consider neighbors along the current dim, but such set exists for every\n","    # multi-dim location, hence the final tensor order is image_dims+1.\n","    neighbors = tmp_input[field_of_view]\n","\n","    # weights is an order 2 tensor: for each output location along 1d- a list\n","    # of weighs matching the field of view. we augment it with ones, for\n","    # broadcasting, so that when multiplies some tensor the weights affect\n","    # only its first dim.\n","    tmp_weights = fw.reshape(weights, (*weights.shape, * [1] * (n_dims - 1)))\n","\n","    # now we simply multiply the weights with the neighbors, and then sum\n","    # along the field of view, to get a single value per out pixel\n","    tmp_output = (neighbors * tmp_weights).sum(1)\n","\n","    # we transpose back the resized dim to its original position\n","    return fw_swapaxes(tmp_output, 0, dim, fw)\n","\n","def get_weights(interp_method, projected_grid, field_of_view):\n","    # the set of weights per each output pixels is the result of the chosen\n","    # interpolation method applied to the distances between projected grid\n","    # locations and the pixel-centers in the field of view (distances are\n","    # directed, can be positive or negative)\n","    weights = interp_method(projected_grid[:, None] - field_of_view)\n","\n","    # we now carefully normalize the weights to sum to 1 per each output pixel\n","    sum_weights = weights.sum(1, keepdims=True)\n","    sum_weights[sum_weights == 0] = 1\n","    return weights / sum_weights\n","\n","def fw_ceil(x, fw):\n","    return x.ceil().long()\n","\n","\n","def fw_cat(x, fw):\n","    return fw.cat(x)\n","\n","\n","def fw_swapaxes(x, ax_1, ax_2, fw):\n","    return x.transpose(ax_1, ax_2)\n","    \n","def fw_set_device(x, device, fw):\n","    return x.to(device)\n","\n","def set_scale_and_out_sz(in_shape, out_shape, scale_factors, fw):\n","    # eventually we must have both scale-factors and out-sizes for all in/out\n","    # dims. however, we support many possible partial arguments\n","    if scale_factors is None and out_shape is None:\n","        raise ValueError(\"either scale_factors or out_shape should be \"\n","                         \"provided\")\n","    if out_shape is not None:\n","        # if out_shape has less dims than in_shape, we defaultly resize the\n","        # first dims for numpy and last dims for torch\n","        out_shape = list(out_shape) + list(in_shape[:-len(out_shape)])\n","        if scale_factors is None:\n","            # if no scale given, we calculate it as the out to in ratio\n","            # (not recomended)\n","            scale_factors = [out_sz / in_sz for out_sz, in_sz\n","                             in zip(out_shape, in_shape)]\n","    if scale_factors is not None:\n","        # by default, if a single number is given as scale, we assume resizing\n","        # two dims (most common are images with 2 spatial dims)\n","        scale_factors = (scale_factors\n","                         if isinstance(scale_factors, (list, tuple))\n","                         else [scale_factors, scale_factors])\n","        # if less scale_factors than in_shape dims, we defaultly resize the\n","        # first dims for numpy and last dims for torch\n","        scale_factors = list(scale_factors) + [1] * (len(in_shape) - len(scale_factors)) \n","        if out_shape is None:\n","            # when no out_shape given, it is calculated by multiplying the\n","            # scale by the in_shape (not recomended)\n","            out_shape = [ceil(scale_factor * in_sz)\n","                         for scale_factor, in_sz in\n","                         zip(scale_factors, in_shape)]\n","        # next line intentionally after out_shape determined for stability\n","        scale_factors = [float(sf) for sf in scale_factors]\n","    return scale_factors, out_shape\n","\n","def apply_antialiasing_if_needed(interp_method, support_sz, scale_factor,\n","                                 antialiasing):\n","    # antialiasing is \"stretching\" the field of view according to the scale\n","    # factor (only for downscaling). this is low-pass filtering. this\n","    # requires modifying both the interpolation (stretching the 1d\n","    # function and multiplying by the scale-factor) and the window size.\n","    if scale_factor >= 1.0 or not antialiasing:\n","        return interp_method, support_sz\n","    cur_interp_method = (lambda arg: scale_factor *\n","                         interp_method(scale_factor * arg))\n","    cur_support_sz = support_sz / scale_factor\n","    return cur_interp_method, cur_support_sz\n","\n","def get_projected_grid(in_sz, out_sz, scale_factor, fw, device=None):\n","    # we start by having the ouput coordinates which are just integer locations\n","    out_coordinates = fw.arange(out_sz)\n","    \n","    # if using torch we need to match the grid tensor device to the input device\n","    out_coordinates = fw_set_device(out_coordinates, device, fw)\n","        \n","    # This is projecting the ouput pixel locations in 1d to the input tensor,\n","    # as non-integer locations.\n","    # the following fomrula is derived in the paper\n","    # \"From Discrete to Continuous Convolutions\" by Shocher et al.\n","    return (out_coordinates / scale_factor +\n","            (in_sz - 1) / 2 - (out_sz - 1) / (2 * scale_factor))\n","\n","\n","def get_field_of_view(projected_grid, cur_support_sz, in_sz, fw, eps):\n","    # for each output pixel, map which input pixels influence it, in 1d.\n","    # we start by calculating the leftmost neighbor, using half of the window\n","    # size (eps is for when boundary is exact int)\n","    left_boundaries = fw_ceil(projected_grid - cur_support_sz / 2 - eps, fw)\n","\n","    # then we simply take all the pixel centers in the field by counting\n","    # window size pixels from the left boundary\n","    ordinal_numbers = fw.arange(ceil(cur_support_sz - eps))\n","    # in case using torch we need to match the device\n","    ordinal_numbers = fw_set_device(ordinal_numbers, projected_grid.device, fw)\n","    field_of_view = left_boundaries[:, None] + ordinal_numbers\n","\n","    # next we do a trick instead of padding, we map the field of view so that\n","    # it would be like mirror padding, without actually padding\n","    # (which would require enlarging the input tensor)\n","    mirror = fw_cat((fw.arange(in_sz), fw.arange(in_sz - 1, -1, step=-1)), fw)\n","    field_of_view = mirror[fw.remainder(field_of_view, mirror.shape[0])]\n","    field_of_view = fw_set_device(field_of_view,projected_grid.device, fw)\n","    return field_of_view\n","\n","def set_framework_dependencies(x):\n","    if type(x) is np.ndarray:\n","        to_dtype = lambda a: a\n","        fw = np\n","    else:\n","        to_dtype = lambda a: a.to(x.dtype)\n","        fw = torch\n","    eps = fw.finfo(fw.float32).eps\n","    return fw, to_dtype, eps\n","\n","def calc_gradient_penalty(run_mode, current_holes, netD, real_data, fake_data, LAMBDA, alpha=None, _grad_outputs=None, mask_ratio=None, not_valid_idx_start=None, not_valid_idx_end=None):\n","    # Gradient penalty method for WGAN\n","    if alpha is None:\n","        alpha = torch.rand(1, 1)\n","        alpha = alpha.expand(real_data.size())\n","        if torch.cuda.is_available():\n","            alpha = alpha.cuda(real_data.get_device())  # gpu) #if use_cuda else alpha\n","    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n","    interpolates = torch.autograd.Variable(interpolates, requires_grad=True)\n","    use_mask = False\n","    mask_ratio = 1\n","    disc_interpolates = netD(interpolates, use_mask)\n","    if _grad_outputs is None:\n","        _grad_outputs = torch.ones(disc_interpolates.size())\n","        if torch.cuda.is_available():\n","            _grad_outputs = _grad_outputs.cuda(real_data.get_device())\n","    gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n","                                    grad_outputs=_grad_outputs,\n","                                    create_graph=True, retain_graph=True, only_inputs=True)[0]\n","    gradient_penalty = ((mask_ratio * gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n","    del gradients, interpolates, _grad_outputs, disc_interpolates\n","    return gradient_penalty\n","\n","def stft(sig, n_fft, hop_length, window_size):\n","    s = torch.stft(sig, n_fft, hop_length, win_length=window_size,\n","                   window=torch.hann_window(window_size, device=sig.device), return_complex=False)\n","    return s\n","\n","def spec(x, n_fft, hop_length, window_size):\n","    s = stft(x, n_fft, hop_length, window_size)\n","    n = torch.norm(s, p=2, dim=-1)\n","    return n\n","\n","def norm(x):\n","    return (x.view(x.shape[0], -1) ** 2).sum(dim=-1).sqrt()\n","\n","\n","def squeeze(x):\n","    if len(x.shape) == 3:\n","        assert x.shape[-1] in [1, 2]\n","        x = torch.mean(x, -1)\n","    if len(x.shape) != 2:\n","        raise ValueError(f'Unknown input shape {x.shape}')\n","    return x\n","\n","def multi_scale_spectrogram_loss(multispec_loss_n_fft, multispec_loss_hop_length, multispec_loss_window_size, current_holes, x_in, x_out):\n","    losses = []\n","    args = [multispec_loss_n_fft,\n","            multispec_loss_hop_length,\n","            multispec_loss_window_size]\n","    for n_fft, hop_length, window_size in zip(*args):\n","        if window_size == -1:\n","            window_size = x_in.shape[1]\n","            hop_length = window_size + 1\n","            n_fft = int(2 ** np.ceil(np.log2(window_size)))\n","        spec_in = spec(squeeze(x_in.float()), n_fft, hop_length, window_size)\n","        spec_out = spec(squeeze(x_out.float()), n_fft, hop_length, window_size)\n","        losses.append(norm(spec_in - spec_out))\n","    return sum(losses) / len(losses)\n","\n","def reset_grads(model, require_grad):\n","    for p in model.parameters():\n","        p.requires_grad_(require_grad)\n","    return model"],"metadata":{"id":"bELoeAltdEdB","executionInfo":{"status":"ok","timestamp":1663242107255,"user_tz":-60,"elapsed":337,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["#model \n","class Generator(nn.Module):\n","    def __init__(self, filter_size, hidden_channels, current_fs ):\n","        super(Generator, self).__init__()\n","        self.head = ConvBlock(filter_size, 1, hidden_channels, dilation_factors[0])\n","        self.body = nn.Sequential()\n","        self.Fs = current_fs\n","        for i in range(num_layers - 2):\n","            block = ConvBlock(filter_size, hidden_channels, hidden_channels, dilation_factors[i + 1])\n","            self.body.add_module('block%d' % (i + 1), block)\n","        self.tail = nn.Sequential()\n","        self.tail.add_module('tail0',\n","                             NormConv1d(in_channels=hidden_channels, out_channels=hidden_channels,\n","                                        kernel_size=filter_size,\n","                                        dilation=dilation_factors[-1]))\n","        self.filter = nn.Sequential(\n","            NormConv1d(in_channels=hidden_channels, out_channels=hidden_channels,\n","                       kernel_size=filter_size, padding=int((filter_size - 1) / 2)),\n","            nn.Tanh()\n","        )\n","        self.gate = nn.Sequential(\n","            NormConv1d(in_channels=hidden_channels, out_channels=hidden_channels,\n","                       kernel_size=filter_size, padding=int((filter_size - 1) / 2)),\n","            nn.Sigmoid()\n","        )\n","        self.out_conv = NormConv1d(hidden_channels, 1, kernel_size=1)\n","        self.pe_filter = PreEmphasisFilter(device)\n","\n","    def forward(self, noise_plus_sig, prev_sig):\n","        out_head = self.head(noise_plus_sig)\n","        out_body = self.body(out_head)\n","        out_tail = self.tail(out_body)\n","        filter = self.filter(out_tail)\n","        gate = self.gate(out_tail)\n","        out_tail = filter * gate\n","        out_tail = self.out_conv(out_tail)\n","        out_filt = self.pe_filter(out_tail)\n","        ind = int((prev_sig.shape[2] - out_filt.shape[2]) / 2)\n","        prev_sig = prev_sig[:, :, ind:(prev_sig.shape[2] - ind)]\n","        output = out_filt + prev_sig\n","        return output\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, run_mode, current_holes, hidden_channels, dilation_factors, num_layers, device,filter_size ):\n","        super(Discriminator, self).__init__()\n","        if run_mode == 'inpainting':\n","            mask = current_holes\n","        else:\n","            mask = None\n","        self.head = ConvBlock(filter_size, 1, hidden_channels, dilation_factors[0], mask=mask)\n","        mask = self.head.mask_out\n","        self.body = nn.ModuleList()\n","        for i in range(num_layers - 2):\n","            block = ConvBlock(filter_size, hidden_channels, hidden_channels,\n","                              dilation_factors[i + 1], mask=mask)\n","            mask = block.mask_out\n","            self.body.add_module('block%d' % (i + 1), block)\n","        self.mask_out = mask\n","        self.tail = NormConv1d(hidden_channels, 1, kernel_size=filter_size,\n","                               dilation=dilation_factors[-1])\n","        self.pe_filter = PreEmphasisFilter(device)\n","\n","    def forward(self, sig, use_mask=False):\n","        out_head = self.head(sig, use_mask)\n","        out_body = out_head\n","        for b in self.body:\n","            out_body = b(out_body, use_mask)\n","        out_tail = self.tail(out_body)\n","        output = self.pe_filter(out_tail)\n","        return output\n","\n","\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1 and classname.find('ConvBlock') == -1 and hasattr(m, 'weight'):\n","        if m.weight.numel() > 1 and m.weight.requires_grad:  # scalar blocks are initiailized upon creation\n","            m.weight.data.normal_(0.0, 0.02)\n","\n","    elif classname.find('Norm') != -1 and hasattr(m, 'weight'):\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)\n","\n","class PreEmphasisFilter(nn.Module):\n","    def __init__(self, device):\n","        super(PreEmphasisFilter, self).__init__()\n","        self.alpha = torch.Tensor([0.97]).to(device)\n","        self.alpha.requires_grad = False\n","\n","    def forward(self, x):\n","        output = torch.cat((x[:, :, 0].view(x.shape[0], x.shape[1], 1), x[:, :, 1:] - self.alpha * x[:, :, :-1]), dim=2)\n","        return output\n","\n","\n","class NormConv1d(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=True):\n","        super(NormConv1d, self).__init__()\n","        self.conv = weight_norm(nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n","                                          stride=stride, padding=padding, dilation=dilation, bias=bias))\n","\n","    def forward(self, x):\n","        output = self.conv(x)\n","        return output\n","\n","\n","class ConvBlock(nn.Sequential):\n","    def __init__(self, filter_size, in_channels, out_channels, dilation=1, mask=None):\n","        super(ConvBlock, self).__init__()\n","        if filter_size is None:\n","            filter_size = filter_size\n","        if mask is not None:\n","            self.mask_in = mask\n","            self.mask_out = []\n","            self.rf = int((filter_size - 1) * dilation)\n","            for hole in self.mask_in:\n","                self.mask_out.append([hole[0] - self.rf, hole[1]])\n","            # ???\n","            # for idx in range(len(self.mask_out) - 1):\n","            #     if self.mask_out[idx+1][0] < self.mask_out[idx][1]:\n","            #         self.mask_out[idx+1][0] = self.mask_out[idx][1] + 1\n","\n","        else:\n","            self.mask_out = None\n","        self.conv = NormConv1d(in_channels, out_channels, filter_size, dilation=dilation)\n","        self.norm = nn.BatchNorm1d(out_channels)\n","        self.activation = nn.LeakyReLU(0.2, inplace=True)\n","\n","    def forward(self, x, use_mask=False):\n","        out_conv = self.conv(x)\n","        if use_mask:\n","            #tmp = torch.cat((out_conv[:, :, :int(self.mask_out[0][0])], out_conv[:, :, int(self.mask_out[0][1] + 1):]), dim=2)\n","            tmp = out_conv[:, :, :int(self.mask_out[0][0])].clone()\n","            cut_idx = []\n","            cut_idx.append(tmp.shape[2])\n","            for idx in range(len(self.mask_out)-1):\n","                tmp = torch.cat((tmp, out_conv[:, :, int(self.mask_out[idx][1] + 1):int(self.mask_out[idx+1][0])]), dim=2)\n","                cut_idx.append(tmp.shape[2])\n","            tmp = torch.cat((tmp, out_conv[:, :, int(self.mask_out[-1][1] + 1):]), dim=2)\n","\n","            tmp_norm = self.norm(tmp)\n","            out_norm = out_conv\n","            out_norm[:, :, :int(self.mask_out[0][0])] = tmp_norm[:, :, :int(cut_idx[0])]\n","            for idx in range(len(self.mask_out) - 1):\n","                out_norm[:, :, int(self.mask_out[idx][1] + 1):int(self.mask_out[idx+1][0])] = tmp_norm[:, :, int(cut_idx[idx]):int(cut_idx[idx+1])] #tmp_norm[:, :, int(self.mask_out[idx][0]):int(self.mask_out[idx+1][0])]\n","                #out_norm[:, :, :int(self.mask_out[idx+1][0])] = tmp_norm[:, :, :int(self.mask_out[idx+1][0])]\n","            out_norm[:, :, int(self.mask_out[-1][1] + 1):] = tmp_norm[:, :, int(cut_idx[-1]):]\n","\n","        else:\n","            out_norm = self.norm(out_conv)\n","        return self.activation(out_norm)"],"metadata":{"id":"uv_GjFaJDb6G","executionInfo":{"status":"ok","timestamp":1663242119649,"user_tz":-60,"elapsed":302,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["#training functions\n","def train(manual_random_seed, fs_list, scales, growing_hidden_channels_factor,learning_rate, beta1, scheduler_lr_decay, plot_losses,\n","          initial_noise_amp, noise_amp_factor, signals_list, dilation_factors, output_folder, inputs_lengths):\n","    if manual_random_seed != -1:\n","        random.seed(manual_random_seed)\n","        torch.manual_seed(manual_random_seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","\n","    fs_list = fs_list\n","    n_scales = len(scales)\n","    generators_list = []\n","    noise_amp_list = []\n","    if run_mode == 'inpainting':\n","        energy_list = [(sig[mask] ** 2).mean().item() for sig, mask in zip(signals_list, masks)]\n","    else:\n","        energy_list = [(sig ** 2).mean().item() for sig in signals_list]\n","    reconstruction_noise_list = []\n","    output_signals = []\n","    loss_vectors = []\n","\n","    for scale_idx in range(n_scales):\n","        output_signals_single_scale, loss_vectors_single_scale, netG, reconstruction_noise_list, noise_amp = train_single_scale(\n","                      scales, device, run_mode, hidden_channels_init, growing_hidden_channels_factor,  learning_rate, beta1, \n","                      scheduler_lr_decay, plot_losses, initial_noise_amp, noise_amp_factor, signals_list, fs_list, \n","                      generators_list, noise_amp_list, energy_list, reconstruction_noise_list, dilation_factors, output_folder, inputs_lengths)\n","\n","        # Write fake sound\n","        fake_sound = output_signals_single_scale['fake_signal'].squeeze()\n","        filename = 'fake@%dHz.wav' % fs_list[scale_idx]\n","        write_signal(os.path.join(output_folder, filename), fake_sound,\n","                     fs_list[scale_idx], overwrite=False)\n","\n","        # Write reconstructed sound\n","        reconstructed_sound = output_signals_single_scale['reconstructed_signal'].squeeze()\n","        filename = 'reconstructed@%dHz.wav' % fs_list[scale_idx]\n","        write_signal(os.path.join(output_folder, filename),\n","                     reconstructed_sound, fs_list[scale_idx], overwrite=False)\n","        torch.save(reconstruction_noise_list,\n","                   os.path.join(output_folder, 'reconstruction_noise_list.pt'))\n","\n","        generators_list.append(netG)\n","        noise_amp_list.append(noise_amp)\n","        output_signals.append(output_signals_single_scale)\n","        loss_vectors.append(loss_vectors_single_scale)\n","\n","    return output_signals, loss_vectors, generators_list, noise_amp_list, energy_list, reconstruction_noise_list\n","\n","\n","def train_single_scale(scales, device, run_mode, hidden_channels_init, growing_hidden_channels_factor,\n","                       learning_rate, beta1, scheduler_lr_decay, plot_losses, initial_noise_amp, noise_amp_factor, signals_list,\n","                        fs_list, generators_list, noise_amp_list, energy_list, reconstruction_noise_list, dilation_factors, output_folder, inputs_lengths):\n","    # Terminology: 0 is the higher scale (original signal, no downsampling). Higher scale means larger downsampling, e.g shorter signals\n","    n_scales = len(scales)\n","    current_scale = n_scales - len(generators_list) - 1\n","    scale_idx = n_scales - current_scale - 1\n","    input_signal = signals_list[scale_idx].to(device)\n","    current_fs = fs_list[scale_idx]\n","    N = len(input_signal)\n","\n","    if run_mode == 'inpainting':\n","        current_mask = masks[scale_idx]\n","        current_mask = current_mask\n","        current_holes = torch.Tensor([(int(idx[0] / Fs * current_fs), int(idx[1] / Fs * current_fs)) for idx in inpainting_indices]).to(device)\n","    else:\n","        current_holes = None\n","\n","    # Create inputs\n","    real_signal = input_signal.reshape(1, 1, N)\n","\n","    hidden_channels = hidden_channels_init if scale_idx == 0 else int(\n","        hidden_channels_init * growing_hidden_channels_factor)\n","\n","    scale_num = n_scales - scale_idx - 1\n","    pad_size = calc_pad_size(dilation_factors, filter_size)\n","    signal_padder = nn.ConstantPad1d(pad_size, 0)\n","\n","    # Initialize models\n","    netD = Discriminator(run_mode, current_holes, hidden_channels, dilation_factors, num_layers, device, filter_size).to(device)\n","    netD.apply(weights_init)\n","    netG = Generator(filter_size, hidden_channels, current_fs).to(device)\n","    netG.apply(weights_init)\n","    receptive_field = calc_receptive_field(filter_size, dilation_factors, current_fs)\n","    receptive_field_percent = 100 * receptive_field / 1e3 / (N / current_fs)\n","    print('Signal in scale %d has %d samples, sample rate is %d[Hz].' % (\n","        scale_num, N, current_fs))\n","    print('Total receptive field is %d[msec] (%.1f%% of input).' % (receptive_field, receptive_field_percent))\n","    with open(os.path.join(output_folder, 'log.txt'), 'a') as f:\n","        f.write('*' * 30 + ' Scale ' + str(scale_num) + ' (' + str(current_fs) + ' [Hz]) ' + '*' * 30)\n","        f.write('\\nreceptive_field = %d[msec] (%.1f%% of input)' % (receptive_field, receptive_field_percent))\n","        f.write('\\nsignal_energy = %.4f' % energy_list[scale_idx])\n","\n","    if scale_idx == 0:\n","        reconstruction_noise = get_noise(device, real_signal.shape)\n","    else:\n","        reconstruction_noise = torch.zeros(real_signal.shape, device=device)\n","        if run_mode == 'inpainting':\n","            reconstruction_noise[:, :, torch.logical_not(current_mask)] = get_noise(device, torch.nonzero(\n","                torch.logical_not(current_mask)).shape[0]).expand(1, 1, -1).to(device)\n","\n","    reconstruction_noise = signal_padder(reconstruction_noise)\n","\n","    if scale_idx > 1:\n","        netG.load_state_dict(\n","            torch.load('%s/netGScale%d.pth' % (output_folder, scale_idx - 1), map_location=device))\n","        netD.load_state_dict(\n","            torch.load('%s/netDScale%d.pth' % (output_folder, scale_idx - 1), map_location=device))\n","\n","    output_folder = output_folder\n","\n","    # Create optimizers\n","    optimizerD = optim.Adam(netD.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n","    optimizerG = optim.Adam(netG.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n","    schedulerD = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizerD, milestones=scheduler_milestones,\n","                                                      gamma=scheduler_lr_decay)\n","    schedulerG = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizerG, milestones=scheduler_milestones,\n","                                                      gamma=scheduler_lr_decay)\n","\n","    # Initialize error vectors\n","    v_err_real = np.zeros(num_epochs, )\n","    v_err_fake = np.zeros(num_epochs, )\n","    v_gp = np.zeros(num_epochs, )\n","    v_rec_loss = np.zeros(num_epochs, )\n","\n","    epochs_start_time = time.time()\n","    # prepare inputs for gradient penalty\n","    if not run_mode == 'inpainting':\n","        D_out_shape = torch.Size((1, 1, N - 2 * pad_size))\n","        _grad_outputs = torch.ones(D_out_shape, device=device)\n","    grad_pen_alpha_vec = torch.rand(num_epochs).to(device)\n","\n","    inputs_lengths = inputs_lengths\n","    for epoch_num in range(num_epochs):\n","        print_progress = epoch_num % 100 == 0\n","        # Create noise\n","        noise_signal = get_noise(device, real_signal.shape)\n","        noise_signal = signal_padder(noise_signal)\n","        #################################################################\n","        # Optimize D by maximizing D(realSignal)+(1-D(G(noise_signal))) #\n","        #################################################################\n","        netD.zero_grad()\n","        # Run on real signal\n","        not_valid_idx_start = []\n","        not_valid_idx_end = []\n","        if run_mode == 'inpainting':\n","            out_D_real = netD(real_signal, use_mask=True)\n","            tot_samples = out_D_real.shape[2]\n","            not_valid_idx_start = [int(idx[0] - receptive_field / 1e3 * current_fs + 1) for idx in current_holes]\n","            not_valid_idx_end = [int(idx[1] + 1) for idx in current_holes]  # +1 is because of pe filter\n","            out_D_real_cp = out_D_real.clone()\n","            out_D_real = out_D_real_cp[:, :, :not_valid_idx_start[0]]\n","            if len(current_holes) > 1:\n","                for i in range(len(current_holes) - 1):\n","                    out_D_real = torch.cat((out_D_real, out_D_real_cp[:, :, not_valid_idx_end[i] + 1:not_valid_idx_start[i+1]]), dim=2)\n","            out_D_real = torch.cat((out_D_real, out_D_real_cp[:, :, not_valid_idx_end[-1] + 1:]), dim=2)\n","            mask_ratio = tot_samples / out_D_real.shape[2]\n","        else:\n","            mask_ratio = 1\n","            out_D_real = netD(real_signal)\n","        err_real_D = -out_D_real.mean()\n","        err_real_D.backward(retain_graph=True)\n","        err_real_D = err_real_D.detach()\n","        if print_progress or plot_losses:\n","            err_real_D_val = err_real_D.item()\n","\n","        if epoch_num == 0:\n","            if run_mode == 'inpainting':\n","                D_out_shape = out_D_real.shape\n","                _grad_outputs = torch.ones(D_out_shape, device=device)\n","            if scale_idx == 0:  # We are at coarsest scale\n","                prev_signal = torch.full(noise_signal.shape, 0, device=device, dtype=noise_signal.dtype)\n","                prev_reconstructed_signal = torch.zeros(reconstruction_noise.shape, device=device)\n","                noise_amp = initial_noise_amp\n","            else:\n","                prev_signal = draw_signal(generators_list, inputs_lengths, fs_list, noise_amp_list, filter_size, dilation_factors, device)\n","                prev_signal = signal_padder(prev_signal)\n","                prev_reconstructed_signal = draw_signal(generators_list, inputs_lengths,\n","                                                        fs_list,\n","                                                        noise_amp_list, filter_size, dilation_factors, device,\n","                                                        reconstruction_noise_list)\n","                prev_reconstructed_signal = signal_padder(prev_reconstructed_signal)\n","                innovation = energy_list[scale_idx] - energy_list[scale_idx - 1]\n","                energy_diff = torch.sqrt(torch.Tensor([innovation])).to(device)\n","                noise_amp = noise_amp_factor * max(torch.Tensor([0]).to(device),\n","                                                          energy_diff)\n","\n","            if scale_idx == 1 and add_cond_noise:\n","                noise_amp = prev_reconstructed_signal.std()\n","\n","            with open(os.path.join(output_folder, 'log.txt'), 'a') as f:\n","                f.write('\\nnoise_amp: %.6f' % noise_amp)\n","\n","            reconstruction_noise = reconstruction_noise * noise_amp\n","            reconstruction_noise_list.append(reconstruction_noise)\n","        else:\n","            if scale_idx > 0:\n","                prev_signal = draw_signal(generators_list, inputs_lengths, fs_list, noise_amp_list, filter_size, dilation_factors, device)\n","                prev_signal = signal_padder(prev_signal)\n","\n","        input_noise = noise_signal * noise_amp\n","\n","        # Run on fake signal\n","        fake_signal = netG((input_noise + prev_signal).detach(), prev_signal)\n","        out_D_fake = netD(fake_signal.detach())\n","        err_fake_D = out_D_fake.mean()\n","        del out_D_real, out_D_fake\n","        err_fake_D.backward(retain_graph=True)\n","        err_fake_D = err_fake_D.detach()\n","        if print_progress or plot_losses:\n","            err_fake_D_val = err_fake_D.item()\n","\n","        lambda_grad=0.01\n","        gradient_penalty = calc_gradient_penalty(run_mode, current_holes, netD, real_signal, fake_signal, lambda_grad,\n","                                                 grad_pen_alpha_vec[epoch_num], _grad_outputs, mask_ratio)\n","        gradient_penalty.backward()\n","        if print_progress or plot_losses:\n","            gradient_penalty_val = gradient_penalty.item()\n","        del gradient_penalty\n","\n","        optimizerD.step()\n","\n","        if plot_losses:\n","            v_err_real[epoch_num] = err_real_D_val\n","            v_err_fake[epoch_num] = err_fake_D_val\n","            v_gp[epoch_num] = gradient_penalty_val\n","\n","        #############################################\n","        # Update G by maximizing D(G(noise_signal)) #\n","        #############################################\n","        netG.zero_grad()\n","        output = netD(fake_signal)\n","        errG = -output.mean()\n","        del output\n","        errG.backward(retain_graph=True)\n","        errG = errG.detach()\n","        if print_progress or plot_losses:\n","            errG_val = errG.item()\n","        if scale_idx == 0:\n","            reconstructed_signal = netG((reconstruction_noise + prev_reconstructed_signal).detach(),\n","                                        prev_reconstructed_signal)\n","        else:\n","            reconstructed_signal = netG((reconstruction_noise + prev_reconstructed_signal).detach(),\n","                                        prev_reconstructed_signal)\n","        if alpha1 > 0:\n","            if run_mode == 'inpainting':\n","                rec_loss_t = alpha1 * torch.mean(\n","                    (real_signal[:, :, current_mask] - reconstructed_signal[:, :, current_mask]) ** 2)\n","            else:\n","                rec_loss_t = alpha1 * torch.mean((real_signal - reconstructed_signal) ** 2)\n","        else:\n","            rec_loss_t = 0\n","        if alpha2 > 0:\n","            multispec_loss_n_fft = (2048, 1024, 512)\n","            multispec_loss_hop_length = (240, 120, 50)\n","            multispec_loss_window_size = (1200, 600, 240)\n","            rec_loss_f = alpha2 * multi_scale_spectrogram_loss(multispec_loss_n_fft, multispec_loss_hop_length, multispec_loss_window_size,\n","                                                               current_holes, real_signal.permute(0, 2, 1),reconstructed_signal.permute(0, 2, 1))\n","        else:\n","            rec_loss_f = 0\n","        rec_loss = rec_loss_t + rec_loss_f\n","        rec_loss.backward(retain_graph=True)\n","        rec_loss = rec_loss.detach()\n","        if alpha1 > 0:\n","            rec_loss_t = rec_loss_t.detach()\n","        if alpha2 > 0:\n","            rec_loss_f = rec_loss_f.detach()\n","        if print_progress or plot_losses:\n","            rec_loss_val = rec_loss.item()\n","\n","        optimizerG.step()\n","\n","        if plot_losses:\n","            v_rec_loss[epoch_num] = rec_loss_val\n","\n","        if print_progress:\n","            print('[%d/%d] D(real): %.2f. D(fake): %.2f. rec_loss: %.4f. gp: %.4f ' % (\n","                epoch_num, num_epochs, -err_real_D_val, err_fake_D_val, rec_loss_val, gradient_penalty_val))\n","\n","        schedulerD.step()\n","        schedulerG.step()\n","\n","        # Some memory cleanup\n","        fake_signal = fake_signal.detach()\n","        reconstructed_signal = reconstructed_signal.detach()\n","        if epoch_num < num_epochs - 1:\n","            del fake_signal, reconstructed_signal, rec_loss, rec_loss_t, rec_loss_f\n","        del noise_signal, input_noise\n","        if scale_idx > 0:\n","            del prev_signal\n","\n","    epochs_stop_time = time.time()\n","    runtime_msg = 'Total time in scale %d: %d[sec] (%.2f[sec]/epoch on avg.). D(real): %f, D(fake): %f, rec_loss: %.4f. gp: %.4f' % (\n","        current_scale, epochs_stop_time - epochs_start_time,\n","        (epochs_stop_time - epochs_start_time) / num_epochs,\n","        -err_real_D_val, err_fake_D_val, rec_loss_val, gradient_penalty_val)\n","    print(runtime_msg)\n","    with open(os.path.join(output_folder, 'log.txt'), 'a') as f:\n","        f.write('\\n%s\\n' % runtime_msg)\n","\n","    # Save this scale models\n","    torch.save(netG.state_dict(), '%s/netGScale%d.pth' % (output_folder, scale_idx))\n","    torch.save(netD.state_dict(), '%s/netDScale%d.pth' % (output_folder, scale_idx))\n","    # Pack outputs\n","    if plot_losses:\n","        loss_vectors = {'v_err_real': v_err_real,\n","                        'v_err_fake': v_err_fake,\n","                        'v_rec_loss': v_rec_loss,\n","                        'v_gp': v_gp}\n","    else:\n","        loss_vectors = []\n","    fake_signal = fake_signal.detach().cpu().numpy()[:, 0, :]\n","    reconstructed_signal = reconstructed_signal.detach().cpu().numpy()[:, 0, :]\n","    output_signals = {'fake_signal': fake_signal, 'reconstructed_signal': reconstructed_signal}\n","    del fake_signal, real_signal, netD, _grad_outputs, grad_pen_alpha_vec, input_signal, reconstructed_signal, prev_reconstructed_signal, reconstruction_noise\n","    netG = reset_grads(netG, False)\n","    netG.eval()\n","    if is_cuda:\n","        torch.cuda.empty_cache()\n","    print('*' * 30 + ' Finished working on scale ' + str(current_scale) + ' ' + '*' * 30)\n","    return output_signals, loss_vectors, netG, reconstruction_noise_list, noise_amp"],"metadata":{"id":"_r37Na9OBSA8","executionInfo":{"status":"ok","timestamp":1663242123898,"user_tz":-60,"elapsed":502,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["#training\n","startTime = time.time()\n","\n","if len(inpainting_indices)%2 != 0:\n","    raise Exception('Provide START and END indices of each hole!')\n","\n","if is_cuda:\n","    torch.cuda.set_device(gpu_num)\n","    device = torch.device(\"cuda:%d\" % gpu_num)\n","\n","if manual_random_seed != -1:\n","    random.seed(manual_random_seed)\n","    torch.manual_seed(manual_random_seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","samples, Fs = get_input_signal(input_file, max_length)\n","\n","fs_list = [f for f in fs_list if f <= Fs]\n","if fs_list[-1] != Fs:\n","    fs_list.append(Fs)\n","\n","scales = [Fs / f for f in fs_list]\n","\n","print('Working on file: %s' % input_file)\n","\n","scheduler_milestones = [int(num_epochs * 2 / 3)]\n","\n","alpha1 = 0\n","alpha2 = 1e-4\n","add_cond_noise = True\n","\n","dilation_factors = [2 ** i for i in range(num_layers)]\n","\n","if not os.path.exists(output_folder):\n","    os.mkdir(output_folder)\n","\n","if os.path.exists(output_folder):\n","    dirs = glob.glob(output_folder + '*')\n","    output_folder = output_folder + '_' + str(len(dirs) + 1)\n","\n","os.mkdir(output_folder)\n","print('Writing results to %s\\n' % output_folder)\n","\n","signals_list, fs_list = create_input_signals(scales, set_first_scale_by_energy, min_energy_th,  filter_size, torch.tensor(samples), Fs)\n","if len(signals_list) == 0:\n","    set_first_scale_by_energy = False\n","    scales = scales[2:]  # Manually start from 500\n","    signals_list, fs_list = create_input_signals(scales, set_first_scale_by_energy, min_energy_th,  filter_size, torch.tensor(samples), Fs)\n","scales = [Fs / f for f in fs_list]\n","\n","fs_list = fs_list\n","inputs_lengths = [len(s) for s in signals_list]\n","\n","print('Running on ' + str(device))\n","\n","output_signals, loss_vectors, generators_list, noise_amp_list, energy_list, reconstruction_noise_list = train(\n","                          manual_random_seed, fs_list, scales, growing_hidden_channels_factor,learning_rate, beta1, scheduler_lr_decay,\n","                          plot_losses, initial_noise_amp, noise_amp_factor, signals_list, dilation_factors, output_folder, inputs_lengths)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzV4gMXQZR92","outputId":"f5dfa6bd-4bc8-4e22-b765-8c32be52c876","executionInfo":{"status":"ok","timestamp":1663269582058,"user_tz":-60,"elapsed":27452722,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Working on file: S7_mono_UG.wav\n","Writing results to outputs_3\n","\n","Running on cuda:0\n","Signal in scale 15 has 8000 samples, sample rate is 320[Hz].\n","Total receptive field is 6378[msec] (25.5% of input).\n","[0/1500] D(real): 0.00. D(fake): 0.00. rec_loss: 0.0324. gp: 0.0075 \n","[100/1500] D(real): 0.00. D(fake): -0.05. rec_loss: 0.0210. gp: 0.0055 \n","[200/1500] D(real): 0.03. D(fake): -0.04. rec_loss: 0.0184. gp: 0.0148 \n","[300/1500] D(real): 0.03. D(fake): -0.04. rec_loss: 0.0181. gp: 0.0083 \n","[400/1500] D(real): -0.05. D(fake): -0.10. rec_loss: 0.0201. gp: 0.0108 \n","[500/1500] D(real): 0.02. D(fake): -0.10. rec_loss: 0.0186. gp: 0.0967 \n","[600/1500] D(real): -0.00. D(fake): -0.11. rec_loss: 0.0225. gp: 0.0361 \n","[700/1500] D(real): -0.16. D(fake): -0.23. rec_loss: 0.0208. gp: 0.0117 \n","[800/1500] D(real): 0.02. D(fake): -0.17. rec_loss: 0.0289. gp: 0.0626 \n","[900/1500] D(real): -0.02. D(fake): -0.23. rec_loss: 0.0243. gp: 0.0250 \n","[1000/1500] D(real): -0.17. D(fake): -0.28. rec_loss: 0.0235. gp: 0.0166 \n","[1100/1500] D(real): -0.03. D(fake): -0.26. rec_loss: 0.0214. gp: 0.0256 \n","[1200/1500] D(real): -0.05. D(fake): -0.30. rec_loss: 0.0209. gp: 0.0441 \n","[1300/1500] D(real): -0.02. D(fake): -0.26. rec_loss: 0.0189. gp: 0.1684 \n","[1400/1500] D(real): -0.07. D(fake): -0.24. rec_loss: 0.0222. gp: 0.0392 \n","Total time in scale 15: 57[sec] (0.04[sec]/epoch on avg.). D(real): -0.066998, D(fake): -0.240802, rec_loss: 0.0222. gp: 0.0392\n","****************************** Finished working on scale 15 ******************************\n","Signal in scale 14 has 10000 samples, sample rate is 400[Hz].\n","Total receptive field is 5102[msec] (20.4% of input).\n","[0/1500] D(real): 0.00. D(fake): 0.00. rec_loss: 0.0327. gp: 0.0082 \n","[100/1500] D(real): 0.08. D(fake): -0.01. rec_loss: 0.0301. gp: 0.0133 \n","[200/1500] D(real): 0.05. D(fake): 0.02. rec_loss: 0.0286. gp: 0.0057 \n","[300/1500] D(real): 0.06. D(fake): -0.06. rec_loss: 0.0299. gp: 0.0320 \n","[400/1500] D(real): 0.00. D(fake): -0.13. rec_loss: 0.0294. gp: 0.0340 \n","[500/1500] D(real): 0.06. D(fake): -0.14. rec_loss: 0.0325. gp: 0.0279 \n","[600/1500] D(real): -0.07. D(fake): -0.22. rec_loss: 0.0286. gp: 0.0882 \n","[700/1500] D(real): 0.05. D(fake): -0.18. rec_loss: 0.0293. gp: 0.1524 \n","[800/1500] D(real): -0.01. D(fake): -0.26. rec_loss: 0.0266. gp: 0.0138 \n","[900/1500] D(real): -0.16. D(fake): -0.27. rec_loss: 0.0277. gp: 0.0405 \n","[1000/1500] D(real): -0.04. D(fake): -0.23. rec_loss: 0.0262. gp: 0.0192 \n","[1100/1500] D(real): 0.00. D(fake): -0.21. rec_loss: 0.0259. gp: 0.0545 \n","[1200/1500] D(real): 0.01. D(fake): -0.25. rec_loss: 0.0261. gp: 0.1412 \n","[1300/1500] D(real): 0.02. D(fake): -0.31. rec_loss: 0.0248. gp: 0.2494 \n","[1400/1500] D(real): 0.02. D(fake): -0.32. rec_loss: 0.0237. gp: 0.0249 \n","Total time in scale 14: 145[sec] (0.10[sec]/epoch on avg.). D(real): 0.024257, D(fake): -0.315611, rec_loss: 0.0237. gp: 0.0249\n","****************************** Finished working on scale 14 ******************************\n","Signal in scale 13 has 12500 samples, sample rate is 500[Hz].\n","Total receptive field is 4082[msec] (16.3% of input).\n","[0/1500] D(real): -0.34. D(fake): -0.35. rec_loss: 0.0527. gp: 0.0910 \n","[100/1500] D(real): -0.09. D(fake): -0.27. rec_loss: 0.0319. gp: 0.0605 \n","[200/1500] D(real): -0.08. D(fake): -0.32. rec_loss: 0.0298. gp: 0.1939 \n","[300/1500] D(real): -0.06. D(fake): -0.25. rec_loss: 0.0317. gp: 0.0238 \n","[400/1500] D(real): -0.16. D(fake): -0.28. rec_loss: 0.0293. gp: 0.0531 \n","[500/1500] D(real): -0.04. D(fake): -0.17. rec_loss: 0.0307. gp: 0.0287 \n","[600/1500] D(real): -0.06. D(fake): -0.21. rec_loss: 0.0276. gp: 0.0189 \n","[700/1500] D(real): 0.04. D(fake): -0.14. rec_loss: 0.0273. gp: 0.0441 \n","[800/1500] D(real): 0.04. D(fake): -0.25. rec_loss: 0.0273. gp: 0.0149 \n","[900/1500] D(real): -0.09. D(fake): -0.23. rec_loss: 0.0261. gp: 0.0210 \n","[1000/1500] D(real): 0.04. D(fake): -0.21. rec_loss: 0.0270. gp: 0.0640 \n","[1100/1500] D(real): 0.05. D(fake): -0.23. rec_loss: 0.0244. gp: 0.0925 \n","[1200/1500] D(real): -0.02. D(fake): -0.26. rec_loss: 0.0245. gp: 0.1160 \n","[1300/1500] D(real): 0.01. D(fake): -0.28. rec_loss: 0.0241. gp: 0.1607 \n","[1400/1500] D(real): 0.01. D(fake): -0.26. rec_loss: 0.0243. gp: 0.2858 \n","Total time in scale 13: 197[sec] (0.13[sec]/epoch on avg.). D(real): 0.013318, D(fake): -0.264318, rec_loss: 0.0243. gp: 0.2858\n","****************************** Finished working on scale 13 ******************************\n","Signal in scale 12 has 16000 samples, sample rate is 640[Hz].\n","Total receptive field is 3189[msec] (12.8% of input).\n","[0/1500] D(real): -0.32. D(fake): -0.30. rec_loss: 0.0432. gp: 0.0577 \n","[100/1500] D(real): -0.23. D(fake): -0.34. rec_loss: 0.0319. gp: 0.0240 \n","[200/1500] D(real): -0.19. D(fake): -0.34. rec_loss: 0.0295. gp: 0.0384 \n","[300/1500] D(real): -0.27. D(fake): -0.36. rec_loss: 0.0280. gp: 0.0653 \n","[400/1500] D(real): -0.20. D(fake): -0.36. rec_loss: 0.0287. gp: 0.0275 \n","[500/1500] D(real): -0.36. D(fake): -0.42. rec_loss: 0.0268. gp: 0.0162 \n","[600/1500] D(real): -0.22. D(fake): -0.39. rec_loss: 0.0260. gp: 0.0925 \n","[700/1500] D(real): -0.25. D(fake): -0.41. rec_loss: 0.0259. gp: 0.0227 \n","[800/1500] D(real): -0.25. D(fake): -0.44. rec_loss: 0.0256. gp: 0.0375 \n","[900/1500] D(real): -0.27. D(fake): -0.42. rec_loss: 0.0250. gp: 0.0326 \n","[1000/1500] D(real): -0.15. D(fake): -0.35. rec_loss: 0.0251. gp: 0.0551 \n","[1100/1500] D(real): -0.12. D(fake): -0.36. rec_loss: 0.0230. gp: 0.0879 \n","[1200/1500] D(real): -0.12. D(fake): -0.40. rec_loss: 0.0229. gp: 0.0726 \n","[1300/1500] D(real): -0.09. D(fake): -0.42. rec_loss: 0.0227. gp: 0.1021 \n","[1400/1500] D(real): -0.13. D(fake): -0.46. rec_loss: 0.0227. gp: 0.0831 \n","Total time in scale 12: 250[sec] (0.17[sec]/epoch on avg.). D(real): -0.127759, D(fake): -0.458916, rec_loss: 0.0227. gp: 0.0831\n","****************************** Finished working on scale 12 ******************************\n","Signal in scale 11 has 20000 samples, sample rate is 800[Hz].\n","Total receptive field is 2551[msec] (10.2% of input).\n","[0/1500] D(real): -0.47. D(fake): -0.47. rec_loss: 0.0455. gp: 0.0915 \n","[100/1500] D(real): -0.22. D(fake): -0.31. rec_loss: 0.0301. gp: 0.0286 \n","[200/1500] D(real): -0.21. D(fake): -0.32. rec_loss: 0.0290. gp: 0.0580 \n","[300/1500] D(real): -0.23. D(fake): -0.37. rec_loss: 0.0280. gp: 0.0580 \n","[400/1500] D(real): -0.38. D(fake): -0.41. rec_loss: 0.0274. gp: 0.0197 \n","[500/1500] D(real): -0.23. D(fake): -0.36. rec_loss: 0.0267. gp: 0.0332 \n","[600/1500] D(real): -0.35. D(fake): -0.47. rec_loss: 0.0266. gp: 0.0191 \n","[700/1500] D(real): -0.24. D(fake): -0.34. rec_loss: 0.0260. gp: 0.0296 \n","[800/1500] D(real): -0.25. D(fake): -0.38. rec_loss: 0.0257. gp: 0.0245 \n","[900/1500] D(real): -0.17. D(fake): -0.31. rec_loss: 0.0247. gp: 0.0337 \n","[1000/1500] D(real): -0.15. D(fake): -0.28. rec_loss: 0.0243. gp: 0.1122 \n","[1100/1500] D(real): -0.12. D(fake): -0.28. rec_loss: 0.0230. gp: 0.0374 \n","[1200/1500] D(real): -0.10. D(fake): -0.30. rec_loss: 0.0227. gp: 0.1093 \n","[1300/1500] D(real): -0.09. D(fake): -0.32. rec_loss: 0.0226. gp: 0.2108 \n","[1400/1500] D(real): -0.08. D(fake): -0.32. rec_loss: 0.0225. gp: 0.1485 \n","Total time in scale 11: 322[sec] (0.21[sec]/epoch on avg.). D(real): -0.078607, D(fake): -0.316475, rec_loss: 0.0225. gp: 0.1485\n","****************************** Finished working on scale 11 ******************************\n","Signal in scale 10 has 25000 samples, sample rate is 1000[Hz].\n","Total receptive field is 2041[msec] (8.2% of input).\n","[0/1500] D(real): -0.39. D(fake): -0.39. rec_loss: 0.0428. gp: 0.0435 \n","[100/1500] D(real): -0.18. D(fake): -0.24. rec_loss: 0.0307. gp: 0.0177 \n","[200/1500] D(real): -0.10. D(fake): -0.19. rec_loss: 0.0304. gp: 0.0242 \n","[300/1500] D(real): -0.11. D(fake): -0.18. rec_loss: 0.0288. gp: 0.0196 \n","[400/1500] D(real): -0.05. D(fake): -0.10. rec_loss: 0.0275. gp: 0.0464 \n","[500/1500] D(real): -0.04. D(fake): -0.14. rec_loss: 0.0269. gp: 0.0734 \n","[600/1500] D(real): -0.02. D(fake): -0.14. rec_loss: 0.0272. gp: 0.0218 \n","[700/1500] D(real): -0.11. D(fake): -0.19. rec_loss: 0.0263. gp: 0.0101 \n","[800/1500] D(real): 0.04. D(fake): -0.08. rec_loss: 0.0257. gp: 0.0673 \n","[900/1500] D(real): 0.00. D(fake): -0.06. rec_loss: 0.0257. gp: 0.0224 \n","[1000/1500] D(real): 0.08. D(fake): -0.07. rec_loss: 0.0251. gp: 0.0539 \n","[1100/1500] D(real): 0.11. D(fake): -0.04. rec_loss: 0.0241. gp: 0.0891 \n","[1200/1500] D(real): 0.09. D(fake): -0.06. rec_loss: 0.0241. gp: 0.0952 \n","[1300/1500] D(real): 0.10. D(fake): -0.07. rec_loss: 0.0240. gp: 0.0416 \n","[1400/1500] D(real): 0.12. D(fake): -0.07. rec_loss: 0.0239. gp: 0.0651 \n","Total time in scale 10: 401[sec] (0.27[sec]/epoch on avg.). D(real): 0.120856, D(fake): -0.068303, rec_loss: 0.0239. gp: 0.0651\n","****************************** Finished working on scale 10 ******************************\n","Signal in scale 9 has 32000 samples, sample rate is 1280[Hz].\n","Total receptive field is 1594[msec] (6.4% of input).\n","[0/1500] D(real): -0.11. D(fake): -0.10. rec_loss: 0.0440. gp: 0.0399 \n","[100/1500] D(real): 0.11. D(fake): 0.06. rec_loss: 0.0303. gp: 0.0123 \n","[200/1500] D(real): 0.14. D(fake): 0.09. rec_loss: 0.0300. gp: 0.0206 \n","[300/1500] D(real): 0.11. D(fake): 0.05. rec_loss: 0.0284. gp: 0.0161 \n","[400/1500] D(real): 0.10. D(fake): 0.06. rec_loss: 0.0282. gp: 0.0271 \n","[500/1500] D(real): 0.08. D(fake): 0.03. rec_loss: 0.0285. gp: 0.0096 \n","[600/1500] D(real): 0.06. D(fake): -0.00. rec_loss: 0.0281. gp: 0.0106 \n","[700/1500] D(real): 0.18. D(fake): 0.10. rec_loss: 0.0268. gp: 0.0219 \n","[800/1500] D(real): 0.13. D(fake): 0.06. rec_loss: 0.0265. gp: 0.0174 \n","[900/1500] D(real): 0.10. D(fake): 0.03. rec_loss: 0.0267. gp: 0.0248 \n","[1000/1500] D(real): 0.01. D(fake): -0.02. rec_loss: 0.0260. gp: 0.0153 \n","[1100/1500] D(real): 0.03. D(fake): 0.00. rec_loss: 0.0253. gp: 0.0297 \n","[1200/1500] D(real): 0.06. D(fake): 0.02. rec_loss: 0.0249. gp: 0.0165 \n","[1300/1500] D(real): 0.06. D(fake): 0.03. rec_loss: 0.0247. gp: 0.0159 \n","[1400/1500] D(real): 0.07. D(fake): 0.03. rec_loss: 0.0245. gp: 0.0098 \n","Total time in scale 9: 509[sec] (0.34[sec]/epoch on avg.). D(real): 0.074647, D(fake): 0.028522, rec_loss: 0.0245. gp: 0.0098\n","****************************** Finished working on scale 9 ******************************\n","Signal in scale 8 has 40000 samples, sample rate is 1600[Hz].\n","Total receptive field is 1275[msec] (5.1% of input).\n","[0/1500] D(real): 0.00. D(fake): -0.01. rec_loss: 0.0453. gp: 0.0261 \n","[100/1500] D(real): 0.12. D(fake): 0.08. rec_loss: 0.0305. gp: 0.0093 \n","[200/1500] D(real): 0.18. D(fake): 0.13. rec_loss: 0.0289. gp: 0.0069 \n","[300/1500] D(real): 0.14. D(fake): 0.09. rec_loss: 0.0290. gp: 0.0058 \n","[400/1500] D(real): 0.21. D(fake): 0.15. rec_loss: 0.0275. gp: 0.0255 \n","[500/1500] D(real): 0.13. D(fake): 0.07. rec_loss: 0.0277. gp: 0.0197 \n","[600/1500] D(real): 0.18. D(fake): 0.06. rec_loss: 0.0278. gp: 0.0434 \n","[700/1500] D(real): 0.23. D(fake): 0.11. rec_loss: 0.0281. gp: 0.0698 \n","[800/1500] D(real): 0.20. D(fake): 0.12. rec_loss: 0.0263. gp: 0.0204 \n","[900/1500] D(real): 0.11. D(fake): -0.01. rec_loss: 0.0273. gp: 0.0293 \n","[1000/1500] D(real): 0.16. D(fake): 0.01. rec_loss: 0.0260. gp: 0.0372 \n","[1100/1500] D(real): 0.12. D(fake): -0.02. rec_loss: 0.0248. gp: 0.0378 \n","[1200/1500] D(real): 0.11. D(fake): -0.05. rec_loss: 0.0245. gp: 0.0419 \n","[1300/1500] D(real): 0.10. D(fake): -0.03. rec_loss: 0.0247. gp: 0.0486 \n","[1400/1500] D(real): 0.17. D(fake): -0.03. rec_loss: 0.0252. gp: 0.0616 \n","Total time in scale 8: 626[sec] (0.42[sec]/epoch on avg.). D(real): 0.168471, D(fake): -0.034962, rec_loss: 0.0252. gp: 0.0616\n","****************************** Finished working on scale 8 ******************************\n","Signal in scale 7 has 50000 samples, sample rate is 2000[Hz].\n","Total receptive field is 1020[msec] (4.1% of input).\n","[0/1500] D(real): -0.12. D(fake): -0.10. rec_loss: 0.0551. gp: 0.0426 \n","[100/1500] D(real): 0.03. D(fake): -0.01. rec_loss: 0.0334. gp: 0.0223 \n","[200/1500] D(real): -0.12. D(fake): -0.13. rec_loss: 0.0315. gp: 0.0130 \n","[300/1500] D(real): -0.04. D(fake): -0.08. rec_loss: 0.0306. gp: 0.0334 \n","[400/1500] D(real): -0.11. D(fake): -0.13. rec_loss: 0.0302. gp: 0.0138 \n","[500/1500] D(real): -0.00. D(fake): -0.09. rec_loss: 0.0304. gp: 0.0308 \n","[600/1500] D(real): -0.00. D(fake): -0.08. rec_loss: 0.0297. gp: 0.0330 \n","[700/1500] D(real): -0.07. D(fake): -0.10. rec_loss: 0.0280. gp: 0.0062 \n","[800/1500] D(real): -0.04. D(fake): -0.10. rec_loss: 0.0280. gp: 0.0181 \n","[900/1500] D(real): -0.01. D(fake): -0.09. rec_loss: 0.0278. gp: 0.0363 \n","[1000/1500] D(real): -0.01. D(fake): -0.08. rec_loss: 0.0274. gp: 0.0170 \n","[1100/1500] D(real): -0.01. D(fake): -0.11. rec_loss: 0.0266. gp: 0.0195 \n","[1200/1500] D(real): 0.00. D(fake): -0.11. rec_loss: 0.0265. gp: 0.0308 \n","[1300/1500] D(real): 0.01. D(fake): -0.13. rec_loss: 0.0264. gp: 0.0382 \n","[1400/1500] D(real): 0.00. D(fake): -0.12. rec_loss: 0.0265. gp: 0.0236 \n","Total time in scale 7: 786[sec] (0.52[sec]/epoch on avg.). D(real): 0.000118, D(fake): -0.121031, rec_loss: 0.0265. gp: 0.0236\n","****************************** Finished working on scale 7 ******************************\n","Signal in scale 6 has 62500 samples, sample rate is 2500[Hz].\n","Total receptive field is 816[msec] (3.3% of input).\n","[0/1500] D(real): -0.18. D(fake): -0.19. rec_loss: 0.0470. gp: 0.0265 \n","[100/1500] D(real): -0.12. D(fake): -0.17. rec_loss: 0.0322. gp: 0.0259 \n","[200/1500] D(real): -0.18. D(fake): -0.22. rec_loss: 0.0335. gp: 0.0146 \n","[300/1500] D(real): -0.17. D(fake): -0.20. rec_loss: 0.0315. gp: 0.0139 \n","[400/1500] D(real): -0.16. D(fake): -0.22. rec_loss: 0.0312. gp: 0.0252 \n","[500/1500] D(real): -0.18. D(fake): -0.23. rec_loss: 0.0314. gp: 0.0162 \n","[600/1500] D(real): -0.14. D(fake): -0.20. rec_loss: 0.0304. gp: 0.0201 \n","[700/1500] D(real): -0.10. D(fake): -0.17. rec_loss: 0.0304. gp: 0.0200 \n","[800/1500] D(real): -0.09. D(fake): -0.16. rec_loss: 0.0334. gp: 0.0179 \n","[900/1500] D(real): -0.11. D(fake): -0.16. rec_loss: 0.0295. gp: 0.0104 \n","[1000/1500] D(real): -0.11. D(fake): -0.14. rec_loss: 0.0300. gp: 0.0058 \n","[1100/1500] D(real): -0.08. D(fake): -0.12. rec_loss: 0.0289. gp: 0.0142 \n","[1200/1500] D(real): -0.05. D(fake): -0.10. rec_loss: 0.0288. gp: 0.0365 \n","[1300/1500] D(real): -0.04. D(fake): -0.14. rec_loss: 0.0288. gp: 0.0235 \n","[1400/1500] D(real): -0.03. D(fake): -0.15. rec_loss: 0.0288. gp: 0.0248 \n","Total time in scale 6: 986[sec] (0.66[sec]/epoch on avg.). D(real): -0.032483, D(fake): -0.149451, rec_loss: 0.0288. gp: 0.0248\n","****************************** Finished working on scale 6 ******************************\n","Signal in scale 5 has 100000 samples, sample rate is 4000[Hz].\n","Total receptive field is 510[msec] (2.0% of input).\n","[0/1500] D(real): -0.20. D(fake): -0.21. rec_loss: 0.0631. gp: 0.0634 \n","[100/1500] D(real): -0.10. D(fake): -0.12. rec_loss: 0.0440. gp: 0.0106 \n","[200/1500] D(real): -0.05. D(fake): -0.08. rec_loss: 0.0428. gp: 0.0162 \n","[300/1500] D(real): -0.08. D(fake): -0.10. rec_loss: 0.0434. gp: 0.0095 \n","[400/1500] D(real): -0.01. D(fake): -0.05. rec_loss: 0.0419. gp: 0.0092 \n","[500/1500] D(real): -0.10. D(fake): -0.11. rec_loss: 0.0418. gp: 0.0062 \n","[600/1500] D(real): -0.00. D(fake): -0.02. rec_loss: 0.0404. gp: 0.0154 \n","[700/1500] D(real): -0.03. D(fake): -0.09. rec_loss: 0.0413. gp: 0.0088 \n","[800/1500] D(real): 0.00. D(fake): -0.04. rec_loss: 0.0399. gp: 0.0093 \n","[900/1500] D(real): -0.06. D(fake): -0.09. rec_loss: 0.0400. gp: 0.0067 \n","[1000/1500] D(real): -0.04. D(fake): -0.06. rec_loss: 0.0385. gp: 0.0108 \n","[1100/1500] D(real): 0.01. D(fake): -0.05. rec_loss: 0.0380. gp: 0.0458 \n","[1200/1500] D(real): -0.02. D(fake): -0.10. rec_loss: 0.0383. gp: 0.0912 \n","[1300/1500] D(real): 0.01. D(fake): -0.07. rec_loss: 0.0380. gp: 0.0154 \n","[1400/1500] D(real): 0.00. D(fake): -0.09. rec_loss: 0.0382. gp: 0.0191 \n","Total time in scale 5: 1479[sec] (0.99[sec]/epoch on avg.). D(real): 0.003635, D(fake): -0.091334, rec_loss: 0.0382. gp: 0.0191\n","****************************** Finished working on scale 5 ******************************\n","Signal in scale 4 has 200000 samples, sample rate is 8000[Hz].\n","Total receptive field is 255[msec] (1.0% of input).\n","[0/1500] D(real): -0.14. D(fake): -0.13. rec_loss: 0.0892. gp: 0.0243 \n","[100/1500] D(real): -0.01. D(fake): -0.02. rec_loss: 0.0681. gp: 0.0071 \n","[200/1500] D(real): 0.02. D(fake): 0.01. rec_loss: 0.0671. gp: 0.0109 \n","[300/1500] D(real): 0.02. D(fake): 0.01. rec_loss: 0.0651. gp: 0.0070 \n","[400/1500] D(real): 0.00. D(fake): -0.01. rec_loss: 0.0637. gp: 0.0069 \n","[500/1500] D(real): 0.05. D(fake): 0.02. rec_loss: 0.0645. gp: 0.0077 \n","[600/1500] D(real): 0.02. D(fake): -0.01. rec_loss: 0.0615. gp: 0.0087 \n","[700/1500] D(real): -0.01. D(fake): -0.04. rec_loss: 0.0599. gp: 0.0083 \n","[800/1500] D(real): 0.01. D(fake): 0.00. rec_loss: 0.0588. gp: 0.0046 \n","[900/1500] D(real): 0.03. D(fake): 0.01. rec_loss: 0.0565. gp: 0.0070 \n","[1000/1500] D(real): 0.03. D(fake): 0.01. rec_loss: 0.0544. gp: 0.0058 \n","[1100/1500] D(real): 0.02. D(fake): -0.00. rec_loss: 0.0530. gp: 0.0076 \n","[1200/1500] D(real): 0.02. D(fake): -0.02. rec_loss: 0.0529. gp: 0.0061 \n","[1300/1500] D(real): 0.03. D(fake): -0.01. rec_loss: 0.0527. gp: 0.0095 \n","[1400/1500] D(real): 0.03. D(fake): -0.01. rec_loss: 0.0528. gp: 0.0107 \n","Total time in scale 4: 2780[sec] (1.85[sec]/epoch on avg.). D(real): 0.030301, D(fake): -0.006010, rec_loss: 0.0528. gp: 0.0107\n","****************************** Finished working on scale 4 ******************************\n","Signal in scale 3 has 250000 samples, sample rate is 10000[Hz].\n","Total receptive field is 204[msec] (0.8% of input).\n","[0/1500] D(real): -0.02. D(fake): -0.03. rec_loss: 0.0894. gp: 0.0130 \n","[100/1500] D(real): -0.03. D(fake): -0.04. rec_loss: 0.0649. gp: 0.0057 \n","[200/1500] D(real): 0.00. D(fake): -0.01. rec_loss: 0.0641. gp: 0.0050 \n","[300/1500] D(real): -0.00. D(fake): -0.02. rec_loss: 0.0643. gp: 0.0060 \n","[400/1500] D(real): 0.01. D(fake): -0.02. rec_loss: 0.0639. gp: 0.0198 \n","[500/1500] D(real): 0.03. D(fake): 0.01. rec_loss: 0.0632. gp: 0.0058 \n","[600/1500] D(real): 0.05. D(fake): 0.03. rec_loss: 0.0628. gp: 0.0165 \n","[700/1500] D(real): 0.03. D(fake): -0.01. rec_loss: 0.0624. gp: 0.0203 \n","[800/1500] D(real): 0.06. D(fake): 0.03. rec_loss: 0.0622. gp: 0.0173 \n","[900/1500] D(real): 0.08. D(fake): 0.05. rec_loss: 0.0606. gp: 0.0180 \n","[1000/1500] D(real): 0.09. D(fake): 0.05. rec_loss: 0.0619. gp: 0.0079 \n","[1100/1500] D(real): 0.08. D(fake): 0.03. rec_loss: 0.0599. gp: 0.0148 \n","[1200/1500] D(real): 0.06. D(fake): 0.02. rec_loss: 0.0600. gp: 0.0090 \n","[1300/1500] D(real): 0.07. D(fake): 0.03. rec_loss: 0.0599. gp: 0.0246 \n","[1400/1500] D(real): 0.07. D(fake): 0.01. rec_loss: 0.0600. gp: 0.0097 \n","Total time in scale 3: 3514[sec] (2.34[sec]/epoch on avg.). D(real): 0.065890, D(fake): 0.011387, rec_loss: 0.0600. gp: 0.0097\n","****************************** Finished working on scale 3 ******************************\n","Signal in scale 2 has 300000 samples, sample rate is 12000[Hz].\n","Total receptive field is 170[msec] (0.7% of input).\n","[0/1500] D(real): -0.01. D(fake): -0.01. rec_loss: 0.0886. gp: 0.0065 \n","[100/1500] D(real): 0.01. D(fake): -0.02. rec_loss: 0.0730. gp: 0.0059 \n","[200/1500] D(real): 0.05. D(fake): 0.02. rec_loss: 0.0715. gp: 0.0054 \n","[300/1500] D(real): 0.01. D(fake): 0.00. rec_loss: 0.0705. gp: 0.0053 \n","[400/1500] D(real): 0.05. D(fake): 0.02. rec_loss: 0.0699. gp: 0.0076 \n","[500/1500] D(real): 0.05. D(fake): 0.02. rec_loss: 0.0703. gp: 0.0097 \n","[600/1500] D(real): 0.08. D(fake): 0.04. rec_loss: 0.0694. gp: 0.0106 \n","[700/1500] D(real): 0.07. D(fake): 0.04. rec_loss: 0.0696. gp: 0.0109 \n","[800/1500] D(real): 0.07. D(fake): 0.03. rec_loss: 0.0686. gp: 0.0114 \n","[900/1500] D(real): 0.05. D(fake): 0.02. rec_loss: 0.0685. gp: 0.0090 \n","[1000/1500] D(real): 0.06. D(fake): 0.04. rec_loss: 0.0682. gp: 0.0096 \n","[1100/1500] D(real): 0.07. D(fake): 0.03. rec_loss: 0.0675. gp: 0.0092 \n","[1200/1500] D(real): 0.07. D(fake): 0.02. rec_loss: 0.0673. gp: 0.0066 \n","[1300/1500] D(real): 0.07. D(fake): 0.01. rec_loss: 0.0673. gp: 0.0189 \n","[1400/1500] D(real): 0.04. D(fake): -0.01. rec_loss: 0.0679. gp: 0.0067 \n","Total time in scale 2: 4284[sec] (2.86[sec]/epoch on avg.). D(real): 0.036786, D(fake): -0.006274, rec_loss: 0.0679. gp: 0.0067\n","****************************** Finished working on scale 2 ******************************\n","Signal in scale 1 has 360000 samples, sample rate is 14400[Hz].\n","Total receptive field is 141[msec] (0.6% of input).\n","[0/1500] D(real): -0.01. D(fake): -0.01. rec_loss: 0.0903. gp: 0.0154 \n","[100/1500] D(real): 0.00. D(fake): -0.02. rec_loss: 0.0810. gp: 0.0062 \n","[200/1500] D(real): -0.01. D(fake): -0.03. rec_loss: 0.0806. gp: 0.0055 \n","[300/1500] D(real): 0.04. D(fake): 0.00. rec_loss: 0.0799. gp: 0.0078 \n","[400/1500] D(real): 0.04. D(fake): 0.02. rec_loss: 0.0790. gp: 0.0106 \n","[500/1500] D(real): 0.02. D(fake): 0.02. rec_loss: 0.0803. gp: 0.0106 \n","[600/1500] D(real): 0.06. D(fake): 0.02. rec_loss: 0.0784. gp: 0.0108 \n","[700/1500] D(real): 0.05. D(fake): 0.03. rec_loss: 0.0774. gp: 0.0066 \n","[800/1500] D(real): -0.02. D(fake): -0.02. rec_loss: 0.0777. gp: 0.0042 \n","[900/1500] D(real): 0.05. D(fake): 0.03. rec_loss: 0.0764. gp: 0.0104 \n","[1000/1500] D(real): 0.05. D(fake): 0.02. rec_loss: 0.0757. gp: 0.0112 \n","[1100/1500] D(real): 0.07. D(fake): 0.03. rec_loss: 0.0747. gp: 0.0092 \n","[1200/1500] D(real): 0.05. D(fake): 0.01. rec_loss: 0.0747. gp: 0.0057 \n","[1300/1500] D(real): 0.08. D(fake): 0.02. rec_loss: 0.0750. gp: 0.0233 \n","[1400/1500] D(real): 0.09. D(fake): 0.02. rec_loss: 0.0747. gp: 0.0062 \n","Total time in scale 1: 5187[sec] (3.46[sec]/epoch on avg.). D(real): 0.085881, D(fake): 0.022885, rec_loss: 0.0747. gp: 0.0062\n","****************************** Finished working on scale 1 ******************************\n","Signal in scale 0 has 400000 samples, sample rate is 16000[Hz].\n","Total receptive field is 127[msec] (0.5% of input).\n","[0/1500] D(real): 0.01. D(fake): -0.00. rec_loss: 0.0945. gp: 0.0053 \n","[100/1500] D(real): 0.02. D(fake): -0.00. rec_loss: 0.0885. gp: 0.0149 \n","[200/1500] D(real): 0.02. D(fake): -0.01. rec_loss: 0.0846. gp: 0.0230 \n","[300/1500] D(real): 0.00. D(fake): -0.00. rec_loss: 0.0834. gp: 0.0048 \n","[400/1500] D(real): 0.04. D(fake): -0.01. rec_loss: 0.0827. gp: 0.0092 \n","[500/1500] D(real): 0.01. D(fake): 0.00. rec_loss: 0.0818. gp: 0.0051 \n","[600/1500] D(real): 0.05. D(fake): 0.02. rec_loss: 0.0811. gp: 0.0103 \n","[700/1500] D(real): 0.04. D(fake): 0.02. rec_loss: 0.0809. gp: 0.0073 \n","[800/1500] D(real): 0.02. D(fake): 0.02. rec_loss: 0.0799. gp: 0.0056 \n","[900/1500] D(real): 0.04. D(fake): 0.03. rec_loss: 0.0792. gp: 0.0047 \n","[1000/1500] D(real): 0.09. D(fake): 0.03. rec_loss: 0.0793. gp: 0.1580 \n","[1100/1500] D(real): 0.05. D(fake): 0.01. rec_loss: 0.0772. gp: 0.0065 \n","[1200/1500] D(real): 0.06. D(fake): 0.01. rec_loss: 0.0771. gp: 0.0199 \n","[1300/1500] D(real): 0.06. D(fake): 0.01. rec_loss: 0.0768. gp: 0.0074 \n","[1400/1500] D(real): 0.08. D(fake): 0.02. rec_loss: 0.0765. gp: 0.0074 \n","Total time in scale 0: 5909[sec] (3.94[sec]/epoch on avg.). D(real): 0.082610, D(fake): 0.016497, rec_loss: 0.0765. gp: 0.0074\n","****************************** Finished working on scale 0 ******************************\n"]}]},{"cell_type":"code","source":["#!zip -r outputs.zip outputs_2"],"metadata":{"id":"bBY1GNTZpbgP","executionInfo":{"status":"ok","timestamp":1663238362166,"user_tz":-60,"elapsed":6,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class AudioGenerator(object):\n","    def __init__(self, output_folder, fs_list, dilation_factors, filter_size, device, generators_list=None, noise_amp_list=None, reconstruction_noise_list=None):\n","        super(AudioGenerator, self).__init__()\n","        self.generators_list = generators_list\n","        self.noise_amp_list = noise_amp_list\n","        self.reconstruction_noise_list = reconstruction_noise_list\n","        self.output_folder = output_folder\n","        self.fs_list= fs_list\n","        self.device = device\n","        self.dilation_factors = dilation_factors\n","        self.filter_size = filter_size\n","        if not os.path.exists(os.path.join(output_folder, 'GeneratedSignals')):\n","            os.mkdir(os.path.join(output_folder, 'GeneratedSignals'))\n","\n","    def generate(self, nSignals=1, length=20, generate_all_scales=False):\n","        for sig_idx in range(nSignals):\n","            # Draws a signal up to current scale, using learned generators\n","            output_signals_list = draw_signal(self.generators_list,\n","                                              [round(f * length) for f in self.fs_list], self.fs_list,\n","                                              self.noise_amp_list,  self.filter_size, self.dilation_factors, self.device, \n","                                              output_all_scales=generate_all_scales)\n","            # Write signals\n","            if generate_all_scales:\n","                for scale_idx, sig in enumerate(output_signals_list):\n","                    write_signal(\n","                        os.path.join(self.output_folder, 'GeneratedSignals',\n","                                     'generated@%dHz.wav' % self.fs_list[scale_idx]),\n","                        sig, self.fs_list[scale_idx], overwrite=False)\n","            else:\n","                write_signal(\n","                    os.path.join(self.output_folder, 'GeneratedSignals',\n","                                 'generated@%dHz.wav' % self.fs_list[-1]),\n","                    output_signals_list, self.fs_list[-1], overwrite=False)\n","\n","    def condition(self, condition, write=True):\n","        condition[\"condition_scale_idx\"] = np.where(np.array(self.fs_list) <= condition[\"condition_fs\"])[0][\n","                                               -1] + 1\n","        condition[\"condition_signal\"] = torch.Tensor(condition[\"condition_signal\"]).expand(1, 1, -1).to(\n","            self.device)\n","        lengths = [int(condition[\"condition_signal\"].shape[2] / condition[\"condition_fs\"] * fs) for fs in\n","                   self.fs_list]\n","        conditioned_signal = draw_signal(self.generators_list, lengths, self.fs_list, self.noise_amp_list, \n","                                         self.filter_size, self.dilation_factors, self.device,\n","                                         condition=condition)\n","        if write:\n","            output_file = os.path.join(self.output_folder, 'GeneratedSignals',\n","                                       'conditioned_on_' + condition['name'])\n","            write_signal(output_file, conditioned_signal, self.params.Fs)\n","        else:\n","            return conditioned_signal"],"metadata":{"id":"pfWK4VohjG0Z","executionInfo":{"status":"ok","timestamp":1663269625394,"user_tz":-60,"elapsed":273,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["nSignals=1\n","length=25\n","generate_all_scales=False\n","\n","audio_generator = AudioGenerator(output_folder, fs_list, dilation_factors, filter_size, device, generators_list, noise_amp_list,\n","                                 reconstruction_noise_list=reconstruction_noise_list)\n","\n","audio_generator.generate(nSignals=nSignals, length=length,generate_all_scales=generate_all_scales)"],"metadata":{"id":"2XgcJ9x-zq06","executionInfo":{"status":"ok","timestamp":1663269629079,"user_tz":-60,"elapsed":1173,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["path = \"/content/outputs_2/GeneratedSignals\""],"metadata":{"id":"W_HyF3o0kkHQ","executionInfo":{"status":"ok","timestamp":1663269631433,"user_tz":-60,"elapsed":529,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["paths = []\n","size = 0\n","for root, dirs, files in os.walk(path):\n","    for file in files:\n","        if (file.endswith(\".wav\") and  (not (file.startswith(\".\") or file.startswith(\"noise\")))):\n","             paths.append(os.path.join(root, file))\n","             size += os.path.getsize(os.path.join(root, file))\n","             \n","\n","\n","print(f'We have {len(paths)} .Wav Files with {size/1024**2:.2f} Mb in size')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wLMleJ-vk2oB","executionInfo":{"status":"ok","timestamp":1663269633086,"user_tz":-60,"elapsed":339,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}},"outputId":"cf1e7ad1-5951-4064-b3f8-d81ffc1bb3c7"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["We have 1 .Wav Files with 0.76 Mb in size\n"]}]},{"cell_type":"code","source":["!!zip -r /content/outputs_2/GeneratedSignals.zip /content/outputs_2/GeneratedSignals"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWO_wzVto6df","executionInfo":{"status":"ok","timestamp":1663269635262,"user_tz":-60,"elapsed":279,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}},"outputId":"80541a13-c314-48e6-e73d-c47a9b7f5d95"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['updating: content/outputs_2/GeneratedSignals/ (stored 0%)',\n"," 'updating: content/outputs_2/GeneratedSignals/generated@16000Hz.wav (deflated 6%)']"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["from google.colab import files\n","files.download('/content/outputs_2/GeneratedSignals.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"T112qY4jpfmr","executionInfo":{"status":"ok","timestamp":1663269638825,"user_tz":-60,"elapsed":365,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}},"outputId":"92c011fe-7ecb-4ca3-c44a-35afd5b098e3"},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_c39f23a5-3406-43c5-8ca4-db3d707a4b91\", \"GeneratedSignals.zip\", 753110)"]},"metadata":{}}]},{"cell_type":"code","source":["!cp /content/outputs_2/GeneratedSignals.zip  /content/drive/MyDrive/FinalProject/CAW_outputs"],"metadata":{"id":"7aCyKbHdaDnH","executionInfo":{"status":"ok","timestamp":1663269643375,"user_tz":-60,"elapsed":2,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["# Remember to change this path everything you do generation ok"],"metadata":{"id":"-Du88qF5aFIw"}},{"cell_type":"code","source":[],"metadata":{"id":"ruT6IPL-aKZn","executionInfo":{"status":"ok","timestamp":1663238364117,"user_tz":-60,"elapsed":8,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"execution_count":18,"outputs":[]}]}