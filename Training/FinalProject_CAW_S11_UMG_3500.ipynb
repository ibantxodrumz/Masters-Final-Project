{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":123796,"status":"ok","timestamp":1663270207719,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"},"user_tz":-60},"id":"dg-Zaz71X5ao","outputId":"da22897b-5d24-4ad1-d641-027190344766"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.2 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (4.1.1)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: librosa==0.8.1 in /usr/local/lib/python3.7/dist-packages (0.8.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (1.21.6)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (1.6.0)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (1.1.0)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (3.0.0)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (4.4.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (21.3)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (1.7.3)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (1.0.2)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (0.56.2)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (0.4.0)\n","Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1) (0.10.3.post1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.8.1) (4.12.0)\n","Requirement already satisfied: setuptools<60 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.8.1) (57.4.0)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.8.1) (0.39.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa==0.8.1) (3.0.9)\n","Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.1) (1.4.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.1) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (2.10)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.1) (3.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa==0.8.1) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.8.1) (2.21)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.43.0->librosa==0.8.1) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.43.0->librosa==0.8.1) (3.8.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting soundfile==0.10.2\n","  Downloading SoundFile-0.10.2-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile==0.10.2) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile==0.10.2) (2.21)\n","Installing collected packages: soundfile\n","  Attempting uninstall: soundfile\n","    Found existing installation: SoundFile 0.10.3.post1\n","    Uninstalling SoundFile-0.10.3.post1:\n","      Successfully uninstalled SoundFile-0.10.3.post1\n","Successfully installed soundfile-0.10.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bokeh==2.3.0\n","  Downloading bokeh-2.3.0.tar.gz (10.6 MB)\n","\u001b[K     |████████████████████████████████| 10.6 MB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (6.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (2.8.2)\n","Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (2.11.3)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (1.21.6)\n","Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (7.1.2)\n","Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (21.3)\n","Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (5.1.1)\n","Requirement already satisfied: typing_extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh==2.3.0) (4.1.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.7->bokeh==2.3.0) (2.0.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh==2.3.0) (3.0.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh==2.3.0) (1.15.0)\n","Building wheels for collected packages: bokeh\n","  Building wheel for bokeh (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bokeh: filename=bokeh-2.3.0-py3-none-any.whl size=11292273 sha256=f1ca589296d36f7c395d6c9e5a60fe75ada394be4d4621fc10c5c5b689a5439a\n","  Stored in directory: /root/.cache/pip/wheels/fe/2b/67/993b844d1b11a6129b91880955c1b315438d00fc39d2dcf489\n","Successfully built bokeh\n","Installing collected packages: bokeh\n","  Attempting uninstall: bokeh\n","    Found existing installation: bokeh 2.3.3\n","    Uninstalling bokeh-2.3.3:\n","      Successfully uninstalled bokeh-2.3.3\n","Successfully installed bokeh-2.3.0\n"]}],"source":["!pip install torch==1.9.0\n","!pip install librosa==0.8.1\n","!pip install soundfile==0.10.2\n","!pip install bokeh==2.3.0"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"jkAW3HWGajZj","executionInfo":{"status":"ok","timestamp":1663270210286,"user_tz":-60,"elapsed":2571,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"outputs":[],"source":["import torch\n","import librosa\n","import soundfile as sf\n","import torch.nn as nn\n","import numpy as np\n","from torch.nn.utils import weight_norm\n","from torch import optim\n","from math import ceil\n","import glob\n","import time\n","import random\n","import os"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22662,"status":"ok","timestamp":1663270232944,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"},"user_tz":-60},"id":"LqIHLYluDlVe","outputId":"0a1ad1e8-f92e-4a31-97d2-a5b82655a0a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["#Connect colab to your google drive\n","from google.colab import drive\n","drive.mount('/gdrive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2501,"status":"ok","timestamp":1663270235440,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"},"user_tz":-60},"id":"2-dJwYs_iAkN","outputId":"4ffc8319-39e3-48a7-e2d9-bef5a0568a4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"SajXpcQKDUgM","executionInfo":{"status":"ok","timestamp":1663270236031,"user_tz":-60,"elapsed":594,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"outputs":[],"source":["#prepare input folder\n","input_folder='inputs'\n","if not os.path.exists(input_folder):\n","    os.mkdir(input_folder)\n","#copy file from drive to colab --remember it has to be from mydrive---for whatever reason it does not go any deeper!\n","!cp /content/drive/MyDrive/S11_ucm_1_mono.wav /content/inputs"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"4q0K6-KXcxmO","executionInfo":{"status":"ok","timestamp":1663270236032,"user_tz":-60,"elapsed":4,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"outputs":[],"source":["#paramaters\n","inpainting_indices= [0, 1]\n","is_cuda = torch.cuda.is_available()\n","gpu_num = 0\n","manual_random_seed = -1\n","input_file = 'S11_ucm_1_mono.wav'\n","segments_to_train = []\n","start_time = 0\n","init_sample_rate =  16000\n","fs_list = [320, 400, 500, 640, 800, 1000, 1280, 1600, 2000, 2500, 4000, 8000, 10000, 12000, 14400, 16000]\n","max_length = 25\n","run_mode = 'normal' #['normal', 'inpainting', 'denoising']\n","num_epochs = 3500\n","learning_rate = 0.0015\n","scheduler_lr_decay = 0.1\n","beta1 = 0.5\n","speech = False\n","num_layers = 8\n","output_folder = 'outputs'\n","filter_size = 9\n","set_first_scale_by_energy = True\n","min_energy_th = 0.0025\n","hidden_channels_init = 16\n","growing_hidden_channels_factor = 6\n","plot_losses = False\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","initial_noise_amp = 1\n","noise_amp_factor = 0.01"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"bELoeAltdEdB","executionInfo":{"status":"ok","timestamp":1663270236418,"user_tz":-60,"elapsed":389,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"outputs":[],"source":["#functions\n","def get_input_signal(input_file, max_length):\n","    file_name = input_file.split('.')\n","    if len(file_name) < 2:\n","        input_file = '.'.join([input_file, 'wav'])\n","    output_folder = file_name[0].replace(' ', '_')\n","    if len(segments_to_train) == 0:\n","        samples, Fs = librosa.load(os.path.join('inputs', input_file), sr=None,\n","                                   offset=start_time, duration=2 * max_length)\n","\n","    if samples.shape[0] / Fs > max_length:\n","        n_samples = int(max_length * Fs)\n","        samples = samples[:n_samples]\n","\n","    output_folder = output_folder\n","    output_folder = os.path.join('outputs', output_folder)\n","    Fs = Fs\n","    if init_sample_rate < Fs:\n","        hr_samples = samples.copy()\n","        samples = librosa.resample(hr_samples, Fs, init_sample_rate)\n","        Fs = init_sample_rate\n","    norm_factor = max(abs(samples.reshape(-1)))\n","    samples = samples / norm_factor\n","    return samples, Fs\n","\n","def create_input_signals(scales, set_first_scale_by_energy, min_energy_th,  filter_size, input_signal, Fs):\n","    # Performs downscaling for desired scales and outputs list of signals\n","    signals_list = []\n","    fs_list = []\n","    n_scales = len(scales)\n","    set_first_scale = False\n","    rf = calc_receptive_field(filter_size, dilation_factors)\n","    for k in range(n_scales):\n","        downsample = scales[k]\n","        fs = int(Fs / downsample)\n","        if downsample == 1:\n","            coarse_sig = input_signal\n","        else:\n","            coarse_sig = torch.Tensor(librosa.resample(input_signal.squeeze().numpy(), Fs, fs))\n","        if speech and fs < 500:\n","            continue\n","        if set_first_scale_by_energy and not speech:\n","            e = (coarse_sig ** 2).mean()\n","            if e < min_energy_th and not set_first_scale:\n","                continue\n","        set_first_scale = True\n","        signals_list.append(coarse_sig)\n","        assert np.mod(fs, 1) == 0, 'Sampling rate is not integer'\n","        fs_list.append(int(fs))\n","\n","        # Write downsampled real sound\n","        filename = 'real@%dHz.wav' % fs\n","        write_signal(os.path.join(output_folder, filename), coarse_sig.cpu(), fs)\n","\n","    return signals_list, fs_list\n","\n","def calc_receptive_field(filter_size, dilation_factors, Fs=None):\n","    if Fs is None:\n","        # in samples\n","        return (filter_size * dilation_factors[0] + sum(dilation_factors[1:]) * (filter_size - 1))\n","    else:\n","        # in [ms]\n","        return (filter_size * dilation_factors[0] + sum(dilation_factors[1:]) * (filter_size - 1)) / Fs * 1e3\n","\n","def write_signal(path, signal, fs, overwrite=False, subtype='PCM_16'):\n","    if signal is None:\n","        return\n","    if torch.is_tensor(signal):\n","        signal = signal.squeeze().detach().cpu().numpy()\n","    if not path.endswith('.wav'):\n","        path = path + '.wav'\n","    if not overwrite:\n","        if os.path.exists(path):\n","            files = glob.glob(path[:-4].replace('[Hz]', '[[]Hz[]]') + '*')\n","            path = path[:-4] + '_' + str(len(files)) + path[-4:]\n","    maxAmp = max(abs(signal.reshape(-1)))\n","    if maxAmp > 1:\n","        signal = signal / maxAmp  # normalize to avoid clipping\n","    sf.write(path, signal, fs, subtype=subtype)\n","\n","def calc_pad_size(dilation_factors, filter_size):\n","    return int(np.ceil(sum(dilation_factors) * (filter_size - 1) / 2))\n","\n","def get_noise(device, shape):\n","    return torch.randn(shape, device=device)\n","\n","def draw_signal(generators_list, signals_lengths_list, fs_list, noise_amp_list, filter_size, dilation_factors, device, reconstruction_noise_list=None,\n","                condition=None, output_all_scales=False):\n","    # Draws a signal up to current scale, using learned generators\n","    pad_size = calc_pad_size(dilation_factors, filter_size)\n","    if output_all_scales:\n","        signals_all_scales = []\n","    for scale_idx, (netG, noise_amp) in enumerate(zip(generators_list, noise_amp_list)):\n","        signal_padder = nn.ConstantPad1d(pad_size, 0)\n","        if condition is None:\n","            n_samples = signals_lengths_list[scale_idx]\n","            if reconstruction_noise_list is not None:\n","                noise_signal = reconstruction_noise_list[scale_idx]\n","            else:\n","                noise_signal = get_noise(device, (1, 1, n_samples))\n","                noise_signal = noise_signal * noise_amp\n","\n","            if scale_idx == 0:\n","                prev_sig = torch.full(noise_signal.shape, 0, device=device, dtype=noise_signal.dtype)\n","            else:\n","                prev_sig = signal_padder(prev_sig)\n","\n","            # pad noise with zeros, to match signal after filtering\n","            if reconstruction_noise_list is None:\n","                # reconstruction_noise is already padded\n","                noise_signal = signal_padder(noise_signal)\n","                if scale_idx == 0:\n","                    prev_sig = signal_padder(prev_sig)\n","        else:\n","            if scale_idx < condition[\"condition_scale_idx\"]:\n","                continue\n","            elif scale_idx == condition[\"condition_scale_idx\"]:\n","                prev_sig = resample_sig(device, condition[\"condition_signal\"], condition['condition_fs'],\n","                                        fs_list[scale_idx]).expand(1, 1, -1)\n","            noise_signal = get_noise(device, prev_sig.shape[2]).expand(1, 1, -1)\n","            noise_signal = signal_padder(noise_signal)\n","            noise_signal = noise_signal * noise_amp\n","            prev_sig = signal_padder(prev_sig)\n","\n","        # Generate this scale signal\n","        cur_sig = netG((noise_signal + prev_sig).detach(), prev_sig)\n","\n","        if output_all_scales:\n","            signals_all_scales.append(torch.squeeze(cur_sig).detach().cpu().numpy())\n","\n","        # Upsample for next scale\n","        if scale_idx < len(fs_list) - 1:\n","            up_sig = resample_sig( device, cur_sig, orig_fs=fs_list[scale_idx], target_fs=fs_list[scale_idx + 1])\n","            if up_sig.shape[2] > signals_lengths_list[scale_idx + 1]:\n","                assert abs(\n","                    up_sig.shape[2] > signals_lengths_list[scale_idx + 1]) < 20, 'Should not happen, check this!'\n","                up_sig = up_sig[:, :, :signals_lengths_list[scale_idx + 1]]\n","            elif up_sig.shape[2] < signals_lengths_list[scale_idx + 1]:\n","                assert abs(\n","                    up_sig.shape[2] < signals_lengths_list[scale_idx + 1]) < 20, 'Should not happen, check this!'\n","                up_sig = torch.cat(\n","                    (up_sig, up_sig.new_zeros(1, 1, signals_lengths_list[scale_idx + 1] - up_sig.shape[2])),\n","                    dim=2)\n","        else:\n","            up_sig = cur_sig\n","        prev_sig = up_sig\n","        prev_sig = prev_sig.detach()\n","\n","        del up_sig, cur_sig, noise_signal, netG\n","\n","    if output_all_scales:\n","        return signals_all_scales\n","    else:\n","        return prev_sig\n","\n","def resample_sig(device,input_signal, orig_fs=None, target_fs=None, resamplers=None):\n","    if resamplers == None:\n","        resamplers = {}\n","    if (orig_fs, target_fs) in resamplers.keys() and resamplers[(orig_fs, target_fs)].in_shape[2] == \\\n","            input_signal.shape[2]:\n","        resampler = resamplers[(orig_fs, target_fs)]\n","    else:\n","        in_shape = input_signal.shape\n","        scale_factors = (1, 1, target_fs / orig_fs)\n","        resampler = ResizeLayer(in_shape, scale_factors=scale_factors, device=device)\n","        resamplers[(orig_fs, target_fs)] = resampler\n","    new_sig = resampler(input_signal)\n","\n","    return new_sig\n","\n","def support_sz(sz):\n","    def wrapper(f):\n","        f.support_sz = sz\n","        return f\n","    return wrapper\n","\n","@support_sz(4)\n","def cubic(x):\n","    fw, to_dtype, eps = set_framework_dependencies(x)\n","    absx = fw.abs(x)\n","    absx2 = absx ** 2\n","    absx3 = absx ** 3\n","    return ((1.5 * absx3 - 2.5 * absx2 + 1.) * to_dtype(absx <= 1.) +\n","            (-0.5 * absx3 + 2.5 * absx2 - 4. * absx + 2.) *\n","            to_dtype((1. < absx) & (absx <= 2.)))\n","\n","class ResizeLayer(nn.Module):\n","    def __init__(self, in_shape, scale_factors=None, out_shape=None,\n","                 interp_method=cubic, support_sz=None,\n","                 antialiasing=True, device=None):\n","        super(ResizeLayer, self).__init__()\n","\n","        # fw stands for framework, that can be either numpy or torch. since\n","        # this is a torch layer, only one option in this case.\n","        fw = torch\n","        eps = fw.finfo(fw.float32).eps\n","\n","        # set missing scale factors or output shapem one according to another,\n","        # scream if both missing\n","        scale_factors, out_shape = set_scale_and_out_sz(in_shape, out_shape,\n","                                                        scale_factors, fw)\n","        \n","        # unless support size is specified by the user, it is an attribute\n","        # of the interpolation method\n","        if support_sz is None:\n","            support_sz = interp_method.support_sz\n","        \n","        self.n_dims = len(in_shape)       \n","\n","        # sort indices of dimensions according to scale of each dimension.\n","        # since we are going dim by dim this is efficient\n","        self.sorted_filtered_dims_and_scales = [(dim, scale_factors[dim])\n","                                                for dim in\n","                                                sorted(range(self.n_dims),\n","                                                key=lambda ind:\n","                                                scale_factors[ind])\n","                                                if scale_factors[dim] != 1.]\n","\n","        # iterate over dims\n","        field_of_view_list = []\n","        weights_list = []\n","        for dim, scale_factor in self.sorted_filtered_dims_and_scales:\n","\n","            # get 1d set of weights and fields of view for each output\n","            # location along this dim\n","            field_of_view, weights = prepare_weights_and_field_of_view_1d(\n","                dim, scale_factor, in_shape[dim], out_shape[dim],\n","                interp_method, support_sz, antialiasing, fw, eps, device)\n","\n","            # keep weights and fields of views for all dims\n","            weights_list.append(nn.Parameter(weights, requires_grad=False))\n","            field_of_view_list.append(nn.Parameter(field_of_view,\n","                                      requires_grad=False))\n","\n","        self.field_of_view = nn.ParameterList(field_of_view_list)\n","        self.weights = nn.ParameterList(weights_list)\n","        self.in_shape = in_shape\n","\n","    def forward(self, input):\n","        # output begins identical to input and changes with each iteration\n","        output = input\n","\n","        for (dim, scale_factor), field_of_view, weights in zip(\n","                self.sorted_filtered_dims_and_scales,\n","                self.field_of_view,\n","                self.weights):\n","            # multiply the weights by the values in the field of view and\n","            # aggreagate\n","            output = apply_weights(output, field_of_view, weights, dim,\n","                                   self.n_dims, torch)\n","        return output\n","\n","def prepare_weights_and_field_of_view_1d(dim, scale_factor, in_sz, out_sz,\n","                                         interp_method, support_sz, \n","                                         antialiasing, fw, eps, device=None):\n","    # If antialiasing is taking place, we modify the window size and the\n","    # interpolation method (see inside function)\n","    interp_method, cur_support_sz = apply_antialiasing_if_needed(\n","                                                             interp_method,\n","                                                             support_sz,\n","                                                             scale_factor,\n","                                                             antialiasing)\n","\n","    # STEP 1- PROJECTED GRID: The non-integer locations of the projection of\n","    # output pixel locations to the input tensor\n","    projected_grid = get_projected_grid(in_sz, out_sz, scale_factor, fw, device)\n","\n","    # STEP 2- FIELDS OF VIEW: for each output pixels, map the input pixels\n","    # that influence it\n","    field_of_view = get_field_of_view(projected_grid, cur_support_sz, in_sz,\n","                                      fw, eps)\n","\n","    # STEP 3- CALCULATE WEIGHTS: Match a set of weights to the pixels in the\n","    # field of view for each output pixel\n","    weights = get_weights(interp_method, projected_grid, field_of_view)\n","\n","    return field_of_view, weights\n","\n","def apply_weights(input, field_of_view, weights, dim, n_dims, fw):\n","    # STEP 4- APPLY WEIGHTS: Each output pixel is calculated by multiplying\n","    # its set of weights with the pixel values in its field of view.\n","    # We now multiply the fields of view with their matching weights.\n","    # We do this by tensor multiplication and broadcasting.\n","    # this step is separated to a different function, so that it can be\n","    # repeated with the same calculated weights and fields.\n","\n","    # for this operations we assume the resized dim is the first one.\n","    # so we transpose and will transpose back after multiplying\n","    tmp_input = fw_swapaxes(input, dim, 0, fw)\n","\n","    # field_of_view is a tensor of order 2: for each output (1d location\n","    # along cur dim)- a list of 1d neighbors locations.\n","    # note that this whole operations is applied to each dim separately,\n","    # this is why it is all in 1d.\n","    # neighbors = tmp_input[field_of_view] is a tensor of order image_dims+1:\n","    # for each output pixel (this time indicated in all dims), these are the\n","    # values of the neighbors in the 1d field of view. note that we only\n","    # consider neighbors along the current dim, but such set exists for every\n","    # multi-dim location, hence the final tensor order is image_dims+1.\n","    neighbors = tmp_input[field_of_view]\n","\n","    # weights is an order 2 tensor: for each output location along 1d- a list\n","    # of weighs matching the field of view. we augment it with ones, for\n","    # broadcasting, so that when multiplies some tensor the weights affect\n","    # only its first dim.\n","    tmp_weights = fw.reshape(weights, (*weights.shape, * [1] * (n_dims - 1)))\n","\n","    # now we simply multiply the weights with the neighbors, and then sum\n","    # along the field of view, to get a single value per out pixel\n","    tmp_output = (neighbors * tmp_weights).sum(1)\n","\n","    # we transpose back the resized dim to its original position\n","    return fw_swapaxes(tmp_output, 0, dim, fw)\n","\n","def get_weights(interp_method, projected_grid, field_of_view):\n","    # the set of weights per each output pixels is the result of the chosen\n","    # interpolation method applied to the distances between projected grid\n","    # locations and the pixel-centers in the field of view (distances are\n","    # directed, can be positive or negative)\n","    weights = interp_method(projected_grid[:, None] - field_of_view)\n","\n","    # we now carefully normalize the weights to sum to 1 per each output pixel\n","    sum_weights = weights.sum(1, keepdims=True)\n","    sum_weights[sum_weights == 0] = 1\n","    return weights / sum_weights\n","\n","def fw_ceil(x, fw):\n","    return x.ceil().long()\n","\n","\n","def fw_cat(x, fw):\n","    return fw.cat(x)\n","\n","\n","def fw_swapaxes(x, ax_1, ax_2, fw):\n","    return x.transpose(ax_1, ax_2)\n","    \n","def fw_set_device(x, device, fw):\n","    return x.to(device)\n","\n","def set_scale_and_out_sz(in_shape, out_shape, scale_factors, fw):\n","    # eventually we must have both scale-factors and out-sizes for all in/out\n","    # dims. however, we support many possible partial arguments\n","    if scale_factors is None and out_shape is None:\n","        raise ValueError(\"either scale_factors or out_shape should be \"\n","                         \"provided\")\n","    if out_shape is not None:\n","        # if out_shape has less dims than in_shape, we defaultly resize the\n","        # first dims for numpy and last dims for torch\n","        out_shape = list(out_shape) + list(in_shape[:-len(out_shape)])\n","        if scale_factors is None:\n","            # if no scale given, we calculate it as the out to in ratio\n","            # (not recomended)\n","            scale_factors = [out_sz / in_sz for out_sz, in_sz\n","                             in zip(out_shape, in_shape)]\n","    if scale_factors is not None:\n","        # by default, if a single number is given as scale, we assume resizing\n","        # two dims (most common are images with 2 spatial dims)\n","        scale_factors = (scale_factors\n","                         if isinstance(scale_factors, (list, tuple))\n","                         else [scale_factors, scale_factors])\n","        # if less scale_factors than in_shape dims, we defaultly resize the\n","        # first dims for numpy and last dims for torch\n","        scale_factors = list(scale_factors) + [1] * (len(in_shape) - len(scale_factors)) \n","        if out_shape is None:\n","            # when no out_shape given, it is calculated by multiplying the\n","            # scale by the in_shape (not recomended)\n","            out_shape = [ceil(scale_factor * in_sz)\n","                         for scale_factor, in_sz in\n","                         zip(scale_factors, in_shape)]\n","        # next line intentionally after out_shape determined for stability\n","        scale_factors = [float(sf) for sf in scale_factors]\n","    return scale_factors, out_shape\n","\n","def apply_antialiasing_if_needed(interp_method, support_sz, scale_factor,\n","                                 antialiasing):\n","    # antialiasing is \"stretching\" the field of view according to the scale\n","    # factor (only for downscaling). this is low-pass filtering. this\n","    # requires modifying both the interpolation (stretching the 1d\n","    # function and multiplying by the scale-factor) and the window size.\n","    if scale_factor >= 1.0 or not antialiasing:\n","        return interp_method, support_sz\n","    cur_interp_method = (lambda arg: scale_factor *\n","                         interp_method(scale_factor * arg))\n","    cur_support_sz = support_sz / scale_factor\n","    return cur_interp_method, cur_support_sz\n","\n","def get_projected_grid(in_sz, out_sz, scale_factor, fw, device=None):\n","    # we start by having the ouput coordinates which are just integer locations\n","    out_coordinates = fw.arange(out_sz)\n","    \n","    # if using torch we need to match the grid tensor device to the input device\n","    out_coordinates = fw_set_device(out_coordinates, device, fw)\n","        \n","    # This is projecting the ouput pixel locations in 1d to the input tensor,\n","    # as non-integer locations.\n","    # the following fomrula is derived in the paper\n","    # \"From Discrete to Continuous Convolutions\" by Shocher et al.\n","    return (out_coordinates / scale_factor +\n","            (in_sz - 1) / 2 - (out_sz - 1) / (2 * scale_factor))\n","\n","\n","def get_field_of_view(projected_grid, cur_support_sz, in_sz, fw, eps):\n","    # for each output pixel, map which input pixels influence it, in 1d.\n","    # we start by calculating the leftmost neighbor, using half of the window\n","    # size (eps is for when boundary is exact int)\n","    left_boundaries = fw_ceil(projected_grid - cur_support_sz / 2 - eps, fw)\n","\n","    # then we simply take all the pixel centers in the field by counting\n","    # window size pixels from the left boundary\n","    ordinal_numbers = fw.arange(ceil(cur_support_sz - eps))\n","    # in case using torch we need to match the device\n","    ordinal_numbers = fw_set_device(ordinal_numbers, projected_grid.device, fw)\n","    field_of_view = left_boundaries[:, None] + ordinal_numbers\n","\n","    # next we do a trick instead of padding, we map the field of view so that\n","    # it would be like mirror padding, without actually padding\n","    # (which would require enlarging the input tensor)\n","    mirror = fw_cat((fw.arange(in_sz), fw.arange(in_sz - 1, -1, step=-1)), fw)\n","    field_of_view = mirror[fw.remainder(field_of_view, mirror.shape[0])]\n","    field_of_view = fw_set_device(field_of_view,projected_grid.device, fw)\n","    return field_of_view\n","\n","def set_framework_dependencies(x):\n","    if type(x) is np.ndarray:\n","        to_dtype = lambda a: a\n","        fw = np\n","    else:\n","        to_dtype = lambda a: a.to(x.dtype)\n","        fw = torch\n","    eps = fw.finfo(fw.float32).eps\n","    return fw, to_dtype, eps\n","\n","def calc_gradient_penalty(run_mode, current_holes, netD, real_data, fake_data, LAMBDA, alpha=None, _grad_outputs=None, mask_ratio=None, not_valid_idx_start=None, not_valid_idx_end=None):\n","    # Gradient penalty method for WGAN\n","    if alpha is None:\n","        alpha = torch.rand(1, 1)\n","        alpha = alpha.expand(real_data.size())\n","        if torch.cuda.is_available():\n","            alpha = alpha.cuda(real_data.get_device())  # gpu) #if use_cuda else alpha\n","    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n","    interpolates = torch.autograd.Variable(interpolates, requires_grad=True)\n","    use_mask = False\n","    mask_ratio = 1\n","    disc_interpolates = netD(interpolates, use_mask)\n","    if _grad_outputs is None:\n","        _grad_outputs = torch.ones(disc_interpolates.size())\n","        if torch.cuda.is_available():\n","            _grad_outputs = _grad_outputs.cuda(real_data.get_device())\n","    gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n","                                    grad_outputs=_grad_outputs,\n","                                    create_graph=True, retain_graph=True, only_inputs=True)[0]\n","    gradient_penalty = ((mask_ratio * gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n","    del gradients, interpolates, _grad_outputs, disc_interpolates\n","    return gradient_penalty\n","\n","def stft(sig, n_fft, hop_length, window_size):\n","    s = torch.stft(sig, n_fft, hop_length, win_length=window_size,\n","                   window=torch.hann_window(window_size, device=sig.device), return_complex=False)\n","    return s\n","\n","def spec(x, n_fft, hop_length, window_size):\n","    s = stft(x, n_fft, hop_length, window_size)\n","    n = torch.norm(s, p=2, dim=-1)\n","    return n\n","\n","def norm(x):\n","    return (x.view(x.shape[0], -1) ** 2).sum(dim=-1).sqrt()\n","\n","\n","def squeeze(x):\n","    if len(x.shape) == 3:\n","        assert x.shape[-1] in [1, 2]\n","        x = torch.mean(x, -1)\n","    if len(x.shape) != 2:\n","        raise ValueError(f'Unknown input shape {x.shape}')\n","    return x\n","\n","def multi_scale_spectrogram_loss(multispec_loss_n_fft, multispec_loss_hop_length, multispec_loss_window_size, current_holes, x_in, x_out):\n","    losses = []\n","    args = [multispec_loss_n_fft,\n","            multispec_loss_hop_length,\n","            multispec_loss_window_size]\n","    for n_fft, hop_length, window_size in zip(*args):\n","        if window_size == -1:\n","            window_size = x_in.shape[1]\n","            hop_length = window_size + 1\n","            n_fft = int(2 ** np.ceil(np.log2(window_size)))\n","        spec_in = spec(squeeze(x_in.float()), n_fft, hop_length, window_size)\n","        spec_out = spec(squeeze(x_out.float()), n_fft, hop_length, window_size)\n","        losses.append(norm(spec_in - spec_out))\n","    return sum(losses) / len(losses)\n","\n","def reset_grads(model, require_grad):\n","    for p in model.parameters():\n","        p.requires_grad_(require_grad)\n","    return model"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"uv_GjFaJDb6G","executionInfo":{"status":"ok","timestamp":1663270236419,"user_tz":-60,"elapsed":4,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"outputs":[],"source":["#model \n","class Generator(nn.Module):\n","    def __init__(self, filter_size, hidden_channels, current_fs ):\n","        super(Generator, self).__init__()\n","        self.head = ConvBlock(filter_size, 1, hidden_channels, dilation_factors[0])\n","        self.body = nn.Sequential()\n","        self.Fs = current_fs\n","        for i in range(num_layers - 2):\n","            block = ConvBlock(filter_size, hidden_channels, hidden_channels, dilation_factors[i + 1])\n","            self.body.add_module('block%d' % (i + 1), block)\n","        self.tail = nn.Sequential()\n","        self.tail.add_module('tail0',\n","                             NormConv1d(in_channels=hidden_channels, out_channels=hidden_channels,\n","                                        kernel_size=filter_size,\n","                                        dilation=dilation_factors[-1]))\n","        self.filter = nn.Sequential(\n","            NormConv1d(in_channels=hidden_channels, out_channels=hidden_channels,\n","                       kernel_size=filter_size, padding=int((filter_size - 1) / 2)),\n","            nn.Tanh()\n","        )\n","        self.gate = nn.Sequential(\n","            NormConv1d(in_channels=hidden_channels, out_channels=hidden_channels,\n","                       kernel_size=filter_size, padding=int((filter_size - 1) / 2)),\n","            nn.Sigmoid()\n","        )\n","        self.out_conv = NormConv1d(hidden_channels, 1, kernel_size=1)\n","        self.pe_filter = PreEmphasisFilter(device)\n","\n","    def forward(self, noise_plus_sig, prev_sig):\n","        out_head = self.head(noise_plus_sig)\n","        out_body = self.body(out_head)\n","        out_tail = self.tail(out_body)\n","        filter = self.filter(out_tail)\n","        gate = self.gate(out_tail)\n","        out_tail = filter * gate\n","        out_tail = self.out_conv(out_tail)\n","        out_filt = self.pe_filter(out_tail)\n","        ind = int((prev_sig.shape[2] - out_filt.shape[2]) / 2)\n","        prev_sig = prev_sig[:, :, ind:(prev_sig.shape[2] - ind)]\n","        output = out_filt + prev_sig\n","        return output\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, run_mode, current_holes, hidden_channels, dilation_factors, num_layers, device,filter_size ):\n","        super(Discriminator, self).__init__()\n","        if run_mode == 'inpainting':\n","            mask = current_holes\n","        else:\n","            mask = None\n","        self.head = ConvBlock(filter_size, 1, hidden_channels, dilation_factors[0], mask=mask)\n","        mask = self.head.mask_out\n","        self.body = nn.ModuleList()\n","        for i in range(num_layers - 2):\n","            block = ConvBlock(filter_size, hidden_channels, hidden_channels,\n","                              dilation_factors[i + 1], mask=mask)\n","            mask = block.mask_out\n","            self.body.add_module('block%d' % (i + 1), block)\n","        self.mask_out = mask\n","        self.tail = NormConv1d(hidden_channels, 1, kernel_size=filter_size,\n","                               dilation=dilation_factors[-1])\n","        self.pe_filter = PreEmphasisFilter(device)\n","\n","    def forward(self, sig, use_mask=False):\n","        out_head = self.head(sig, use_mask)\n","        out_body = out_head\n","        for b in self.body:\n","            out_body = b(out_body, use_mask)\n","        out_tail = self.tail(out_body)\n","        output = self.pe_filter(out_tail)\n","        return output\n","\n","\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1 and classname.find('ConvBlock') == -1 and hasattr(m, 'weight'):\n","        if m.weight.numel() > 1 and m.weight.requires_grad:  # scalar blocks are initiailized upon creation\n","            m.weight.data.normal_(0.0, 0.02)\n","\n","    elif classname.find('Norm') != -1 and hasattr(m, 'weight'):\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)\n","\n","class PreEmphasisFilter(nn.Module):\n","    def __init__(self, device):\n","        super(PreEmphasisFilter, self).__init__()\n","        self.alpha = torch.Tensor([0.97]).to(device)\n","        self.alpha.requires_grad = False\n","\n","    def forward(self, x):\n","        output = torch.cat((x[:, :, 0].view(x.shape[0], x.shape[1], 1), x[:, :, 1:] - self.alpha * x[:, :, :-1]), dim=2)\n","        return output\n","\n","\n","class NormConv1d(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=True):\n","        super(NormConv1d, self).__init__()\n","        self.conv = weight_norm(nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n","                                          stride=stride, padding=padding, dilation=dilation, bias=bias))\n","\n","    def forward(self, x):\n","        output = self.conv(x)\n","        return output\n","\n","\n","class ConvBlock(nn.Sequential):\n","    def __init__(self, filter_size, in_channels, out_channels, dilation=1, mask=None):\n","        super(ConvBlock, self).__init__()\n","        if filter_size is None:\n","            filter_size = filter_size\n","        if mask is not None:\n","            self.mask_in = mask\n","            self.mask_out = []\n","            self.rf = int((filter_size - 1) * dilation)\n","            for hole in self.mask_in:\n","                self.mask_out.append([hole[0] - self.rf, hole[1]])\n","            # ???\n","            # for idx in range(len(self.mask_out) - 1):\n","            #     if self.mask_out[idx+1][0] < self.mask_out[idx][1]:\n","            #         self.mask_out[idx+1][0] = self.mask_out[idx][1] + 1\n","\n","        else:\n","            self.mask_out = None\n","        self.conv = NormConv1d(in_channels, out_channels, filter_size, dilation=dilation)\n","        self.norm = nn.BatchNorm1d(out_channels)\n","        self.activation = nn.LeakyReLU(0.2, inplace=True)\n","\n","    def forward(self, x, use_mask=False):\n","        out_conv = self.conv(x)\n","        if use_mask:\n","            #tmp = torch.cat((out_conv[:, :, :int(self.mask_out[0][0])], out_conv[:, :, int(self.mask_out[0][1] + 1):]), dim=2)\n","            tmp = out_conv[:, :, :int(self.mask_out[0][0])].clone()\n","            cut_idx = []\n","            cut_idx.append(tmp.shape[2])\n","            for idx in range(len(self.mask_out)-1):\n","                tmp = torch.cat((tmp, out_conv[:, :, int(self.mask_out[idx][1] + 1):int(self.mask_out[idx+1][0])]), dim=2)\n","                cut_idx.append(tmp.shape[2])\n","            tmp = torch.cat((tmp, out_conv[:, :, int(self.mask_out[-1][1] + 1):]), dim=2)\n","\n","            tmp_norm = self.norm(tmp)\n","            out_norm = out_conv\n","            out_norm[:, :, :int(self.mask_out[0][0])] = tmp_norm[:, :, :int(cut_idx[0])]\n","            for idx in range(len(self.mask_out) - 1):\n","                out_norm[:, :, int(self.mask_out[idx][1] + 1):int(self.mask_out[idx+1][0])] = tmp_norm[:, :, int(cut_idx[idx]):int(cut_idx[idx+1])] #tmp_norm[:, :, int(self.mask_out[idx][0]):int(self.mask_out[idx+1][0])]\n","                #out_norm[:, :, :int(self.mask_out[idx+1][0])] = tmp_norm[:, :, :int(self.mask_out[idx+1][0])]\n","            out_norm[:, :, int(self.mask_out[-1][1] + 1):] = tmp_norm[:, :, int(cut_idx[-1]):]\n","\n","        else:\n","            out_norm = self.norm(out_conv)\n","        return self.activation(out_norm)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"_r37Na9OBSA8","executionInfo":{"status":"ok","timestamp":1663270236419,"user_tz":-60,"elapsed":4,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"outputs":[],"source":["#training functions\n","def train(manual_random_seed, fs_list, scales, growing_hidden_channels_factor,learning_rate, beta1, scheduler_lr_decay, plot_losses,\n","          initial_noise_amp, noise_amp_factor, signals_list, dilation_factors, output_folder, inputs_lengths):\n","    if manual_random_seed != -1:\n","        random.seed(manual_random_seed)\n","        torch.manual_seed(manual_random_seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","\n","    fs_list = fs_list\n","    n_scales = len(scales)\n","    generators_list = []\n","    noise_amp_list = []\n","    if run_mode == 'inpainting':\n","        energy_list = [(sig[mask] ** 2).mean().item() for sig, mask in zip(signals_list, masks)]\n","    else:\n","        energy_list = [(sig ** 2).mean().item() for sig in signals_list]\n","    reconstruction_noise_list = []\n","    output_signals = []\n","    loss_vectors = []\n","\n","    for scale_idx in range(n_scales):\n","        output_signals_single_scale, loss_vectors_single_scale, netG, reconstruction_noise_list, noise_amp = train_single_scale(\n","                      scales, device, run_mode, hidden_channels_init, growing_hidden_channels_factor,  learning_rate, beta1, \n","                      scheduler_lr_decay, plot_losses, initial_noise_amp, noise_amp_factor, signals_list, fs_list, \n","                      generators_list, noise_amp_list, energy_list, reconstruction_noise_list, dilation_factors, output_folder, inputs_lengths)\n","\n","        # Write fake sound\n","        fake_sound = output_signals_single_scale['fake_signal'].squeeze()\n","        filename = 'fake@%dHz.wav' % fs_list[scale_idx]\n","        write_signal(os.path.join(output_folder, filename), fake_sound,\n","                     fs_list[scale_idx], overwrite=False)\n","\n","        # Write reconstructed sound\n","        reconstructed_sound = output_signals_single_scale['reconstructed_signal'].squeeze()\n","        filename = 'reconstructed@%dHz.wav' % fs_list[scale_idx]\n","        write_signal(os.path.join(output_folder, filename),\n","                     reconstructed_sound, fs_list[scale_idx], overwrite=False)\n","        torch.save(reconstruction_noise_list,\n","                   os.path.join(output_folder, 'reconstruction_noise_list.pt'))\n","\n","        generators_list.append(netG)\n","        noise_amp_list.append(noise_amp)\n","        output_signals.append(output_signals_single_scale)\n","        loss_vectors.append(loss_vectors_single_scale)\n","\n","    return output_signals, loss_vectors, generators_list, noise_amp_list, energy_list, reconstruction_noise_list\n","\n","\n","def train_single_scale(scales, device, run_mode, hidden_channels_init, growing_hidden_channels_factor,\n","                       learning_rate, beta1, scheduler_lr_decay, plot_losses, initial_noise_amp, noise_amp_factor, signals_list,\n","                        fs_list, generators_list, noise_amp_list, energy_list, reconstruction_noise_list, dilation_factors, output_folder, inputs_lengths):\n","    # Terminology: 0 is the higher scale (original signal, no downsampling). Higher scale means larger downsampling, e.g shorter signals\n","    n_scales = len(scales)\n","    current_scale = n_scales - len(generators_list) - 1\n","    scale_idx = n_scales - current_scale - 1\n","    input_signal = signals_list[scale_idx].to(device)\n","    current_fs = fs_list[scale_idx]\n","    N = len(input_signal)\n","\n","    if run_mode == 'inpainting':\n","        current_mask = masks[scale_idx]\n","        current_mask = current_mask\n","        current_holes = torch.Tensor([(int(idx[0] / Fs * current_fs), int(idx[1] / Fs * current_fs)) for idx in inpainting_indices]).to(device)\n","    else:\n","        current_holes = None\n","\n","    # Create inputs\n","    real_signal = input_signal.reshape(1, 1, N)\n","\n","    hidden_channels = hidden_channels_init if scale_idx == 0 else int(\n","        hidden_channels_init * growing_hidden_channels_factor)\n","\n","    scale_num = n_scales - scale_idx - 1\n","    pad_size = calc_pad_size(dilation_factors, filter_size)\n","    signal_padder = nn.ConstantPad1d(pad_size, 0)\n","\n","    # Initialize models\n","    netD = Discriminator(run_mode, current_holes, hidden_channels, dilation_factors, num_layers, device, filter_size).to(device)\n","    netD.apply(weights_init)\n","    netG = Generator(filter_size, hidden_channels, current_fs).to(device)\n","    netG.apply(weights_init)\n","    receptive_field = calc_receptive_field(filter_size, dilation_factors, current_fs)\n","    receptive_field_percent = 100 * receptive_field / 1e3 / (N / current_fs)\n","    print('Signal in scale %d has %d samples, sample rate is %d[Hz].' % (\n","        scale_num, N, current_fs))\n","    print('Total receptive field is %d[msec] (%.1f%% of input).' % (receptive_field, receptive_field_percent))\n","    with open(os.path.join(output_folder, 'log.txt'), 'a') as f:\n","        f.write('*' * 30 + ' Scale ' + str(scale_num) + ' (' + str(current_fs) + ' [Hz]) ' + '*' * 30)\n","        f.write('\\nreceptive_field = %d[msec] (%.1f%% of input)' % (receptive_field, receptive_field_percent))\n","        f.write('\\nsignal_energy = %.4f' % energy_list[scale_idx])\n","\n","    if scale_idx == 0:\n","        reconstruction_noise = get_noise(device, real_signal.shape)\n","    else:\n","        reconstruction_noise = torch.zeros(real_signal.shape, device=device)\n","        if run_mode == 'inpainting':\n","            reconstruction_noise[:, :, torch.logical_not(current_mask)] = get_noise(device, torch.nonzero(\n","                torch.logical_not(current_mask)).shape[0]).expand(1, 1, -1).to(device)\n","\n","    reconstruction_noise = signal_padder(reconstruction_noise)\n","\n","    if scale_idx > 1:\n","        netG.load_state_dict(\n","            torch.load('%s/netGScale%d.pth' % (output_folder, scale_idx - 1), map_location=device))\n","        netD.load_state_dict(\n","            torch.load('%s/netDScale%d.pth' % (output_folder, scale_idx - 1), map_location=device))\n","\n","    output_folder = output_folder\n","\n","    # Create optimizers\n","    optimizerD = optim.Adam(netD.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n","    optimizerG = optim.Adam(netG.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n","    schedulerD = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizerD, milestones=scheduler_milestones,\n","                                                      gamma=scheduler_lr_decay)\n","    schedulerG = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizerG, milestones=scheduler_milestones,\n","                                                      gamma=scheduler_lr_decay)\n","\n","    # Initialize error vectors\n","    v_err_real = np.zeros(num_epochs, )\n","    v_err_fake = np.zeros(num_epochs, )\n","    v_gp = np.zeros(num_epochs, )\n","    v_rec_loss = np.zeros(num_epochs, )\n","\n","    epochs_start_time = time.time()\n","    # prepare inputs for gradient penalty\n","    if not run_mode == 'inpainting':\n","        D_out_shape = torch.Size((1, 1, N - 2 * pad_size))\n","        _grad_outputs = torch.ones(D_out_shape, device=device)\n","    grad_pen_alpha_vec = torch.rand(num_epochs).to(device)\n","\n","    inputs_lengths = inputs_lengths\n","    for epoch_num in range(num_epochs):\n","        print_progress = epoch_num % 100 == 0\n","        # Create noise\n","        noise_signal = get_noise(device, real_signal.shape)\n","        noise_signal = signal_padder(noise_signal)\n","        #################################################################\n","        # Optimize D by maximizing D(realSignal)+(1-D(G(noise_signal))) #\n","        #################################################################\n","        netD.zero_grad()\n","        # Run on real signal\n","        not_valid_idx_start = []\n","        not_valid_idx_end = []\n","        if run_mode == 'inpainting':\n","            out_D_real = netD(real_signal, use_mask=True)\n","            tot_samples = out_D_real.shape[2]\n","            not_valid_idx_start = [int(idx[0] - receptive_field / 1e3 * current_fs + 1) for idx in current_holes]\n","            not_valid_idx_end = [int(idx[1] + 1) for idx in current_holes]  # +1 is because of pe filter\n","            out_D_real_cp = out_D_real.clone()\n","            out_D_real = out_D_real_cp[:, :, :not_valid_idx_start[0]]\n","            if len(current_holes) > 1:\n","                for i in range(len(current_holes) - 1):\n","                    out_D_real = torch.cat((out_D_real, out_D_real_cp[:, :, not_valid_idx_end[i] + 1:not_valid_idx_start[i+1]]), dim=2)\n","            out_D_real = torch.cat((out_D_real, out_D_real_cp[:, :, not_valid_idx_end[-1] + 1:]), dim=2)\n","            mask_ratio = tot_samples / out_D_real.shape[2]\n","        else:\n","            mask_ratio = 1\n","            out_D_real = netD(real_signal)\n","        err_real_D = -out_D_real.mean()\n","        err_real_D.backward(retain_graph=True)\n","        err_real_D = err_real_D.detach()\n","        if print_progress or plot_losses:\n","            err_real_D_val = err_real_D.item()\n","\n","        if epoch_num == 0:\n","            if run_mode == 'inpainting':\n","                D_out_shape = out_D_real.shape\n","                _grad_outputs = torch.ones(D_out_shape, device=device)\n","            if scale_idx == 0:  # We are at coarsest scale\n","                prev_signal = torch.full(noise_signal.shape, 0, device=device, dtype=noise_signal.dtype)\n","                prev_reconstructed_signal = torch.zeros(reconstruction_noise.shape, device=device)\n","                noise_amp = initial_noise_amp\n","            else:\n","                prev_signal = draw_signal(generators_list, inputs_lengths, fs_list, noise_amp_list, filter_size, dilation_factors, device)\n","                prev_signal = signal_padder(prev_signal)\n","                prev_reconstructed_signal = draw_signal(generators_list, inputs_lengths,\n","                                                        fs_list,\n","                                                        noise_amp_list, filter_size, dilation_factors, device,\n","                                                        reconstruction_noise_list)\n","                prev_reconstructed_signal = signal_padder(prev_reconstructed_signal)\n","                innovation = energy_list[scale_idx] - energy_list[scale_idx - 1]\n","                energy_diff = torch.sqrt(torch.Tensor([innovation])).to(device)\n","                noise_amp = noise_amp_factor * max(torch.Tensor([0]).to(device),\n","                                                          energy_diff)\n","\n","            if scale_idx == 1 and add_cond_noise:\n","                noise_amp = prev_reconstructed_signal.std()\n","\n","            with open(os.path.join(output_folder, 'log.txt'), 'a') as f:\n","                f.write('\\nnoise_amp: %.6f' % noise_amp)\n","\n","            reconstruction_noise = reconstruction_noise * noise_amp\n","            reconstruction_noise_list.append(reconstruction_noise)\n","        else:\n","            if scale_idx > 0:\n","                prev_signal = draw_signal(generators_list, inputs_lengths, fs_list, noise_amp_list, filter_size, dilation_factors, device)\n","                prev_signal = signal_padder(prev_signal)\n","\n","        input_noise = noise_signal * noise_amp\n","\n","        # Run on fake signal\n","        fake_signal = netG((input_noise + prev_signal).detach(), prev_signal)\n","        out_D_fake = netD(fake_signal.detach())\n","        err_fake_D = out_D_fake.mean()\n","        del out_D_real, out_D_fake\n","        err_fake_D.backward(retain_graph=True)\n","        err_fake_D = err_fake_D.detach()\n","        if print_progress or plot_losses:\n","            err_fake_D_val = err_fake_D.item()\n","\n","        lambda_grad=0.01\n","        gradient_penalty = calc_gradient_penalty(run_mode, current_holes, netD, real_signal, fake_signal, lambda_grad,\n","                                                 grad_pen_alpha_vec[epoch_num], _grad_outputs, mask_ratio)\n","        gradient_penalty.backward()\n","        if print_progress or plot_losses:\n","            gradient_penalty_val = gradient_penalty.item()\n","        del gradient_penalty\n","\n","        optimizerD.step()\n","\n","        if plot_losses:\n","            v_err_real[epoch_num] = err_real_D_val\n","            v_err_fake[epoch_num] = err_fake_D_val\n","            v_gp[epoch_num] = gradient_penalty_val\n","\n","        #############################################\n","        # Update G by maximizing D(G(noise_signal)) #\n","        #############################################\n","        netG.zero_grad()\n","        output = netD(fake_signal)\n","        errG = -output.mean()\n","        del output\n","        errG.backward(retain_graph=True)\n","        errG = errG.detach()\n","        if print_progress or plot_losses:\n","            errG_val = errG.item()\n","        if scale_idx == 0:\n","            reconstructed_signal = netG((reconstruction_noise + prev_reconstructed_signal).detach(),\n","                                        prev_reconstructed_signal)\n","        else:\n","            reconstructed_signal = netG((reconstruction_noise + prev_reconstructed_signal).detach(),\n","                                        prev_reconstructed_signal)\n","        if alpha1 > 0:\n","            if run_mode == 'inpainting':\n","                rec_loss_t = alpha1 * torch.mean(\n","                    (real_signal[:, :, current_mask] - reconstructed_signal[:, :, current_mask]) ** 2)\n","            else:\n","                rec_loss_t = alpha1 * torch.mean((real_signal - reconstructed_signal) ** 2)\n","        else:\n","            rec_loss_t = 0\n","        if alpha2 > 0:\n","            multispec_loss_n_fft = (2048, 1024, 512)\n","            multispec_loss_hop_length = (240, 120, 50)\n","            multispec_loss_window_size = (1200, 600, 240)\n","            rec_loss_f = alpha2 * multi_scale_spectrogram_loss(multispec_loss_n_fft, multispec_loss_hop_length, multispec_loss_window_size,\n","                                                               current_holes, real_signal.permute(0, 2, 1),reconstructed_signal.permute(0, 2, 1))\n","        else:\n","            rec_loss_f = 0\n","        rec_loss = rec_loss_t + rec_loss_f\n","        rec_loss.backward(retain_graph=True)\n","        rec_loss = rec_loss.detach()\n","        if alpha1 > 0:\n","            rec_loss_t = rec_loss_t.detach()\n","        if alpha2 > 0:\n","            rec_loss_f = rec_loss_f.detach()\n","        if print_progress or plot_losses:\n","            rec_loss_val = rec_loss.item()\n","\n","        optimizerG.step()\n","\n","        if plot_losses:\n","            v_rec_loss[epoch_num] = rec_loss_val\n","\n","        if print_progress:\n","            print('[%d/%d] D(real): %.2f. D(fake): %.2f. rec_loss: %.4f. gp: %.4f ' % (\n","                epoch_num, num_epochs, -err_real_D_val, err_fake_D_val, rec_loss_val, gradient_penalty_val))\n","\n","        schedulerD.step()\n","        schedulerG.step()\n","\n","        # Some memory cleanup\n","        fake_signal = fake_signal.detach()\n","        reconstructed_signal = reconstructed_signal.detach()\n","        if epoch_num < num_epochs - 1:\n","            del fake_signal, reconstructed_signal, rec_loss, rec_loss_t, rec_loss_f\n","        del noise_signal, input_noise\n","        if scale_idx > 0:\n","            del prev_signal\n","\n","    epochs_stop_time = time.time()\n","    runtime_msg = 'Total time in scale %d: %d[sec] (%.2f[sec]/epoch on avg.). D(real): %f, D(fake): %f, rec_loss: %.4f. gp: %.4f' % (\n","        current_scale, epochs_stop_time - epochs_start_time,\n","        (epochs_stop_time - epochs_start_time) / num_epochs,\n","        -err_real_D_val, err_fake_D_val, rec_loss_val, gradient_penalty_val)\n","    print(runtime_msg)\n","    with open(os.path.join(output_folder, 'log.txt'), 'a') as f:\n","        f.write('\\n%s\\n' % runtime_msg)\n","\n","    # Save this scale models\n","    torch.save(netG.state_dict(), '%s/netGScale%d.pth' % (output_folder, scale_idx))\n","    torch.save(netD.state_dict(), '%s/netDScale%d.pth' % (output_folder, scale_idx))\n","    # Pack outputs\n","    if plot_losses:\n","        loss_vectors = {'v_err_real': v_err_real,\n","                        'v_err_fake': v_err_fake,\n","                        'v_rec_loss': v_rec_loss,\n","                        'v_gp': v_gp}\n","    else:\n","        loss_vectors = []\n","    fake_signal = fake_signal.detach().cpu().numpy()[:, 0, :]\n","    reconstructed_signal = reconstructed_signal.detach().cpu().numpy()[:, 0, :]\n","    output_signals = {'fake_signal': fake_signal, 'reconstructed_signal': reconstructed_signal}\n","    del fake_signal, real_signal, netD, _grad_outputs, grad_pen_alpha_vec, input_signal, reconstructed_signal, prev_reconstructed_signal, reconstruction_noise\n","    netG = reset_grads(netG, False)\n","    netG.eval()\n","    if is_cuda:\n","        torch.cuda.empty_cache()\n","    print('*' * 30 + ' Finished working on scale ' + str(current_scale) + ' ' + '*' * 30)\n","    return output_signals, loss_vectors, netG, reconstruction_noise_list, noise_amp"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzV4gMXQZR92","executionInfo":{"status":"ok","timestamp":1663332110155,"user_tz":-60,"elapsed":61873739,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}},"outputId":"3008f771-85ee-4bea-f9c0-77a21c4964d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Working on file: S11_ucm_1_mono.wav\n","Writing results to outputs_2\n","\n","Running on cuda:0\n","Signal in scale 15 has 7680 samples, sample rate is 320[Hz].\n","Total receptive field is 6378[msec] (26.6% of input).\n","[0/3500] D(real): 0.00. D(fake): 0.00. rec_loss: 0.0278. gp: 0.0083 \n","[100/3500] D(real): 0.01. D(fake): -0.02. rec_loss: 0.0181. gp: 0.0053 \n","[200/3500] D(real): 0.00. D(fake): -0.06. rec_loss: 0.0173. gp: 0.0061 \n","[300/3500] D(real): -0.09. D(fake): -0.09. rec_loss: 0.0181. gp: 0.0087 \n","[400/3500] D(real): 0.03. D(fake): -0.02. rec_loss: 0.0166. gp: 0.0429 \n","[500/3500] D(real): -0.00. D(fake): -0.05. rec_loss: 0.0169. gp: 0.0090 \n","[600/3500] D(real): -0.03. D(fake): -0.09. rec_loss: 0.0164. gp: 0.0306 \n","[700/3500] D(real): -0.06. D(fake): -0.12. rec_loss: 0.0167. gp: 0.0069 \n","[800/3500] D(real): -0.11. D(fake): -0.16. rec_loss: 0.0171. gp: 0.0159 \n","[900/3500] D(real): -0.07. D(fake): -0.18. rec_loss: 0.0163. gp: 0.0130 \n","[1000/3500] D(real): -0.05. D(fake): -0.18. rec_loss: 0.0174. gp: 0.0077 \n","[1100/3500] D(real): -0.08. D(fake): -0.22. rec_loss: 0.0174. gp: 0.0163 \n","[1200/3500] D(real): -0.07. D(fake): -0.23. rec_loss: 0.0196. gp: 0.0536 \n","[1300/3500] D(real): -0.13. D(fake): -0.24. rec_loss: 0.0179. gp: 0.0609 \n","[1400/3500] D(real): -0.23. D(fake): -0.28. rec_loss: 0.0183. gp: 0.0517 \n","[1500/3500] D(real): -0.22. D(fake): -0.27. rec_loss: 0.0159. gp: 0.0283 \n","[1600/3500] D(real): -0.11. D(fake): -0.20. rec_loss: 0.0159. gp: 0.0552 \n","[1700/3500] D(real): -0.13. D(fake): -0.25. rec_loss: 0.0159. gp: 0.0121 \n","[1800/3500] D(real): -0.30. D(fake): -0.31. rec_loss: 0.0211. gp: 0.0088 \n","[1900/3500] D(real): -0.10. D(fake): -0.25. rec_loss: 0.0170. gp: 0.0214 \n","[2000/3500] D(real): -0.15. D(fake): -0.26. rec_loss: 0.0169. gp: 0.0073 \n","[2100/3500] D(real): -0.13. D(fake): -0.33. rec_loss: 0.0166. gp: 0.0433 \n","[2200/3500] D(real): -0.05. D(fake): -0.16. rec_loss: 0.0221. gp: 0.0088 \n","[2300/3500] D(real): -0.07. D(fake): -0.19. rec_loss: 0.0171. gp: 0.0155 \n","[2400/3500] D(real): -0.08. D(fake): -0.24. rec_loss: 0.0165. gp: 0.0927 \n","[2500/3500] D(real): -0.09. D(fake): -0.25. rec_loss: 0.0163. gp: 0.0944 \n","[2600/3500] D(real): -0.10. D(fake): -0.27. rec_loss: 0.0163. gp: 0.0441 \n","[2700/3500] D(real): -0.12. D(fake): -0.30. rec_loss: 0.0163. gp: 0.0436 \n","[2800/3500] D(real): -0.18. D(fake): -0.32. rec_loss: 0.0161. gp: 0.0927 \n","[2900/3500] D(real): -0.14. D(fake): -0.37. rec_loss: 0.0163. gp: 0.0278 \n","[3000/3500] D(real): -0.13. D(fake): -0.35. rec_loss: 0.0160. gp: 0.0349 \n","[3100/3500] D(real): -0.14. D(fake): -0.37. rec_loss: 0.0161. gp: 0.2815 \n","[3200/3500] D(real): -0.19. D(fake): -0.38. rec_loss: 0.0159. gp: 0.0467 \n","[3300/3500] D(real): -0.14. D(fake): -0.39. rec_loss: 0.0159. gp: 0.0689 \n","[3400/3500] D(real): -0.15. D(fake): -0.43. rec_loss: 0.0159. gp: 0.0142 \n","Total time in scale 15: 199[sec] (0.06[sec]/epoch on avg.). D(real): -0.152669, D(fake): -0.425474, rec_loss: 0.0159. gp: 0.0142\n","****************************** Finished working on scale 15 ******************************\n","Signal in scale 14 has 9600 samples, sample rate is 400[Hz].\n","Total receptive field is 5102[msec] (21.3% of input).\n","[0/3500] D(real): -0.00. D(fake): -0.00. rec_loss: 0.0245. gp: 0.0084 \n","[100/3500] D(real): 0.06. D(fake): 0.04. rec_loss: 0.0242. gp: 0.0156 \n","[200/3500] D(real): 0.03. D(fake): -0.00. rec_loss: 0.0226. gp: 0.0106 \n","[300/3500] D(real): 0.02. D(fake): -0.01. rec_loss: 0.0232. gp: 0.0227 \n","[400/3500] D(real): 0.01. D(fake): -0.05. rec_loss: 0.0223. gp: 0.0231 \n","[500/3500] D(real): -0.01. D(fake): -0.11. rec_loss: 0.0224. gp: 0.0405 \n","[600/3500] D(real): -0.01. D(fake): -0.08. rec_loss: 0.0216. gp: 0.0134 \n","[700/3500] D(real): 0.02. D(fake): -0.10. rec_loss: 0.0226. gp: 0.1361 \n","[800/3500] D(real): 0.04. D(fake): -0.02. rec_loss: 0.0219. gp: 0.0090 \n","[900/3500] D(real): 0.11. D(fake): -0.08. rec_loss: 0.0220. gp: 0.0214 \n","[1000/3500] D(real): 0.08. D(fake): -0.08. rec_loss: 0.0229. gp: 0.1382 \n","[1100/3500] D(real): 0.04. D(fake): -0.11. rec_loss: 0.0230. gp: 0.0166 \n","[1200/3500] D(real): 0.16. D(fake): -0.06. rec_loss: 0.0219. gp: 0.0613 \n","[1300/3500] D(real): 0.14. D(fake): -0.20. rec_loss: 0.0220. gp: 0.0267 \n","[1400/3500] D(real): 0.15. D(fake): -0.00. rec_loss: 0.0219. gp: 0.0215 \n","[1500/3500] D(real): 0.06. D(fake): -0.14. rec_loss: 0.0228. gp: 0.1350 \n","[1600/3500] D(real): 0.20. D(fake): 0.06. rec_loss: 0.0259. gp: 0.0094 \n","[1700/3500] D(real): 0.17. D(fake): -0.21. rec_loss: 0.0218. gp: 0.0608 \n","[1800/3500] D(real): 0.07. D(fake): -0.14. rec_loss: 0.0219. gp: 0.0323 \n","[1900/3500] D(real): 0.21. D(fake): -0.14. rec_loss: 0.0208. gp: 0.0506 \n","[2000/3500] D(real): 0.15. D(fake): -0.33. rec_loss: 0.0210. gp: 0.0193 \n","[2100/3500] D(real): -0.02. D(fake): -0.19. rec_loss: 0.0213. gp: 0.0160 \n","[2200/3500] D(real): 0.10. D(fake): -0.02. rec_loss: 0.0219. gp: 0.0117 \n","[2300/3500] D(real): -0.18. D(fake): -0.22. rec_loss: 0.0210. gp: 0.0218 \n","[2400/3500] D(real): -0.08. D(fake): -0.15. rec_loss: 0.0207. gp: 0.0057 \n","[2500/3500] D(real): -0.04. D(fake): -0.14. rec_loss: 0.0206. gp: 0.0491 \n","[2600/3500] D(real): -0.01. D(fake): -0.12. rec_loss: 0.0206. gp: 0.0688 \n","[2700/3500] D(real): 0.02. D(fake): -0.12. rec_loss: 0.0204. gp: 0.0708 \n","[2800/3500] D(real): 0.07. D(fake): -0.12. rec_loss: 0.0202. gp: 0.0150 \n","[2900/3500] D(real): 0.08. D(fake): -0.12. rec_loss: 0.0202. gp: 0.0155 \n","[3000/3500] D(real): 0.12. D(fake): -0.09. rec_loss: 0.0202. gp: 0.0565 \n","[3100/3500] D(real): 0.14. D(fake): -0.12. rec_loss: 0.0203. gp: 0.0485 \n","[3200/3500] D(real): 0.14. D(fake): -0.09. rec_loss: 0.0204. gp: 0.0449 \n","[3300/3500] D(real): 0.15. D(fake): -0.10. rec_loss: 0.0205. gp: 0.1105 \n","[3400/3500] D(real): 0.20. D(fake): -0.09. rec_loss: 0.0205. gp: 0.1835 \n","Total time in scale 14: 334[sec] (0.10[sec]/epoch on avg.). D(real): 0.196316, D(fake): -0.093330, rec_loss: 0.0205. gp: 0.1835\n","****************************** Finished working on scale 14 ******************************\n","Signal in scale 13 has 12000 samples, sample rate is 500[Hz].\n","Total receptive field is 4082[msec] (17.0% of input).\n","[0/3500] D(real): -0.09. D(fake): -0.09. rec_loss: 0.0308. gp: 0.1466 \n","[100/3500] D(real): 0.12. D(fake): -0.02. rec_loss: 0.0268. gp: 0.0870 \n","[200/3500] D(real): 0.10. D(fake): -0.05. rec_loss: 0.0272. gp: 0.0570 \n","[300/3500] D(real): 0.11. D(fake): -0.13. rec_loss: 0.0271. gp: 0.1286 \n","[400/3500] D(real): -0.10. D(fake): -0.16. rec_loss: 0.0255. gp: 0.0178 \n","[500/3500] D(real): -0.03. D(fake): -0.06. rec_loss: 0.0245. gp: 0.0156 \n","[600/3500] D(real): 0.07. D(fake): -0.03. rec_loss: 0.0243. gp: 0.0352 \n","[700/3500] D(real): 0.18. D(fake): 0.01. rec_loss: 0.0242. gp: 0.0602 \n","[800/3500] D(real): -0.03. D(fake): -0.16. rec_loss: 0.0240. gp: 0.0180 \n","[900/3500] D(real): -0.05. D(fake): -0.07. rec_loss: 0.0232. gp: 0.0077 \n","[1000/3500] D(real): 0.02. D(fake): -0.05. rec_loss: 0.0226. gp: 0.0155 \n","[1100/3500] D(real): 0.07. D(fake): -0.04. rec_loss: 0.0233. gp: 0.0244 \n","[1200/3500] D(real): 0.17. D(fake): -0.03. rec_loss: 0.0231. gp: 0.2114 \n","[1300/3500] D(real): 0.01. D(fake): -0.03. rec_loss: 0.0226. gp: 0.0121 \n","[1400/3500] D(real): 0.24. D(fake): 0.05. rec_loss: 0.0221. gp: 0.0248 \n","[1500/3500] D(real): 0.07. D(fake): 0.04. rec_loss: 0.0216. gp: 0.0060 \n","[1600/3500] D(real): 0.19. D(fake): 0.10. rec_loss: 0.0220. gp: 0.0377 \n","[1700/3500] D(real): 0.08. D(fake): -0.05. rec_loss: 0.0221. gp: 0.0356 \n","[1800/3500] D(real): 0.24. D(fake): 0.02. rec_loss: 0.0207. gp: 0.0354 \n","[1900/3500] D(real): 0.20. D(fake): 0.04. rec_loss: 0.0202. gp: 0.0630 \n","[2000/3500] D(real): 0.31. D(fake): 0.07. rec_loss: 0.0204. gp: 0.0825 \n","[2100/3500] D(real): 0.18. D(fake): 0.04. rec_loss: 0.0202. gp: 0.0174 \n","[2200/3500] D(real): 0.41. D(fake): -0.07. rec_loss: 0.0207. gp: 0.1185 \n","[2300/3500] D(real): 0.20. D(fake): 0.15. rec_loss: 0.0202. gp: 0.0107 \n","[2400/3500] D(real): 0.25. D(fake): 0.15. rec_loss: 0.0189. gp: 0.0254 \n","[2500/3500] D(real): 0.25. D(fake): 0.13. rec_loss: 0.0187. gp: 0.0394 \n","[2600/3500] D(real): 0.27. D(fake): 0.15. rec_loss: 0.0186. gp: 0.0439 \n","[2700/3500] D(real): 0.29. D(fake): 0.15. rec_loss: 0.0184. gp: 0.0666 \n","[2800/3500] D(real): 0.33. D(fake): 0.18. rec_loss: 0.0183. gp: 0.0898 \n","[2900/3500] D(real): 0.35. D(fake): 0.16. rec_loss: 0.0182. gp: 0.0775 \n","[3000/3500] D(real): 0.38. D(fake): 0.18. rec_loss: 0.0181. gp: 0.0704 \n","[3100/3500] D(real): 0.40. D(fake): 0.17. rec_loss: 0.0180. gp: 0.0729 \n","[3200/3500] D(real): 0.43. D(fake): 0.17. rec_loss: 0.0179. gp: 0.0390 \n","[3300/3500] D(real): 0.45. D(fake): 0.18. rec_loss: 0.0179. gp: 0.1460 \n","[3400/3500] D(real): 0.42. D(fake): 0.14. rec_loss: 0.0179. gp: 0.0319 \n","Total time in scale 13: 440[sec] (0.13[sec]/epoch on avg.). D(real): 0.420698, D(fake): 0.140986, rec_loss: 0.0179. gp: 0.0319\n","****************************** Finished working on scale 13 ******************************\n","Signal in scale 12 has 15360 samples, sample rate is 640[Hz].\n","Total receptive field is 3189[msec] (13.3% of input).\n","[0/3500] D(real): 0.12. D(fake): 0.13. rec_loss: 0.0359. gp: 0.0327 \n","[100/3500] D(real): 0.21. D(fake): 0.16. rec_loss: 0.0261. gp: 0.0166 \n","[200/3500] D(real): 0.38. D(fake): 0.21. rec_loss: 0.0257. gp: 0.0774 \n","[300/3500] D(real): 0.41. D(fake): 0.29. rec_loss: 0.0250. gp: 0.0251 \n","[400/3500] D(real): 0.46. D(fake): 0.28. rec_loss: 0.0245. gp: 0.0267 \n","[500/3500] D(real): 0.51. D(fake): 0.31. rec_loss: 0.0237. gp: 0.0322 \n","[600/3500] D(real): 0.43. D(fake): 0.34. rec_loss: 0.0228. gp: 0.0332 \n","[700/3500] D(real): 0.47. D(fake): 0.26. rec_loss: 0.0224. gp: 0.0803 \n","[800/3500] D(real): 0.26. D(fake): 0.21. rec_loss: 0.0221. gp: 0.0096 \n","[900/3500] D(real): 0.65. D(fake): 0.43. rec_loss: 0.0222. gp: 0.1913 \n","[1000/3500] D(real): 0.47. D(fake): 0.40. rec_loss: 0.0209. gp: 0.0406 \n","[1100/3500] D(real): 0.51. D(fake): 0.42. rec_loss: 0.0202. gp: 0.0266 \n","[1200/3500] D(real): 0.73. D(fake): 0.64. rec_loss: 0.0196. gp: 0.0166 \n","[1300/3500] D(real): 1.07. D(fake): 0.89. rec_loss: 0.0201. gp: 0.0375 \n","[1400/3500] D(real): 1.10. D(fake): 0.81. rec_loss: 0.0190. gp: 0.0962 \n","[1500/3500] D(real): 0.84. D(fake): 0.78. rec_loss: 0.0183. gp: 0.0180 \n","[1600/3500] D(real): 1.05. D(fake): 0.84. rec_loss: 0.0178. gp: 0.1347 \n","[1700/3500] D(real): 1.06. D(fake): 0.90. rec_loss: 0.0171. gp: 0.0311 \n","[1800/3500] D(real): 1.07. D(fake): 0.89. rec_loss: 0.0169. gp: 0.0414 \n","[1900/3500] D(real): 1.22. D(fake): 0.90. rec_loss: 0.0178. gp: 0.3142 \n","[2000/3500] D(real): 1.27. D(fake): 1.02. rec_loss: 0.0163. gp: 0.0485 \n","[2100/3500] D(real): 1.33. D(fake): 1.06. rec_loss: 0.0154. gp: 0.0833 \n","[2200/3500] D(real): 1.38. D(fake): 1.16. rec_loss: 0.0156. gp: 0.0460 \n","[2300/3500] D(real): 1.56. D(fake): 1.19. rec_loss: 0.0165. gp: 0.2362 \n","[2400/3500] D(real): 1.48. D(fake): 1.23. rec_loss: 0.0146. gp: 0.0540 \n","[2500/3500] D(real): 1.54. D(fake): 1.22. rec_loss: 0.0141. gp: 0.0656 \n","[2600/3500] D(real): 1.58. D(fake): 1.15. rec_loss: 0.0143. gp: 0.3406 \n","[2700/3500] D(real): 1.58. D(fake): 1.16. rec_loss: 0.0138. gp: 0.1928 \n","[2800/3500] D(real): 1.52. D(fake): 1.10. rec_loss: 0.0140. gp: 0.3624 \n","[2900/3500] D(real): 1.52. D(fake): 1.13. rec_loss: 0.0137. gp: 0.1419 \n","[3000/3500] D(real): 1.57. D(fake): 1.11. rec_loss: 0.0136. gp: 0.4298 \n","[3100/3500] D(real): 1.58. D(fake): 1.15. rec_loss: 0.0138. gp: 0.3221 \n","[3200/3500] D(real): 1.59. D(fake): 1.08. rec_loss: 0.0146. gp: 0.0678 \n","[3300/3500] D(real): 1.58. D(fake): 1.15. rec_loss: 0.0137. gp: 0.3413 \n","[3400/3500] D(real): 1.56. D(fake): 1.13. rec_loss: 0.0147. gp: 0.3566 \n","Total time in scale 12: 569[sec] (0.16[sec]/epoch on avg.). D(real): 1.561611, D(fake): 1.129870, rec_loss: 0.0147. gp: 0.3566\n","****************************** Finished working on scale 12 ******************************\n","Signal in scale 11 has 19200 samples, sample rate is 800[Hz].\n","Total receptive field is 2551[msec] (10.6% of input).\n","[0/3500] D(real): 1.07. D(fake): 1.08. rec_loss: 0.0401. gp: 0.1471 \n","[100/3500] D(real): 1.05. D(fake): 0.91. rec_loss: 0.0312. gp: 0.0337 \n","[200/3500] D(real): 0.92. D(fake): 0.82. rec_loss: 0.0296. gp: 0.0134 \n","[300/3500] D(real): 0.90. D(fake): 0.84. rec_loss: 0.0279. gp: 0.0289 \n","[400/3500] D(real): 1.10. D(fake): 0.88. rec_loss: 0.0264. gp: 0.0823 \n","[500/3500] D(real): 0.96. D(fake): 0.89. rec_loss: 0.0245. gp: 0.0103 \n","[600/3500] D(real): 1.21. D(fake): 0.99. rec_loss: 0.0239. gp: 0.0851 \n","[700/3500] D(real): 0.98. D(fake): 0.86. rec_loss: 0.0218. gp: 0.0464 \n","[800/3500] D(real): 1.10. D(fake): 0.95. rec_loss: 0.0239. gp: 0.0491 \n","[900/3500] D(real): 1.14. D(fake): 0.90. rec_loss: 0.0207. gp: 0.1352 \n","[1000/3500] D(real): 1.09. D(fake): 0.95. rec_loss: 0.0199. gp: 0.0529 \n","[1100/3500] D(real): 0.93. D(fake): 0.92. rec_loss: 0.0202. gp: 0.0072 \n","[1200/3500] D(real): 1.02. D(fake): 0.97. rec_loss: 0.0185. gp: 0.0410 \n","[1300/3500] D(real): 1.15. D(fake): 1.07. rec_loss: 0.0189. gp: 0.0543 \n","[1400/3500] D(real): 1.22. D(fake): 1.10. rec_loss: 0.0175. gp: 0.0389 \n","[1500/3500] D(real): 1.31. D(fake): 1.16. rec_loss: 0.0179. gp: 0.0540 \n","[1600/3500] D(real): 1.37. D(fake): 1.23. rec_loss: 0.0298. gp: 0.0256 \n","[1700/3500] D(real): 1.45. D(fake): 1.19. rec_loss: 0.0174. gp: 0.1392 \n","[1800/3500] D(real): 1.19. D(fake): 1.11. rec_loss: 0.0171. gp: 0.0354 \n","[1900/3500] D(real): 1.35. D(fake): 1.15. rec_loss: 0.0164. gp: 0.0538 \n","[2000/3500] D(real): 1.18. D(fake): 1.13. rec_loss: 0.0161. gp: 0.0129 \n","[2100/3500] D(real): 1.42. D(fake): 1.25. rec_loss: 0.0157. gp: 0.0587 \n","[2200/3500] D(real): 1.49. D(fake): 1.19. rec_loss: 0.0164. gp: 0.3389 \n","[2300/3500] D(real): 1.57. D(fake): 1.26. rec_loss: 0.0160. gp: 0.0454 \n","[2400/3500] D(real): 1.64. D(fake): 1.29. rec_loss: 0.0146. gp: 0.1697 \n","[2500/3500] D(real): 1.67. D(fake): 1.28. rec_loss: 0.0144. gp: 0.1969 \n","[2600/3500] D(real): 1.60. D(fake): 1.28. rec_loss: 0.0146. gp: 0.0480 \n","[2700/3500] D(real): 1.66. D(fake): 1.34. rec_loss: 0.0147. gp: 0.2110 \n","[2800/3500] D(real): 1.68. D(fake): 1.27. rec_loss: 0.0148. gp: 0.0828 \n","[2900/3500] D(real): 1.70. D(fake): 1.29. rec_loss: 0.0143. gp: 0.2015 \n","[3000/3500] D(real): 1.63. D(fake): 1.29. rec_loss: 0.0146. gp: 0.0680 \n","[3100/3500] D(real): 1.61. D(fake): 1.28. rec_loss: 0.0166. gp: 0.0349 \n","[3200/3500] D(real): 1.63. D(fake): 1.27. rec_loss: 0.0151. gp: 0.1916 \n","[3300/3500] D(real): 1.70. D(fake): 1.34. rec_loss: 0.0144. gp: 0.1191 \n","[3400/3500] D(real): 1.66. D(fake): 1.27. rec_loss: 0.0149. gp: 0.0606 \n","Total time in scale 11: 735[sec] (0.21[sec]/epoch on avg.). D(real): 1.658553, D(fake): 1.269747, rec_loss: 0.0149. gp: 0.0606\n","****************************** Finished working on scale 11 ******************************\n","Signal in scale 10 has 24000 samples, sample rate is 1000[Hz].\n","Total receptive field is 2041[msec] (8.5% of input).\n","[0/3500] D(real): 1.22. D(fake): 1.22. rec_loss: 0.0533. gp: 0.2322 \n","[100/3500] D(real): 1.43. D(fake): 1.33. rec_loss: 0.0368. gp: 0.0418 \n","[200/3500] D(real): 1.55. D(fake): 1.38. rec_loss: 0.0333. gp: 0.0794 \n","[300/3500] D(real): 1.59. D(fake): 1.43. rec_loss: 0.0310. gp: 0.0538 \n","[400/3500] D(real): 1.70. D(fake): 1.50. rec_loss: 0.0323. gp: 0.1052 \n","[500/3500] D(real): 1.60. D(fake): 1.48. rec_loss: 0.0276. gp: 0.0356 \n","[600/3500] D(real): 1.52. D(fake): 1.45. rec_loss: 0.0278. gp: 0.0168 \n","[700/3500] D(real): 1.74. D(fake): 1.49. rec_loss: 0.0253. gp: 0.0915 \n","[800/3500] D(real): 1.48. D(fake): 1.45. rec_loss: 0.0365. gp: 0.0090 \n","[900/3500] D(real): 1.49. D(fake): 1.36. rec_loss: 0.0240. gp: 0.0441 \n","[1000/3500] D(real): 1.55. D(fake): 1.44. rec_loss: 0.0241. gp: 0.0525 \n","[1100/3500] D(real): 1.59. D(fake): 1.44. rec_loss: 0.0221. gp: 0.0523 \n","[1200/3500] D(real): 1.77. D(fake): 1.57. rec_loss: 0.0210. gp: 0.0618 \n","[1300/3500] D(real): 1.64. D(fake): 1.55. rec_loss: 0.0341. gp: 0.0524 \n","[1400/3500] D(real): 1.86. D(fake): 1.57. rec_loss: 0.0215. gp: 0.0767 \n","[1500/3500] D(real): 1.82. D(fake): 1.60. rec_loss: 0.0206. gp: 0.0844 \n","[1600/3500] D(real): 1.80. D(fake): 1.49. rec_loss: 0.0230. gp: 0.0934 \n","[1700/3500] D(real): 1.59. D(fake): 1.53. rec_loss: 0.0198. gp: 0.0166 \n","[1800/3500] D(real): 1.77. D(fake): 1.45. rec_loss: 0.0365. gp: 0.1708 \n","[1900/3500] D(real): 1.73. D(fake): 1.52. rec_loss: 0.0194. gp: 0.0841 \n","[2000/3500] D(real): 1.78. D(fake): 1.55. rec_loss: 0.0184. gp: 0.0736 \n","[2100/3500] D(real): 1.71. D(fake): 1.56. rec_loss: 0.0184. gp: 0.0556 \n","[2200/3500] D(real): 1.66. D(fake): 1.57. rec_loss: 0.0180. gp: 0.0590 \n","[2300/3500] D(real): 1.76. D(fake): 1.58. rec_loss: 0.0178. gp: 0.0350 \n","[2400/3500] D(real): 1.91. D(fake): 1.57. rec_loss: 0.0178. gp: 0.2379 \n","[2500/3500] D(real): 1.88. D(fake): 1.51. rec_loss: 0.0168. gp: 0.0598 \n","[2600/3500] D(real): 1.96. D(fake): 1.61. rec_loss: 0.0173. gp: 0.0723 \n","[2700/3500] D(real): 1.89. D(fake): 1.50. rec_loss: 0.0170. gp: 0.0500 \n","[2800/3500] D(real): 1.92. D(fake): 1.56. rec_loss: 0.0169. gp: 0.0680 \n","[2900/3500] D(real): 1.97. D(fake): 1.59. rec_loss: 0.0165. gp: 0.1797 \n","[3000/3500] D(real): 1.97. D(fake): 1.58. rec_loss: 0.0175. gp: 0.1835 \n","[3100/3500] D(real): 1.92. D(fake): 1.58. rec_loss: 0.0163. gp: 0.0751 \n","[3200/3500] D(real): 1.91. D(fake): 1.60. rec_loss: 0.0185. gp: 0.0433 \n","[3300/3500] D(real): 1.94. D(fake): 1.59. rec_loss: 0.0170. gp: 0.1180 \n","[3400/3500] D(real): 1.97. D(fake): 1.61. rec_loss: 0.0175. gp: 0.1259 \n","Total time in scale 10: 912[sec] (0.26[sec]/epoch on avg.). D(real): 1.967580, D(fake): 1.610780, rec_loss: 0.0175. gp: 0.1259\n","****************************** Finished working on scale 10 ******************************\n","Signal in scale 9 has 30720 samples, sample rate is 1280[Hz].\n","Total receptive field is 1594[msec] (6.6% of input).\n","[0/3500] D(real): 1.53. D(fake): 1.54. rec_loss: 0.0537. gp: 0.1327 \n","[100/3500] D(real): 1.60. D(fake): 1.53. rec_loss: 0.0387. gp: 0.0280 \n","[200/3500] D(real): 1.53. D(fake): 1.41. rec_loss: 0.0341. gp: 0.0518 \n","[300/3500] D(real): 1.42. D(fake): 1.32. rec_loss: 0.0310. gp: 0.0250 \n","[400/3500] D(real): 1.47. D(fake): 1.37. rec_loss: 0.0283. gp: 0.0717 \n","[500/3500] D(real): 1.37. D(fake): 1.32. rec_loss: 0.0275. gp: 0.0232 \n","[600/3500] D(real): 1.50. D(fake): 1.32. rec_loss: 0.0256. gp: 0.1790 \n","[700/3500] D(real): 1.52. D(fake): 1.33. rec_loss: 0.0242. gp: 0.0383 \n","[800/3500] D(real): 1.60. D(fake): 1.40. rec_loss: 0.0270. gp: 0.0708 \n","[900/3500] D(real): 1.52. D(fake): 1.41. rec_loss: 0.0256. gp: 0.0556 \n","[1000/3500] D(real): 1.56. D(fake): 1.37. rec_loss: 0.0367. gp: 0.0864 \n","[1100/3500] D(real): 1.31. D(fake): 1.29. rec_loss: 0.0394. gp: 0.0428 \n","[1200/3500] D(real): 1.41. D(fake): 1.18. rec_loss: 0.0334. gp: 0.1464 \n","[1300/3500] D(real): 1.45. D(fake): 1.30. rec_loss: 0.0205. gp: 0.0312 \n","[1400/3500] D(real): 1.47. D(fake): 1.28. rec_loss: 0.0207. gp: 0.1353 \n","[1500/3500] D(real): 1.61. D(fake): 1.41. rec_loss: 0.0391. gp: 0.0325 \n","[1600/3500] D(real): 1.69. D(fake): 1.41. rec_loss: 0.0220. gp: 0.0644 \n","[1700/3500] D(real): 1.28. D(fake): 1.19. rec_loss: 0.0197. gp: 0.0202 \n","[1800/3500] D(real): 1.32. D(fake): 1.23. rec_loss: 0.0210. gp: 0.0886 \n","[1900/3500] D(real): 1.56. D(fake): 1.39. rec_loss: 0.0196. gp: 0.0543 \n","[2000/3500] D(real): 1.58. D(fake): 1.45. rec_loss: 0.0397. gp: 0.0156 \n","[2100/3500] D(real): 1.69. D(fake): 1.49. rec_loss: 0.0317. gp: 0.1040 \n","[2200/3500] D(real): 1.49. D(fake): 1.47. rec_loss: 0.0203. gp: 0.0145 \n","[2300/3500] D(real): 1.49. D(fake): 1.36. rec_loss: 0.0189. gp: 0.0336 \n","[2400/3500] D(real): 1.55. D(fake): 1.39. rec_loss: 0.0174. gp: 0.0529 \n","[2500/3500] D(real): 1.59. D(fake): 1.41. rec_loss: 0.0172. gp: 0.1125 \n","[2600/3500] D(real): 1.56. D(fake): 1.39. rec_loss: 0.0171. gp: 0.0503 \n","[2700/3500] D(real): 1.60. D(fake): 1.41. rec_loss: 0.0169. gp: 0.1182 \n","[2800/3500] D(real): 1.62. D(fake): 1.39. rec_loss: 0.0169. gp: 0.1233 \n","[2900/3500] D(real): 1.65. D(fake): 1.42. rec_loss: 0.0168. gp: 0.1427 \n","[3000/3500] D(real): 1.68. D(fake): 1.45. rec_loss: 0.0168. gp: 0.0580 \n","[3100/3500] D(real): 1.71. D(fake): 1.43. rec_loss: 0.0167. gp: 0.1334 \n","[3200/3500] D(real): 1.71. D(fake): 1.44. rec_loss: 0.0168. gp: 0.0502 \n","[3300/3500] D(real): 1.72. D(fake): 1.47. rec_loss: 0.0167. gp: 0.0858 \n","[3400/3500] D(real): 1.74. D(fake): 1.44. rec_loss: 0.0168. gp: 0.0920 \n","Total time in scale 9: 1157[sec] (0.33[sec]/epoch on avg.). D(real): 1.739384, D(fake): 1.443465, rec_loss: 0.0168. gp: 0.0920\n","****************************** Finished working on scale 9 ******************************\n","Signal in scale 8 has 38400 samples, sample rate is 1600[Hz].\n","Total receptive field is 1275[msec] (5.3% of input).\n","[0/3500] D(real): 1.37. D(fake): 1.39. rec_loss: 0.0582. gp: 0.1071 \n","[100/3500] D(real): 1.35. D(fake): 1.34. rec_loss: 0.0393. gp: 0.0093 \n","[200/3500] D(real): 1.28. D(fake): 1.20. rec_loss: 0.0345. gp: 0.0315 \n","[300/3500] D(real): 1.29. D(fake): 1.25. rec_loss: 0.0459. gp: 0.0120 \n","[400/3500] D(real): 1.37. D(fake): 1.28. rec_loss: 0.0298. gp: 0.0221 \n","[500/3500] D(real): 1.33. D(fake): 1.30. rec_loss: 0.0287. gp: 0.0272 \n","[600/3500] D(real): 1.52. D(fake): 1.38. rec_loss: 0.0277. gp: 0.0629 \n","[700/3500] D(real): 1.60. D(fake): 1.49. rec_loss: 0.0258. gp: 0.0478 \n","[800/3500] D(real): 1.74. D(fake): 1.53. rec_loss: 0.0335. gp: 0.1448 \n","[900/3500] D(real): 1.59. D(fake): 1.50. rec_loss: 0.0245. gp: 0.0390 \n","[1000/3500] D(real): 1.79. D(fake): 1.55. rec_loss: 0.0260. gp: 0.0486 \n","[1100/3500] D(real): 1.78. D(fake): 1.65. rec_loss: 0.0230. gp: 0.0778 \n","[1200/3500] D(real): 1.56. D(fake): 1.50. rec_loss: 0.0442. gp: 0.0218 \n","[1300/3500] D(real): 1.65. D(fake): 1.50. rec_loss: 0.0231. gp: 0.0572 \n","[1400/3500] D(real): 1.38. D(fake): 1.31. rec_loss: 0.0261. gp: 0.0215 \n","[1500/3500] D(real): 1.27. D(fake): 1.24. rec_loss: 0.0233. gp: 0.0216 \n","[1600/3500] D(real): 1.64. D(fake): 1.37. rec_loss: 0.0234. gp: 0.0632 \n","[1700/3500] D(real): 1.57. D(fake): 1.37. rec_loss: 0.0221. gp: 0.1866 \n","[1800/3500] D(real): 1.43. D(fake): 1.36. rec_loss: 0.0415. gp: 0.0243 \n","[1900/3500] D(real): 1.28. D(fake): 1.24. rec_loss: 0.0207. gp: 0.0129 \n","[2000/3500] D(real): 1.55. D(fake): 1.23. rec_loss: 0.0220. gp: 0.1806 \n","[2100/3500] D(real): 1.53. D(fake): 1.41. rec_loss: 0.0203. gp: 0.0310 \n","[2200/3500] D(real): 1.63. D(fake): 1.40. rec_loss: 0.0217. gp: 0.0686 \n","[2300/3500] D(real): 1.63. D(fake): 1.40. rec_loss: 0.0199. gp: 0.0935 \n","[2400/3500] D(real): 1.50. D(fake): 1.31. rec_loss: 0.0188. gp: 0.0682 \n","[2500/3500] D(real): 1.56. D(fake): 1.34. rec_loss: 0.0184. gp: 0.0847 \n","[2600/3500] D(real): 1.57. D(fake): 1.30. rec_loss: 0.0182. gp: 0.2387 \n","[2700/3500] D(real): 1.59. D(fake): 1.33. rec_loss: 0.0181. gp: 0.0466 \n","[2800/3500] D(real): 1.63. D(fake): 1.29. rec_loss: 0.0181. gp: 0.0667 \n","[2900/3500] D(real): 1.66. D(fake): 1.35. rec_loss: 0.0185. gp: 0.2774 \n","[3000/3500] D(real): 1.66. D(fake): 1.33. rec_loss: 0.0181. gp: 0.0501 \n","[3100/3500] D(real): 1.64. D(fake): 1.38. rec_loss: 0.0183. gp: 0.0555 \n","[3200/3500] D(real): 1.67. D(fake): 1.39. rec_loss: 0.0183. gp: 0.1023 \n","[3300/3500] D(real): 1.69. D(fake): 1.41. rec_loss: 0.0181. gp: 0.0491 \n","[3400/3500] D(real): 1.72. D(fake): 1.41. rec_loss: 0.0180. gp: 0.0888 \n","Total time in scale 8: 1420[sec] (0.41[sec]/epoch on avg.). D(real): 1.719421, D(fake): 1.409668, rec_loss: 0.0180. gp: 0.0888\n","****************************** Finished working on scale 8 ******************************\n","Signal in scale 7 has 48000 samples, sample rate is 2000[Hz].\n","Total receptive field is 1020[msec] (4.3% of input).\n","[0/3500] D(real): 1.30. D(fake): 1.39. rec_loss: 0.0809. gp: 0.2170 \n","[100/3500] D(real): 1.30. D(fake): 1.25. rec_loss: 0.0589. gp: 0.0566 \n","[200/3500] D(real): 1.24. D(fake): 1.18. rec_loss: 0.0491. gp: 0.0309 \n","[300/3500] D(real): 1.12. D(fake): 1.01. rec_loss: 0.0426. gp: 0.0918 \n","[400/3500] D(real): 1.10. D(fake): 1.02. rec_loss: 0.0390. gp: 0.0238 \n","[500/3500] D(real): 1.12. D(fake): 1.04. rec_loss: 0.0367. gp: 0.0576 \n","[600/3500] D(real): 1.19. D(fake): 1.10. rec_loss: 0.0395. gp: 0.0320 \n","[700/3500] D(real): 1.03. D(fake): 1.02. rec_loss: 0.0330. gp: 0.0155 \n","[800/3500] D(real): 1.20. D(fake): 1.00. rec_loss: 0.0322. gp: 0.0379 \n","[900/3500] D(real): 1.14. D(fake): 0.92. rec_loss: 0.0311. gp: 0.1291 \n","[1000/3500] D(real): 1.15. D(fake): 1.08. rec_loss: 0.0295. gp: 0.0169 \n","[1100/3500] D(real): 1.00. D(fake): 0.98. rec_loss: 0.0300. gp: 0.0249 \n","[1200/3500] D(real): 1.13. D(fake): 0.95. rec_loss: 0.0264. gp: 0.0508 \n","[1300/3500] D(real): 1.01. D(fake): 0.92. rec_loss: 0.0268. gp: 0.0481 \n","[1400/3500] D(real): 1.08. D(fake): 0.97. rec_loss: 0.0244. gp: 0.0514 \n","[1500/3500] D(real): 1.17. D(fake): 1.07. rec_loss: 0.0243. gp: 0.0255 \n","[1600/3500] D(real): 1.17. D(fake): 1.13. rec_loss: 0.0237. gp: 0.0183 \n","[1700/3500] D(real): 1.33. D(fake): 1.19. rec_loss: 0.0279. gp: 0.0322 \n","[1800/3500] D(real): 1.21. D(fake): 1.09. rec_loss: 0.0235. gp: 0.0306 \n","[1900/3500] D(real): 1.18. D(fake): 1.12. rec_loss: 0.0212. gp: 0.0112 \n","[2000/3500] D(real): 1.30. D(fake): 1.14. rec_loss: 0.0214. gp: 0.0389 \n","[2100/3500] D(real): 1.09. D(fake): 1.08. rec_loss: 0.0213. gp: 0.0062 \n","[2200/3500] D(real): 1.05. D(fake): 1.00. rec_loss: 0.0202. gp: 0.0204 \n","[2300/3500] D(real): 1.08. D(fake): 0.92. rec_loss: 0.0208. gp: 0.0595 \n","[2400/3500] D(real): 1.25. D(fake): 1.03. rec_loss: 0.0185. gp: 0.1471 \n","[2500/3500] D(real): 1.27. D(fake): 1.09. rec_loss: 0.0183. gp: 0.1756 \n","[2600/3500] D(real): 1.27. D(fake): 1.06. rec_loss: 0.0182. gp: 0.0736 \n","[2700/3500] D(real): 1.31. D(fake): 1.10. rec_loss: 0.0180. gp: 0.0409 \n","[2800/3500] D(real): 1.33. D(fake): 1.10. rec_loss: 0.0180. gp: 0.0685 \n","[2900/3500] D(real): 1.37. D(fake): 1.13. rec_loss: 0.0179. gp: 0.0367 \n","[3000/3500] D(real): 1.43. D(fake): 1.15. rec_loss: 0.0179. gp: 0.0395 \n","[3100/3500] D(real): 1.46. D(fake): 1.18. rec_loss: 0.0181. gp: 0.0485 \n","[3200/3500] D(real): 1.48. D(fake): 1.21. rec_loss: 0.0178. gp: 0.0465 \n","[3300/3500] D(real): 1.45. D(fake): 1.23. rec_loss: 0.0178. gp: 0.0372 \n","[3400/3500] D(real): 1.52. D(fake): 1.21. rec_loss: 0.0179. gp: 0.0551 \n","Total time in scale 7: 1817[sec] (0.52[sec]/epoch on avg.). D(real): 1.515248, D(fake): 1.211375, rec_loss: 0.0179. gp: 0.0551\n","****************************** Finished working on scale 7 ******************************\n","Signal in scale 6 has 60000 samples, sample rate is 2500[Hz].\n","Total receptive field is 816[msec] (3.4% of input).\n","[0/3500] D(real): 1.15. D(fake): 1.11. rec_loss: 0.0801. gp: 0.1709 \n","[100/3500] D(real): 1.14. D(fake): 1.10. rec_loss: 0.0593. gp: 0.0273 \n","[200/3500] D(real): 1.03. D(fake): 0.96. rec_loss: 0.0514. gp: 0.0572 \n","[300/3500] D(real): 0.96. D(fake): 0.91. rec_loss: 0.0473. gp: 0.0170 \n","[400/3500] D(real): 1.03. D(fake): 0.93. rec_loss: 0.0419. gp: 0.0513 \n","[500/3500] D(real): 1.00. D(fake): 0.89. rec_loss: 0.0380. gp: 0.0318 \n","[600/3500] D(real): 0.95. D(fake): 0.85. rec_loss: 0.0405. gp: 0.0179 \n","[700/3500] D(real): 0.96. D(fake): 0.83. rec_loss: 0.0395. gp: 0.1463 \n","[800/3500] D(real): 0.93. D(fake): 0.84. rec_loss: 0.0344. gp: 0.0175 \n","[900/3500] D(real): 1.07. D(fake): 0.94. rec_loss: 0.0315. gp: 0.0642 \n","[1000/3500] D(real): 0.97. D(fake): 0.91. rec_loss: 0.0313. gp: 0.0135 \n","[1100/3500] D(real): 1.08. D(fake): 0.92. rec_loss: 0.0314. gp: 0.2245 \n","[1200/3500] D(real): 1.03. D(fake): 0.89. rec_loss: 0.0294. gp: 0.0349 \n","[1300/3500] D(real): 0.99. D(fake): 0.88. rec_loss: 0.0278. gp: 0.0244 \n","[1400/3500] D(real): 1.11. D(fake): 0.92. rec_loss: 0.0277. gp: 0.0467 \n","[1500/3500] D(real): 1.04. D(fake): 0.88. rec_loss: 0.0271. gp: 0.0283 \n","[1600/3500] D(real): 1.08. D(fake): 0.90. rec_loss: 0.0383. gp: 0.0366 \n","[1700/3500] D(real): 1.02. D(fake): 0.92. rec_loss: 0.0260. gp: 0.0719 \n","[1800/3500] D(real): 0.94. D(fake): 0.83. rec_loss: 0.0246. gp: 0.0311 \n","[1900/3500] D(real): 1.03. D(fake): 0.84. rec_loss: 0.0253. gp: 0.1323 \n","[2000/3500] D(real): 0.88. D(fake): 0.85. rec_loss: 0.0244. gp: 0.0183 \n","[2100/3500] D(real): 1.01. D(fake): 0.81. rec_loss: 0.0303. gp: 0.0592 \n","[2200/3500] D(real): 0.95. D(fake): 0.76. rec_loss: 0.0228. gp: 0.0726 \n","[2300/3500] D(real): 0.94. D(fake): 0.86. rec_loss: 0.0221. gp: 0.0257 \n","[2400/3500] D(real): 1.01. D(fake): 0.77. rec_loss: 0.0208. gp: 0.0378 \n","[2500/3500] D(real): 1.06. D(fake): 0.81. rec_loss: 0.0216. gp: 0.0552 \n","[2600/3500] D(real): 1.10. D(fake): 0.83. rec_loss: 0.0212. gp: 0.0390 \n","[2700/3500] D(real): 1.12. D(fake): 0.84. rec_loss: 0.0203. gp: 0.2862 \n","[2800/3500] D(real): 1.14. D(fake): 0.87. rec_loss: 0.0206. gp: 0.0424 \n","[2900/3500] D(real): 1.16. D(fake): 0.85. rec_loss: 0.0206. gp: 0.0517 \n","[3000/3500] D(real): 1.18. D(fake): 0.88. rec_loss: 0.0220. gp: 0.0809 \n","[3100/3500] D(real): 1.13. D(fake): 0.88. rec_loss: 0.0205. gp: 0.1389 \n","[3200/3500] D(real): 1.13. D(fake): 0.87. rec_loss: 0.0207. gp: 0.0280 \n","[3300/3500] D(real): 1.18. D(fake): 0.87. rec_loss: 0.0207. gp: 0.0510 \n","[3400/3500] D(real): 1.20. D(fake): 0.90. rec_loss: 0.0210. gp: 0.3448 \n","Total time in scale 6: 2199[sec] (0.63[sec]/epoch on avg.). D(real): 1.198999, D(fake): 0.896880, rec_loss: 0.0210. gp: 0.3448\n","****************************** Finished working on scale 6 ******************************\n","Signal in scale 5 has 96000 samples, sample rate is 4000[Hz].\n","Total receptive field is 510[msec] (2.1% of input).\n","[0/3500] D(real): 0.86. D(fake): 0.92. rec_loss: 0.1201. gp: 0.1307 \n","[100/3500] D(real): 0.87. D(fake): 0.84. rec_loss: 0.0891. gp: 0.0199 \n","[200/3500] D(real): 0.69. D(fake): 0.63. rec_loss: 0.1143. gp: 0.0519 \n","[300/3500] D(real): 0.40. D(fake): 0.35. rec_loss: 0.0620. gp: 0.0217 \n","[400/3500] D(real): 0.20. D(fake): 0.18. rec_loss: 0.0574. gp: 0.0091 \n","[500/3500] D(real): 0.16. D(fake): 0.14. rec_loss: 0.0508. gp: 0.0075 \n","[600/3500] D(real): 0.08. D(fake): 0.04. rec_loss: 0.0467. gp: 0.0172 \n","[700/3500] D(real): 0.09. D(fake): 0.03. rec_loss: 0.0446. gp: 0.0129 \n","[800/3500] D(real): 0.09. D(fake): 0.03. rec_loss: 0.0422. gp: 0.0174 \n","[900/3500] D(real): 0.11. D(fake): 0.05. rec_loss: 0.0407. gp: 0.0263 \n","[1000/3500] D(real): 0.05. D(fake): 0.03. rec_loss: 0.0382. gp: 0.0122 \n","[1100/3500] D(real): 0.12. D(fake): 0.04. rec_loss: 0.0371. gp: 0.0163 \n","[1200/3500] D(real): 0.08. D(fake): 0.04. rec_loss: 0.0351. gp: 0.0226 \n","[1300/3500] D(real): 0.10. D(fake): 0.05. rec_loss: 0.0352. gp: 0.0175 \n","[1400/3500] D(real): 0.10. D(fake): 0.08. rec_loss: 0.0341. gp: 0.0095 \n","[1500/3500] D(real): 0.20. D(fake): 0.10. rec_loss: 0.0465. gp: 0.0444 \n","[1600/3500] D(real): 0.23. D(fake): 0.16. rec_loss: 0.0327. gp: 0.0386 \n","[1700/3500] D(real): 0.27. D(fake): 0.18. rec_loss: 0.0326. gp: 0.0493 \n","[1800/3500] D(real): 0.28. D(fake): 0.19. rec_loss: 0.0320. gp: 0.0582 \n","[1900/3500] D(real): 0.29. D(fake): 0.17. rec_loss: 0.0311. gp: 0.0205 \n","[2000/3500] D(real): 0.16. D(fake): 0.14. rec_loss: 0.0287. gp: 0.0053 \n","[2100/3500] D(real): 0.25. D(fake): 0.13. rec_loss: 0.0293. gp: 0.0266 \n","[2200/3500] D(real): 0.31. D(fake): 0.23. rec_loss: 0.0293. gp: 0.0183 \n","[2300/3500] D(real): 0.24. D(fake): 0.23. rec_loss: 0.0272. gp: 0.0096 \n","[2400/3500] D(real): 0.36. D(fake): 0.22. rec_loss: 0.0253. gp: 0.1004 \n","[2500/3500] D(real): 0.37. D(fake): 0.20. rec_loss: 0.0250. gp: 0.0176 \n","[2600/3500] D(real): 0.39. D(fake): 0.25. rec_loss: 0.0248. gp: 0.1574 \n","[2700/3500] D(real): 0.40. D(fake): 0.26. rec_loss: 0.0247. gp: 0.0729 \n","[2800/3500] D(real): 0.41. D(fake): 0.26. rec_loss: 0.0251. gp: 0.0144 \n","[2900/3500] D(real): 0.39. D(fake): 0.26. rec_loss: 0.0247. gp: 0.0337 \n","[3000/3500] D(real): 0.39. D(fake): 0.26. rec_loss: 0.0264. gp: 0.0139 \n","[3100/3500] D(real): 0.47. D(fake): 0.30. rec_loss: 0.0246. gp: 0.0274 \n","[3200/3500] D(real): 0.43. D(fake): 0.30. rec_loss: 0.0257. gp: 0.0152 \n","[3300/3500] D(real): 0.46. D(fake): 0.29. rec_loss: 0.0246. gp: 0.0151 \n","[3400/3500] D(real): 0.45. D(fake): 0.31. rec_loss: 0.0248. gp: 0.0418 \n","Total time in scale 5: 3342[sec] (0.95[sec]/epoch on avg.). D(real): 0.452371, D(fake): 0.308203, rec_loss: 0.0248. gp: 0.0418\n","****************************** Finished working on scale 5 ******************************\n","Signal in scale 4 has 192000 samples, sample rate is 8000[Hz].\n","Total receptive field is 255[msec] (1.1% of input).\n","[0/3500] D(real): 0.23. D(fake): 0.26. rec_loss: 0.1847. gp: 0.0388 \n","[100/3500] D(real): 0.26. D(fake): 0.25. rec_loss: 0.1249. gp: 0.0096 \n","[200/3500] D(real): 0.21. D(fake): 0.20. rec_loss: 0.0997. gp: 0.0088 \n","[300/3500] D(real): 0.17. D(fake): 0.15. rec_loss: 0.0880. gp: 0.0060 \n","[400/3500] D(real): 0.03. D(fake): 0.01. rec_loss: 0.0791. gp: 0.0088 \n","[500/3500] D(real): -0.00. D(fake): -0.04. rec_loss: 0.0731. gp: 0.0122 \n","[600/3500] D(real): -0.18. D(fake): -0.21. rec_loss: 0.0702. gp: 0.0107 \n","[700/3500] D(real): -0.28. D(fake): -0.29. rec_loss: 0.0669. gp: 0.0074 \n","[800/3500] D(real): -0.37. D(fake): -0.40. rec_loss: 0.0644. gp: 0.0122 \n","[900/3500] D(real): -0.45. D(fake): -0.50. rec_loss: 0.0628. gp: 0.0262 \n","[1000/3500] D(real): -0.58. D(fake): -0.61. rec_loss: 0.0596. gp: 0.0081 \n","[1100/3500] D(real): -0.60. D(fake): -0.65. rec_loss: 0.0559. gp: 0.0291 \n","[1200/3500] D(real): -0.64. D(fake): -0.70. rec_loss: 0.0545. gp: 0.0196 \n","[1300/3500] D(real): -0.76. D(fake): -0.81. rec_loss: 0.0530. gp: 0.0079 \n","[1400/3500] D(real): -0.77. D(fake): -0.82. rec_loss: 0.0515. gp: 0.0098 \n","[1500/3500] D(real): -0.77. D(fake): -0.83. rec_loss: 0.0507. gp: 0.0492 \n","[1600/3500] D(real): -0.88. D(fake): -0.88. rec_loss: 0.0474. gp: 0.0047 \n","[1700/3500] D(real): -0.84. D(fake): -0.86. rec_loss: 0.0469. gp: 0.0089 \n","[1800/3500] D(real): -0.80. D(fake): -0.85. rec_loss: 0.0467. gp: 0.0300 \n","[1900/3500] D(real): -0.79. D(fake): -0.82. rec_loss: 0.0448. gp: 0.0079 \n","[2000/3500] D(real): -0.68. D(fake): -0.71. rec_loss: 0.1818. gp: 0.1431 \n","[2100/3500] D(real): -0.56. D(fake): -0.60. rec_loss: 0.1676. gp: 0.0271 \n","[2200/3500] D(real): -0.49. D(fake): -0.50. rec_loss: 0.1525. gp: 0.0073 \n","[2300/3500] D(real): -0.46. D(fake): -0.48. rec_loss: 0.1365. gp: 0.0096 \n","[2400/3500] D(real): -0.45. D(fake): -0.47. rec_loss: 0.1310. gp: 0.0080 \n","[2500/3500] D(real): -0.45. D(fake): -0.48. rec_loss: 0.1297. gp: 0.0082 \n","[2600/3500] D(real): -0.45. D(fake): -0.48. rec_loss: 0.1281. gp: 0.0069 \n","[2700/3500] D(real): -0.46. D(fake): -0.48. rec_loss: 0.1262. gp: 0.0070 \n","[2800/3500] D(real): -0.46. D(fake): -0.48. rec_loss: 0.1245. gp: 0.0118 \n","[2900/3500] D(real): -0.46. D(fake): -0.48. rec_loss: 0.1227. gp: 0.0080 \n","[3000/3500] D(real): -0.47. D(fake): -0.50. rec_loss: 0.1210. gp: 0.0114 \n","[3100/3500] D(real): -0.47. D(fake): -0.50. rec_loss: 0.1192. gp: 0.0106 \n","[3200/3500] D(real): -0.46. D(fake): -0.49. rec_loss: 0.1175. gp: 0.0085 \n","[3300/3500] D(real): -0.47. D(fake): -0.49. rec_loss: 0.1158. gp: 0.0070 \n","[3400/3500] D(real): -0.47. D(fake): -0.50. rec_loss: 0.1142. gp: 0.0068 \n","Total time in scale 4: 6265[sec] (1.79[sec]/epoch on avg.). D(real): -0.472175, D(fake): -0.497589, rec_loss: 0.1142. gp: 0.0068\n","****************************** Finished working on scale 4 ******************************\n","Signal in scale 3 has 240000 samples, sample rate is 10000[Hz].\n","Total receptive field is 204[msec] (0.9% of input).\n","[0/3500] D(real): -0.50. D(fake): -0.50. rec_loss: 0.2190. gp: 0.0070 \n","[100/3500] D(real): -0.49. D(fake): -0.49. rec_loss: 0.1309. gp: 0.0058 \n","[200/3500] D(real): -0.49. D(fake): -0.50. rec_loss: 0.1141. gp: 0.0055 \n","[300/3500] D(real): -0.50. D(fake): -0.51. rec_loss: 0.1023. gp: 0.0063 \n","[400/3500] D(real): -0.50. D(fake): -0.52. rec_loss: 0.0933. gp: 0.0074 \n","[500/3500] D(real): -0.47. D(fake): -0.49. rec_loss: 0.0891. gp: 0.0064 \n","[600/3500] D(real): -0.46. D(fake): -0.49. rec_loss: 0.0851. gp: 0.0134 \n","[700/3500] D(real): -0.47. D(fake): -0.50. rec_loss: 0.0797. gp: 0.0166 \n","[800/3500] D(real): -0.48. D(fake): -0.51. rec_loss: 0.0757. gp: 0.0061 \n","[900/3500] D(real): -0.46. D(fake): -0.48. rec_loss: 0.0727. gp: 0.0093 \n","[1000/3500] D(real): -0.52. D(fake): -0.55. rec_loss: 0.0696. gp: 0.0128 \n","[1100/3500] D(real): -0.49. D(fake): -0.52. rec_loss: 0.0698. gp: 0.0099 \n","[1200/3500] D(real): -0.43. D(fake): -0.46. rec_loss: 0.0671. gp: 0.0108 \n","[1300/3500] D(real): -0.42. D(fake): -0.46. rec_loss: 0.0651. gp: 0.0124 \n","[1400/3500] D(real): -0.39. D(fake): -0.44. rec_loss: 0.0632. gp: 0.0181 \n","[1500/3500] D(real): -0.40. D(fake): -0.42. rec_loss: 0.0624. gp: 0.0118 \n","[1600/3500] D(real): -0.42. D(fake): -0.43. rec_loss: 0.0597. gp: 0.0043 \n","[1700/3500] D(real): -0.40. D(fake): -0.43. rec_loss: 0.0594. gp: 0.0141 \n","[1800/3500] D(real): -0.40. D(fake): -0.44. rec_loss: 0.0584. gp: 0.0249 \n","[1900/3500] D(real): -0.35. D(fake): -0.40. rec_loss: 0.0580. gp: 0.0244 \n","[2000/3500] D(real): -0.44. D(fake): -0.48. rec_loss: 0.0567. gp: 0.0088 \n","[2100/3500] D(real): -0.37. D(fake): -0.43. rec_loss: 0.0557. gp: 0.0398 \n","[2200/3500] D(real): -0.30. D(fake): -0.35. rec_loss: 0.0549. gp: 0.0169 \n","[2300/3500] D(real): -0.32. D(fake): -0.38. rec_loss: 0.0566. gp: 0.0429 \n","[2400/3500] D(real): -0.35. D(fake): -0.40. rec_loss: 0.0494. gp: 0.0119 \n","[2500/3500] D(real): -0.34. D(fake): -0.41. rec_loss: 0.0492. gp: 0.0522 \n","[2600/3500] D(real): -0.33. D(fake): -0.42. rec_loss: 0.0492. gp: 0.0132 \n","[2700/3500] D(real): -0.35. D(fake): -0.43. rec_loss: 0.0491. gp: 0.0143 \n","[2800/3500] D(real): -0.37. D(fake): -0.44. rec_loss: 0.0490. gp: 0.0230 \n","[2900/3500] D(real): -0.38. D(fake): -0.45. rec_loss: 0.0491. gp: 0.0922 \n","[3000/3500] D(real): -0.38. D(fake): -0.46. rec_loss: 0.0491. gp: 0.0198 \n","[3100/3500] D(real): -0.39. D(fake): -0.47. rec_loss: 0.0489. gp: 0.0124 \n","[3200/3500] D(real): -0.40. D(fake): -0.49. rec_loss: 0.0488. gp: 0.0445 \n","[3300/3500] D(real): -0.42. D(fake): -0.49. rec_loss: 0.0487. gp: 0.0261 \n","[3400/3500] D(real): -0.43. D(fake): -0.50. rec_loss: 0.0487. gp: 0.0208 \n","Total time in scale 3: 7904[sec] (2.26[sec]/epoch on avg.). D(real): -0.432927, D(fake): -0.503631, rec_loss: 0.0487. gp: 0.0208\n","****************************** Finished working on scale 3 ******************************\n","Signal in scale 2 has 288000 samples, sample rate is 12000[Hz].\n","Total receptive field is 170[msec] (0.7% of input).\n","[0/3500] D(real): -0.50. D(fake): -0.51. rec_loss: 0.2411. gp: 0.0308 \n","[100/3500] D(real): -0.39. D(fake): -0.42. rec_loss: 0.1284. gp: 0.0160 \n","[200/3500] D(real): -0.45. D(fake): -0.47. rec_loss: 0.1109. gp: 0.0072 \n","[300/3500] D(real): -0.46. D(fake): -0.47. rec_loss: 0.0998. gp: 0.0076 \n","[400/3500] D(real): -0.49. D(fake): -0.49. rec_loss: 0.0923. gp: 0.0061 \n","[500/3500] D(real): -0.45. D(fake): -0.47. rec_loss: 0.0884. gp: 0.0109 \n","[600/3500] D(real): -0.56. D(fake): -0.58. rec_loss: 0.0833. gp: 0.0061 \n","[700/3500] D(real): -0.55. D(fake): -0.57. rec_loss: 0.0797. gp: 0.0049 \n","[800/3500] D(real): -0.54. D(fake): -0.56. rec_loss: 0.0787. gp: 0.0131 \n","[900/3500] D(real): -0.56. D(fake): -0.62. rec_loss: 0.0773. gp: 0.0122 \n","[1000/3500] D(real): -0.57. D(fake): -0.62. rec_loss: 0.0735. gp: 0.0131 \n","[1100/3500] D(real): -0.61. D(fake): -0.63. rec_loss: 0.0709. gp: 0.0067 \n","[1200/3500] D(real): -0.61. D(fake): -0.67. rec_loss: 0.0702. gp: 0.0507 \n","[1300/3500] D(real): -0.64. D(fake): -0.70. rec_loss: 0.0698. gp: 0.0127 \n","[1400/3500] D(real): -0.74. D(fake): -0.76. rec_loss: 0.0682. gp: 0.0089 \n","[1500/3500] D(real): -0.69. D(fake): -0.78. rec_loss: 0.0666. gp: 0.0269 \n","[1600/3500] D(real): -0.70. D(fake): -0.74. rec_loss: 0.0643. gp: 0.0138 \n","[1700/3500] D(real): -0.66. D(fake): -0.71. rec_loss: 0.0620. gp: 0.0190 \n","[1800/3500] D(real): -0.68. D(fake): -0.75. rec_loss: 0.0620. gp: 0.0759 \n","[1900/3500] D(real): -0.74. D(fake): -0.79. rec_loss: 0.0617. gp: 0.0111 \n","[2000/3500] D(real): -0.73. D(fake): -0.79. rec_loss: 0.0606. gp: 0.0131 \n","[2100/3500] D(real): -0.73. D(fake): -0.76. rec_loss: 0.0589. gp: 0.0083 \n","[2200/3500] D(real): -0.71. D(fake): -0.76. rec_loss: 0.0589. gp: 0.0100 \n","[2300/3500] D(real): -0.74. D(fake): -0.78. rec_loss: 0.0589. gp: 0.0111 \n","[2400/3500] D(real): -0.69. D(fake): -0.75. rec_loss: 0.0538. gp: 0.0129 \n","[2500/3500] D(real): -0.71. D(fake): -0.78. rec_loss: 0.0536. gp: 0.0248 \n","[2600/3500] D(real): -0.73. D(fake): -0.81. rec_loss: 0.0536. gp: 0.0600 \n","[2700/3500] D(real): -0.72. D(fake): -0.80. rec_loss: 0.0536. gp: 0.0448 \n","[2800/3500] D(real): -0.76. D(fake): -0.83. rec_loss: 0.0534. gp: 0.0185 \n","[2900/3500] D(real): -0.73. D(fake): -0.82. rec_loss: 0.0532. gp: 0.0106 \n","[3000/3500] D(real): -0.73. D(fake): -0.84. rec_loss: 0.0532. gp: 0.0113 \n","[3100/3500] D(real): -0.75. D(fake): -0.83. rec_loss: 0.0535. gp: 0.0096 \n","[3200/3500] D(real): -0.75. D(fake): -0.85. rec_loss: 0.0532. gp: 0.1649 \n","[3300/3500] D(real): -0.77. D(fake): -0.87. rec_loss: 0.0530. gp: 0.0215 \n","[3400/3500] D(real): -0.78. D(fake): -0.86. rec_loss: 0.0528. gp: 0.0474 \n","Total time in scale 2: 9626[sec] (2.75[sec]/epoch on avg.). D(real): -0.784794, D(fake): -0.855157, rec_loss: 0.0528. gp: 0.0474\n","****************************** Finished working on scale 2 ******************************\n","Signal in scale 1 has 345600 samples, sample rate is 14400[Hz].\n","Total receptive field is 141[msec] (0.6% of input).\n","[0/3500] D(real): -0.85. D(fake): -0.86. rec_loss: 0.2551. gp: 0.0911 \n","[100/3500] D(real): -0.81. D(fake): -0.83. rec_loss: 0.1401. gp: 0.0120 \n","[200/3500] D(real): -0.80. D(fake): -0.83. rec_loss: 0.1205. gp: 0.0070 \n","[300/3500] D(real): -0.78. D(fake): -0.81. rec_loss: 0.1100. gp: 0.0084 \n","[400/3500] D(real): -0.83. D(fake): -0.89. rec_loss: 0.1027. gp: 0.1302 \n","[500/3500] D(real): -0.77. D(fake): -0.80. rec_loss: 0.0954. gp: 0.0158 \n","[600/3500] D(real): -0.76. D(fake): -0.82. rec_loss: 0.0927. gp: 0.0337 \n","[700/3500] D(real): -0.78. D(fake): -0.81. rec_loss: 0.0868. gp: 0.0073 \n","[800/3500] D(real): -0.76. D(fake): -0.80. rec_loss: 0.0853. gp: 0.0187 \n","[900/3500] D(real): -0.74. D(fake): -0.80. rec_loss: 0.0835. gp: 0.0086 \n","[1000/3500] D(real): -0.77. D(fake): -0.82. rec_loss: 0.0821. gp: 0.0158 \n","[1100/3500] D(real): -0.74. D(fake): -0.80. rec_loss: 0.0817. gp: 0.0285 \n","[1200/3500] D(real): -0.78. D(fake): -0.82. rec_loss: 0.0780. gp: 0.0144 \n","[1300/3500] D(real): -0.79. D(fake): -0.87. rec_loss: 0.0762. gp: 0.0294 \n","[1400/3500] D(real): -0.76. D(fake): -0.78. rec_loss: 0.0737. gp: 0.0064 \n","[1500/3500] D(real): -0.69. D(fake): -0.74. rec_loss: 0.0717. gp: 0.0165 \n","[1600/3500] D(real): -0.63. D(fake): -0.70. rec_loss: 0.0729. gp: 0.0152 \n","[1700/3500] D(real): -0.67. D(fake): -0.72. rec_loss: 0.0708. gp: 0.0086 \n","[1800/3500] D(real): -0.63. D(fake): -0.70. rec_loss: 0.0712. gp: 0.0334 \n","[1900/3500] D(real): -0.68. D(fake): -0.71. rec_loss: 0.0686. gp: 0.0145 \n","[2000/3500] D(real): -0.65. D(fake): -0.73. rec_loss: 0.0683. gp: 0.1042 \n","[2100/3500] D(real): -0.77. D(fake): -0.77. rec_loss: 0.0661. gp: 0.0080 \n","[2200/3500] D(real): -0.69. D(fake): -0.71. rec_loss: 0.0653. gp: 0.0091 \n","[2300/3500] D(real): -0.67. D(fake): -0.75. rec_loss: 0.0674. gp: 0.0356 \n","[2400/3500] D(real): -0.70. D(fake): -0.78. rec_loss: 0.0605. gp: 0.0173 \n","[2500/3500] D(real): -0.69. D(fake): -0.77. rec_loss: 0.0603. gp: 0.0576 \n","[2600/3500] D(real): -0.72. D(fake): -0.78. rec_loss: 0.0602. gp: 0.0142 \n","[2700/3500] D(real): -0.68. D(fake): -0.77. rec_loss: 0.0601. gp: 0.0109 \n","[2800/3500] D(real): -0.71. D(fake): -0.80. rec_loss: 0.0602. gp: 0.0193 \n","[2900/3500] D(real): -0.71. D(fake): -0.81. rec_loss: 0.0599. gp: 0.0412 \n","[3000/3500] D(real): -0.72. D(fake): -0.82. rec_loss: 0.0600. gp: 0.0540 \n","[3100/3500] D(real): -0.74. D(fake): -0.83. rec_loss: 0.0602. gp: 0.0739 \n","[3200/3500] D(real): -0.80. D(fake): -0.85. rec_loss: 0.0596. gp: 0.0402 \n","[3300/3500] D(real): -0.76. D(fake): -0.85. rec_loss: 0.0594. gp: 0.0228 \n","[3400/3500] D(real): -0.75. D(fake): -0.84. rec_loss: 0.0593. gp: 0.0130 \n","Total time in scale 1: 11672[sec] (3.33[sec]/epoch on avg.). D(real): -0.754308, D(fake): -0.841176, rec_loss: 0.0593. gp: 0.0130\n","****************************** Finished working on scale 1 ******************************\n","Signal in scale 0 has 384000 samples, sample rate is 16000[Hz].\n","Total receptive field is 127[msec] (0.5% of input).\n","[0/3500] D(real): -0.83. D(fake): -0.87. rec_loss: 0.2590. gp: 0.0176 \n","[100/3500] D(real): -0.85. D(fake): -0.85. rec_loss: 0.1407. gp: 0.0074 \n","[200/3500] D(real): -0.79. D(fake): -0.82. rec_loss: 0.1218. gp: 0.0097 \n","[300/3500] D(real): -0.76. D(fake): -0.80. rec_loss: 0.1121. gp: 0.0207 \n","[400/3500] D(real): -0.82. D(fake): -0.87. rec_loss: 0.1064. gp: 0.0338 \n","[500/3500] D(real): -0.88. D(fake): -0.88. rec_loss: 0.0972. gp: 0.0057 \n","[600/3500] D(real): -0.82. D(fake): -0.86. rec_loss: 0.0948. gp: 0.0130 \n","[700/3500] D(real): -0.87. D(fake): -0.90. rec_loss: 0.0926. gp: 0.0099 \n","[800/3500] D(real): -0.82. D(fake): -0.90. rec_loss: 0.0909. gp: 0.0201 \n","[900/3500] D(real): -0.87. D(fake): -0.90. rec_loss: 0.0842. gp: 0.0102 \n","[1000/3500] D(real): -0.82. D(fake): -0.87. rec_loss: 0.0831. gp: 0.0304 \n","[1100/3500] D(real): -0.84. D(fake): -0.90. rec_loss: 0.0809. gp: 0.0197 \n","[1200/3500] D(real): -0.92. D(fake): -0.94. rec_loss: 0.0784. gp: 0.0061 \n","[1300/3500] D(real): -0.82. D(fake): -0.85. rec_loss: 0.0790. gp: 0.0097 \n","[1400/3500] D(real): -0.82. D(fake): -0.89. rec_loss: 0.0781. gp: 0.0323 \n","[1500/3500] D(real): -0.85. D(fake): -0.93. rec_loss: 0.0746. gp: 0.0104 \n","[1600/3500] D(real): -0.84. D(fake): -0.90. rec_loss: 0.0756. gp: 0.0112 \n","[1700/3500] D(real): -0.97. D(fake): -0.98. rec_loss: 0.0716. gp: 0.0132 \n","[1800/3500] D(real): -0.99. D(fake): -1.00. rec_loss: 0.0721. gp: 0.0091 \n","[1900/3500] D(real): -0.83. D(fake): -0.89. rec_loss: 0.0716. gp: 0.0080 \n","[2000/3500] D(real): -0.95. D(fake): -0.96. rec_loss: 0.0710. gp: 0.0064 \n","[2100/3500] D(real): -0.93. D(fake): -1.00. rec_loss: 0.0704. gp: 0.0930 \n","[2200/3500] D(real): -0.90. D(fake): -0.96. rec_loss: 0.0683. gp: 0.0096 \n","[2300/3500] D(real): -0.87. D(fake): -0.97. rec_loss: 0.0686. gp: 0.0141 \n","[2400/3500] D(real): -0.92. D(fake): -1.01. rec_loss: 0.0628. gp: 0.0177 \n","[2500/3500] D(real): -0.95. D(fake): -1.02. rec_loss: 0.0627. gp: 0.0311 \n","[2600/3500] D(real): -0.97. D(fake): -1.05. rec_loss: 0.0628. gp: 0.0111 \n","[2700/3500] D(real): -0.94. D(fake): -1.04. rec_loss: 0.0625. gp: 0.1453 \n","[2800/3500] D(real): -0.96. D(fake): -1.04. rec_loss: 0.0623. gp: 0.0126 \n","[2900/3500] D(real): -0.96. D(fake): -1.04. rec_loss: 0.0622. gp: 0.0176 \n","[3000/3500] D(real): -0.96. D(fake): -1.05. rec_loss: 0.0620. gp: 0.0079 \n","[3100/3500] D(real): -0.98. D(fake): -1.06. rec_loss: 0.0619. gp: 0.0533 \n","[3200/3500] D(real): -0.98. D(fake): -1.07. rec_loss: 0.0622. gp: 0.0095 \n","[3300/3500] D(real): -0.96. D(fake): -1.05. rec_loss: 0.0618. gp: 0.0187 \n","[3400/3500] D(real): -0.96. D(fake): -1.08. rec_loss: 0.0618. gp: 0.0282 \n","Total time in scale 0: 13258[sec] (3.79[sec]/epoch on avg.). D(real): -0.955415, D(fake): -1.077937, rec_loss: 0.0618. gp: 0.0282\n","****************************** Finished working on scale 0 ******************************\n"]}],"source":["#training\n","startTime = time.time()\n","\n","if len(inpainting_indices)%2 != 0:\n","    raise Exception('Provide START and END indices of each hole!')\n","\n","if is_cuda:\n","    torch.cuda.set_device(gpu_num)\n","    device = torch.device(\"cuda:%d\" % gpu_num)\n","\n","if manual_random_seed != -1:\n","    random.seed(manual_random_seed)\n","    torch.manual_seed(manual_random_seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","samples, Fs = get_input_signal(input_file, max_length)\n","\n","fs_list = [f for f in fs_list if f <= Fs]\n","if fs_list[-1] != Fs:\n","    fs_list.append(Fs)\n","\n","scales = [Fs / f for f in fs_list]\n","\n","print('Working on file: %s' % input_file)\n","\n","scheduler_milestones = [int(num_epochs * 2 / 3)]\n","\n","alpha1 = 0\n","alpha2 = 1e-4\n","add_cond_noise = True\n","\n","dilation_factors = [2 ** i for i in range(num_layers)]\n","\n","if not os.path.exists(output_folder):\n","    os.mkdir(output_folder)\n","\n","if os.path.exists(output_folder):\n","    dirs = glob.glob(output_folder + '*')\n","    output_folder = output_folder + '_' + str(len(dirs) + 1)\n","\n","os.mkdir(output_folder)\n","print('Writing results to %s\\n' % output_folder)\n","\n","signals_list, fs_list = create_input_signals(scales, set_first_scale_by_energy, min_energy_th,  filter_size, torch.tensor(samples), Fs)\n","if len(signals_list) == 0:\n","    set_first_scale_by_energy = False\n","    scales = scales[2:]  # Manually start from 500\n","    signals_list, fs_list = create_input_signals(scales, set_first_scale_by_energy, min_energy_th,  filter_size, torch.tensor(samples), Fs)\n","scales = [Fs / f for f in fs_list]\n","\n","fs_list = fs_list\n","inputs_lengths = [len(s) for s in signals_list]\n","\n","print('Running on ' + str(device))\n","\n","output_signals, loss_vectors, generators_list, noise_amp_list, energy_list, reconstruction_noise_list = train(\n","                          manual_random_seed, fs_list, scales, growing_hidden_channels_factor,learning_rate, beta1, scheduler_lr_decay,\n","                          plot_losses, initial_noise_amp, noise_amp_factor, signals_list, dilation_factors, output_folder, inputs_lengths)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"bBY1GNTZpbgP","executionInfo":{"status":"ok","timestamp":1663332110155,"user_tz":-60,"elapsed":5,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"outputs":[],"source":["#!zip -r outputs.zip outputs_2"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"pfWK4VohjG0Z","executionInfo":{"status":"ok","timestamp":1663332776250,"user_tz":-60,"elapsed":228,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"outputs":[],"source":["class AudioGenerator(object):\n","    def __init__(self, output_folder, fs_list, dilation_factors, filter_size, device, generators_list=None, noise_amp_list=None, reconstruction_noise_list=None):\n","        super(AudioGenerator, self).__init__()\n","        self.generators_list = generators_list\n","        self.noise_amp_list = noise_amp_list\n","        self.reconstruction_noise_list = reconstruction_noise_list\n","        self.output_folder = output_folder\n","        self.fs_list= fs_list\n","        self.device = device\n","        self.dilation_factors = dilation_factors\n","        self.filter_size = filter_size\n","        if not os.path.exists(os.path.join(output_folder, 'GeneratedSignals')):\n","            os.mkdir(os.path.join(output_folder, 'GeneratedSignals'))\n","\n","    def generate(self, nSignals=1, length=20, generate_all_scales=False):\n","        for sig_idx in range(nSignals):\n","            # Draws a signal up to current scale, using learned generators\n","            output_signals_list = draw_signal(self.generators_list,\n","                                              [round(f * length) for f in self.fs_list], self.fs_list,\n","                                              self.noise_amp_list,  self.filter_size, self.dilation_factors, self.device, \n","                                              output_all_scales=generate_all_scales)\n","            # Write signals\n","            if generate_all_scales:\n","                for scale_idx, sig in enumerate(output_signals_list):\n","                    write_signal(\n","                        os.path.join(self.output_folder, 'GeneratedSignals',\n","                                     'generated@%dHz.wav' % self.fs_list[scale_idx]),\n","                        sig, self.fs_list[scale_idx], overwrite=False)\n","            else:\n","                write_signal(\n","                    os.path.join(self.output_folder, 'GeneratedSignals',\n","                                 'generated@%dHz.wav' % self.fs_list[-1]),\n","                    output_signals_list, self.fs_list[-1], overwrite=False)\n","\n","    def condition(self, condition, write=True):\n","        condition[\"condition_scale_idx\"] = np.where(np.array(self.fs_list) <= condition[\"condition_fs\"])[0][\n","                                               -1] + 1\n","        condition[\"condition_signal\"] = torch.Tensor(condition[\"condition_signal\"]).expand(1, 1, -1).to(\n","            self.device)\n","        lengths = [int(condition[\"condition_signal\"].shape[2] / condition[\"condition_fs\"] * fs) for fs in\n","                   self.fs_list]\n","        conditioned_signal = draw_signal(self.generators_list, lengths, self.fs_list, self.noise_amp_list, \n","                                         self.filter_size, self.dilation_factors, self.device,\n","                                         condition=condition)\n","        if write:\n","            output_file = os.path.join(self.output_folder, 'GeneratedSignals',\n","                                       'conditioned_on_' + condition['name'])\n","            write_signal(output_file, conditioned_signal, self.params.Fs)\n","        else:\n","            return conditioned_signal"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"2XgcJ9x-zq06","executionInfo":{"status":"ok","timestamp":1663332936122,"user_tz":-60,"elapsed":529,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"outputs":[],"source":["nSignals=1\n","length=25\n","generate_all_scales=False\n","\n","audio_generator = AudioGenerator(output_folder, fs_list, dilation_factors, filter_size, device, generators_list, noise_amp_list,\n","                                 reconstruction_noise_list=reconstruction_noise_list)\n","\n","audio_generator.generate(nSignals=nSignals, length=length,generate_all_scales=generate_all_scales)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"W_HyF3o0kkHQ","executionInfo":{"status":"ok","timestamp":1663332931275,"user_tz":-60,"elapsed":294,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"outputs":[],"source":["path = \"/content/outputs_2/GeneratedSignals\""]},{"cell_type":"code","execution_count":33,"metadata":{"id":"wLMleJ-vk2oB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663332940099,"user_tz":-60,"elapsed":213,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}},"outputId":"855b0eb1-40d2-4d12-f0ee-200e9e387e9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["We have 5 .Wav Files with 3.81 Mb in size\n"]}],"source":["paths = []\n","size = 0\n","for root, dirs, files in os.walk(path):\n","    for file in files:\n","        if (file.endswith(\".wav\") and  (not (file.startswith(\".\") or file.startswith(\"noise\")))):\n","             paths.append(os.path.join(root, file))\n","             size += os.path.getsize(os.path.join(root, file))\n","             \n","\n","\n","print(f'We have {len(paths)} .Wav Files with {size/1024**2:.2f} Mb in size')"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"wWO_wzVto6df","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663332945680,"user_tz":-60,"elapsed":483,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}},"outputId":"261e98d3-eb83-441d-b2ef-506675f31fa9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['updating: content/outputs_2/GeneratedSignals/ (stored 0%)',\n"," 'updating: content/outputs_2/GeneratedSignals/generated@16000Hz.wav (deflated 14%)',\n"," 'updating: content/outputs_2/GeneratedSignals/generated@16000Hz_1.wav (deflated 16%)',\n"," '  adding: content/outputs_2/GeneratedSignals/generated@16000Hz_2.wav (deflated 13%)',\n"," '  adding: content/outputs_2/GeneratedSignals/generated@16000Hz_3.wav (deflated 15%)',\n"," '  adding: content/outputs_2/GeneratedSignals/generated@16000Hz_4.wav (deflated 11%)']"]},"metadata":{},"execution_count":34}],"source":["!!zip -r /content/outputs_2/GeneratedSignals.zip /content/outputs_2/GeneratedSignals"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"T112qY4jpfmr","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1663332953362,"user_tz":-60,"elapsed":226,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}},"outputId":"e7b4c119-0262-4a8f-d779-58321bbadeb6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_4fa14740-ee0c-42f7-a905-1cc9d73abc68\", \"GeneratedSignals.zip\", 3446358)"]},"metadata":{}}],"source":["from google.colab import files\n","files.download('/content/outputs_2/GeneratedSignals.zip')"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"7aCyKbHdaDnH","executionInfo":{"status":"ok","timestamp":1663332957167,"user_tz":-60,"elapsed":2,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"outputs":[],"source":["!cp /content/outputs_2/GeneratedSignals.zip  /content/drive/MyDrive/FinalProject/CAW_outputs"]},{"cell_type":"markdown","metadata":{"id":"-Du88qF5aFIw"},"source":["# Remember to change this path everything you do generation ok"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"ruT6IPL-aKZn","executionInfo":{"status":"ok","timestamp":1663332111748,"user_tz":-60,"elapsed":6,"user":{"displayName":"ibantxo drums","userId":"09404425136583861915"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[],"background_execution":"on"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}